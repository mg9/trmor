
number of params: 3078 
Namespace(batchsize=512, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=300, fig_path='evaluation/probing/tense/results/training/vqvae_7_1_probe/3487_instances/300epochs.png', log_path='evaluation/probing/tense/results/training/vqvae_7_1_probe/3487_instances/300epochs.log', logger=<common.utils.Logger object at 0x7f286160bfd0>, lr=0.001, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='vqvae_7_1_probe', model=VQVAE_Probe(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_root): Linear(in_features=512, out_features=320, bias=True)
  (vq_layer_root): VectorQuantizer(
    (embedding): Embedding(1000, 320)
  )
  (ord_linears): ModuleList(
    (0): Linear(in_features=512, out_features=32, bias=True)
    (1): Linear(in_features=512, out_features=32, bias=True)
    (2): Linear(in_features=512, out_features=32, bias=True)
    (3): Linear(in_features=512, out_features=32, bias=True)
    (4): Linear(in_features=512, out_features=32, bias=True)
    (5): Linear(in_features=512, out_features=32, bias=True)
  )
  (ord_vq_layers): ModuleList(
    (0): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (1): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (2): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (3): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (4): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (5): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
  )
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/tense/results/training/vqvae_7_1_probe/3487_instances/', nh=512, ni=256, num_dicts=7, nz=512, opt='Adam', orddict_emb_num=100, pretrained_model=VQVAE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_root): Linear(in_features=512, out_features=320, bias=True)
  (vq_layer_root): VectorQuantizer(
    (embedding): Embedding(1000, 320)
  )
  (ord_linears): ModuleList(
    (0): Linear(in_features=512, out_features=32, bias=True)
    (1): Linear(in_features=512, out_features=32, bias=True)
    (2): Linear(in_features=512, out_features=32, bias=True)
    (3): Linear(in_features=512, out_features=32, bias=True)
    (4): Linear(in_features=512, out_features=32, bias=True)
    (5): Linear(in_features=512, out_features=32, bias=True)
  )
  (ord_vq_layers): ModuleList(
    (0): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (1): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (2): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (3): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (4): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (5): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(32, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=32, bias=False)
    (loss): CrossEntropyLoss()
  )
), rootdict_emb_dim=320, rootdict_emb_num=1000, save_path='evaluation/probing/tense/results/training/vqvae_7_1_probe/3487_instances/300epochs.pt', seq_to_no_pad='surface', task='surf2tense', trndata='evaluation/probing/tense/data/sosimple.new.trn.combined.txt', trnsize=3487, tstdata='evaluation/probing/tense/data/sosimple.new.seenroots.val.txt', tstsize=209, valdata='evaluation/probing/tense/data/sosimple.new.seenroots.val.txt', valsize=209)

encoder.embed.weight, torch.Size([32, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
linear_root.weight, torch.Size([320, 512]): False
linear_root.bias, torch.Size([320]): False
vq_layer_root.embedding.weight, torch.Size([1000, 320]): False
ord_linears.0.weight, torch.Size([32, 512]): False
ord_linears.0.bias, torch.Size([32]): False
ord_linears.1.weight, torch.Size([32, 512]): False
ord_linears.1.bias, torch.Size([32]): False
ord_linears.2.weight, torch.Size([32, 512]): False
ord_linears.2.bias, torch.Size([32]): False
ord_linears.3.weight, torch.Size([32, 512]): False
ord_linears.3.bias, torch.Size([32]): False
ord_linears.4.weight, torch.Size([32, 512]): False
ord_linears.4.bias, torch.Size([32]): False
ord_linears.5.weight, torch.Size([32, 512]): False
ord_linears.5.bias, torch.Size([32]): False
ord_vq_layers.0.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.1.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.2.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.3.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.4.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.5.embedding.weight, torch.Size([100, 32]): False
linear.weight, torch.Size([6, 512]): True
linear.bias, torch.Size([6]): True
epoch: 0 avg_loss: 1.5955, acc: 0.2819 
val --- avg_loss: 1.0752, acc: 0.8756  
update best loss 

epoch: 1 avg_loss: 1.0692, acc: 0.5087 
val --- avg_loss: 0.6671, acc: 0.9569  
update best loss 

epoch: 2 avg_loss: 0.8229, acc: 0.6100 
val --- avg_loss: 0.5846, acc: 0.9569  
update best loss 

epoch: 3 avg_loss: 0.6764, acc: 0.7072 
val --- avg_loss: 0.4871, acc: 0.9617  
update best loss 

epoch: 4 avg_loss: 0.5772, acc: 0.7508 
val --- avg_loss: 0.4116, acc: 0.9713  
update best loss 

epoch: 5 avg_loss: 0.5064, acc: 0.8010 
val --- avg_loss: 0.3850, acc: 0.9713  
update best loss 

epoch: 6 avg_loss: 0.4494, acc: 0.8314 
val --- avg_loss: 0.3268, acc: 0.9761  
update best loss 

epoch: 7 avg_loss: 0.4041, acc: 0.8546 
val --- avg_loss: 0.3032, acc: 0.9761  
update best loss 

epoch: 8 avg_loss: 0.3682, acc: 0.8712 
val --- avg_loss: 0.2880, acc: 0.9809  
update best loss 

epoch: 9 avg_loss: 0.3386, acc: 0.8824 
val --- avg_loss: 0.2605, acc: 0.9809  
update best loss 

epoch: 10 avg_loss: 0.3156, acc: 0.8991 
val --- avg_loss: 0.2585, acc: 0.9713  
update best loss 

epoch: 11 avg_loss: 0.2923, acc: 0.9042 
val --- avg_loss: 0.2279, acc: 0.9761  
update best loss 

epoch: 12 avg_loss: 0.2729, acc: 0.9097 
val --- avg_loss: 0.2196, acc: 0.9713  
update best loss 

epoch: 13 avg_loss: 0.2584, acc: 0.9148 
val --- avg_loss: 0.2058, acc: 0.9761  
update best loss 

epoch: 14 avg_loss: 0.2436, acc: 0.9237 
val --- avg_loss: 0.2143, acc: 0.9713  

epoch: 15 avg_loss: 0.2296, acc: 0.9292 
val --- avg_loss: 0.1951, acc: 0.9809  
update best loss 

epoch: 16 avg_loss: 0.2191, acc: 0.9295 
val --- avg_loss: 0.1705, acc: 0.9856  
update best loss 

epoch: 17 avg_loss: 0.2083, acc: 0.9320 
val --- avg_loss: 0.1691, acc: 0.9856  
update best loss 

epoch: 18 avg_loss: 0.2003, acc: 0.9372 
val --- avg_loss: 0.1827, acc: 0.9809  

epoch: 19 avg_loss: 0.1908, acc: 0.9447 
val --- avg_loss: 0.1718, acc: 0.9856  

epoch: 20 avg_loss: 0.1833, acc: 0.9444 
val --- avg_loss: 0.1535, acc: 0.9856  
update best loss 

epoch: 21 avg_loss: 0.1766, acc: 0.9458 
val --- avg_loss: 0.1529, acc: 0.9856  
update best loss 

epoch: 22 avg_loss: 0.1700, acc: 0.9481 
val --- avg_loss: 0.1476, acc: 0.9856  
update best loss 

epoch: 23 avg_loss: 0.1639, acc: 0.9487 
val --- avg_loss: 0.1464, acc: 0.9856  
update best loss 

epoch: 24 avg_loss: 0.1583, acc: 0.9515 
val --- avg_loss: 0.1430, acc: 0.9856  
update best loss 

epoch: 25 avg_loss: 0.1532, acc: 0.9515 
val --- avg_loss: 0.1367, acc: 0.9856  
update best loss 

epoch: 26 avg_loss: 0.1479, acc: 0.9518 
val --- avg_loss: 0.1352, acc: 0.9809  
update best loss 

epoch: 27 avg_loss: 0.1438, acc: 0.9527 
val --- avg_loss: 0.1349, acc: 0.9856  
update best loss 

epoch: 28 avg_loss: 0.1399, acc: 0.9541 
val --- avg_loss: 0.1350, acc: 0.9809  

epoch: 29 avg_loss: 0.1357, acc: 0.9558 
val --- avg_loss: 0.1227, acc: 0.9856  
update best loss 

epoch: 30 avg_loss: 0.1318, acc: 0.9561 
val --- avg_loss: 0.1259, acc: 0.9809  

epoch: 31 avg_loss: 0.1282, acc: 0.9573 
val --- avg_loss: 0.1210, acc: 0.9809  
update best loss 

epoch: 32 avg_loss: 0.1251, acc: 0.9567 
val --- avg_loss: 0.1178, acc: 0.9809  
update best loss 

epoch: 33 avg_loss: 0.1216, acc: 0.9581 
val --- avg_loss: 0.1169, acc: 0.9809  
update best loss 

epoch: 34 avg_loss: 0.1192, acc: 0.9570 
val --- avg_loss: 0.1158, acc: 0.9809  
update best loss 

epoch: 35 avg_loss: 0.1160, acc: 0.9593 
val --- avg_loss: 0.1136, acc: 0.9809  
update best loss 

epoch: 36 avg_loss: 0.1136, acc: 0.9593 
val --- avg_loss: 0.1107, acc: 0.9809  
update best loss 

epoch: 37 avg_loss: 0.1110, acc: 0.9604 
val --- avg_loss: 0.1072, acc: 0.9809  
update best loss 

epoch: 38 avg_loss: 0.1088, acc: 0.9601 
val --- avg_loss: 0.1053, acc: 0.9809  
update best loss 

epoch: 39 avg_loss: 0.1067, acc: 0.9621 
val --- avg_loss: 0.1094, acc: 0.9809  

epoch: 40 avg_loss: 0.1042, acc: 0.9624 
val --- avg_loss: 0.1044, acc: 0.9809  
update best loss 

epoch: 41 avg_loss: 0.1018, acc: 0.9621 
val --- avg_loss: 0.1016, acc: 0.9809  
update best loss 

epoch: 42 avg_loss: 0.1003, acc: 0.9633 
val --- avg_loss: 0.0985, acc: 0.9809  
update best loss 

epoch: 43 avg_loss: 0.0979, acc: 0.9642 
val --- avg_loss: 0.1023, acc: 0.9761  

epoch: 44 avg_loss: 0.0960, acc: 0.9644 
val --- avg_loss: 0.1008, acc: 0.9761  

epoch: 45 avg_loss: 0.0948, acc: 0.9644 
val --- avg_loss: 0.0958, acc: 0.9809  
update best loss 

epoch: 46 avg_loss: 0.0927, acc: 0.9656 
val --- avg_loss: 0.0961, acc: 0.9856  

epoch: 47 avg_loss: 0.0912, acc: 0.9653 
val --- avg_loss: 0.0967, acc: 0.9761  

epoch: 48 avg_loss: 0.0896, acc: 0.9659 
val --- avg_loss: 0.0950, acc: 0.9761  
update best loss 

epoch: 49 avg_loss: 0.0884, acc: 0.9670 
val --- avg_loss: 0.0915, acc: 0.9856  
update best loss 

epoch: 50 avg_loss: 0.0869, acc: 0.9667 
val --- avg_loss: 0.0939, acc: 0.9856  

epoch: 51 avg_loss: 0.0853, acc: 0.9682 
val --- avg_loss: 0.0923, acc: 0.9809  

epoch: 52 avg_loss: 0.0840, acc: 0.9687 
val --- avg_loss: 0.0891, acc: 0.9809  
update best loss 

epoch: 53 avg_loss: 0.0827, acc: 0.9693 
val --- avg_loss: 0.0869, acc: 0.9856  
update best loss 

epoch: 54 avg_loss: 0.0818, acc: 0.9690 
val --- avg_loss: 0.0859, acc: 0.9856  
update best loss 

epoch: 55 avg_loss: 0.0803, acc: 0.9696 
val --- avg_loss: 0.0880, acc: 0.9761  

epoch: 56 avg_loss: 0.0790, acc: 0.9705 
val --- avg_loss: 0.0852, acc: 0.9761  
update best loss 

epoch: 57 avg_loss: 0.0779, acc: 0.9716 
val --- avg_loss: 0.0862, acc: 0.9809  

epoch: 58 avg_loss: 0.0769, acc: 0.9719 
val --- avg_loss: 0.0872, acc: 0.9713  

epoch: 59 avg_loss: 0.0756, acc: 0.9730 
val --- avg_loss: 0.0856, acc: 0.9713  

epoch: 60 avg_loss: 0.0747, acc: 0.9730 
val --- avg_loss: 0.0832, acc: 0.9761  
update best loss 

epoch: 61 avg_loss: 0.0739, acc: 0.9722 
val --- avg_loss: 0.0786, acc: 0.9809  
update best loss 

epoch: 62 avg_loss: 0.0727, acc: 0.9733 
val --- avg_loss: 0.0809, acc: 0.9713  

epoch: 63 avg_loss: 0.0722, acc: 0.9742 
val --- avg_loss: 0.0846, acc: 0.9713  

epoch: 64 avg_loss: 0.0712, acc: 0.9739 
val --- avg_loss: 0.0789, acc: 0.9713  

epoch: 65 avg_loss: 0.0701, acc: 0.9745 
val --- avg_loss: 0.0772, acc: 0.9856  
update best loss 

epoch: 66 avg_loss: 0.0695, acc: 0.9759 
val --- avg_loss: 0.0835, acc: 0.9713  

epoch: 67 avg_loss: 0.0682, acc: 0.9751 
val --- avg_loss: 0.0778, acc: 0.9713  

epoch: 68 avg_loss: 0.0673, acc: 0.9751 
val --- avg_loss: 0.0785, acc: 0.9713  

epoch: 69 avg_loss: 0.0669, acc: 0.9748 
val --- avg_loss: 0.0762, acc: 0.9761  
update best loss 

epoch: 70 avg_loss: 0.0661, acc: 0.9751 
val --- avg_loss: 0.0784, acc: 0.9713  

epoch: 71 avg_loss: 0.0655, acc: 0.9762 
val --- avg_loss: 0.0735, acc: 0.9761  
update best loss 

epoch: 72 avg_loss: 0.0642, acc: 0.9771 
val --- avg_loss: 0.0780, acc: 0.9713  

epoch: 73 avg_loss: 0.0637, acc: 0.9776 
val --- avg_loss: 0.0794, acc: 0.9713  

epoch: 74 avg_loss: 0.0628, acc: 0.9771 
val --- avg_loss: 0.0756, acc: 0.9713  

epoch: 75 avg_loss: 0.0623, acc: 0.9765 
val --- avg_loss: 0.0720, acc: 0.9713  
update best loss 

epoch: 76 avg_loss: 0.0615, acc: 0.9782 
val --- avg_loss: 0.0730, acc: 0.9713  

epoch: 77 avg_loss: 0.0608, acc: 0.9782 
val --- avg_loss: 0.0735, acc: 0.9713  

epoch: 78 avg_loss: 0.0601, acc: 0.9796 
val --- avg_loss: 0.0732, acc: 0.9761  

epoch: 79 avg_loss: 0.0595, acc: 0.9785 
val --- avg_loss: 0.0732, acc: 0.9713  

epoch: 80 avg_loss: 0.0589, acc: 0.9796 
val --- avg_loss: 0.0727, acc: 0.9713  

epoch: 81 avg_loss: 0.0585, acc: 0.9791 
val --- avg_loss: 0.0736, acc: 0.9713  

epoch: 82 avg_loss: 0.0580, acc: 0.9788 
val --- avg_loss: 0.0700, acc: 0.9761  
update best loss 

epoch: 83 avg_loss: 0.0572, acc: 0.9791 
val --- avg_loss: 0.0710, acc: 0.9713  

epoch: 84 avg_loss: 0.0566, acc: 0.9794 
val --- avg_loss: 0.0738, acc: 0.9713  

epoch: 85 avg_loss: 0.0564, acc: 0.9802 
val --- avg_loss: 0.0698, acc: 0.9713  
update best loss 

epoch: 86 avg_loss: 0.0558, acc: 0.9805 
val --- avg_loss: 0.0717, acc: 0.9713  

epoch: 87 avg_loss: 0.0549, acc: 0.9814 
val --- avg_loss: 0.0712, acc: 0.9713  

epoch: 88 avg_loss: 0.0547, acc: 0.9805 
val --- avg_loss: 0.0668, acc: 0.9713  
update best loss 

epoch: 89 avg_loss: 0.0539, acc: 0.9808 
val --- avg_loss: 0.0688, acc: 0.9713  

epoch: 90 avg_loss: 0.0535, acc: 0.9805 
val --- avg_loss: 0.0692, acc: 0.9713  

epoch: 91 avg_loss: 0.0531, acc: 0.9805 
val --- avg_loss: 0.0686, acc: 0.9713  

epoch: 92 avg_loss: 0.0524, acc: 0.9814 
val --- avg_loss: 0.0674, acc: 0.9713  

epoch: 93 avg_loss: 0.0521, acc: 0.9808 
val --- avg_loss: 0.0654, acc: 0.9713  
update best loss 

epoch: 94 avg_loss: 0.0515, acc: 0.9814 
val --- avg_loss: 0.0687, acc: 0.9713  

epoch: 95 avg_loss: 0.0514, acc: 0.9811 
val --- avg_loss: 0.0679, acc: 0.9713  

epoch: 96 avg_loss: 0.0507, acc: 0.9814 
val --- avg_loss: 0.0649, acc: 0.9713  
update best loss 

epoch: 97 avg_loss: 0.0503, acc: 0.9816 
val --- avg_loss: 0.0640, acc: 0.9713  
update best loss 

epoch: 98 avg_loss: 0.0497, acc: 0.9814 
val --- avg_loss: 0.0658, acc: 0.9713  

epoch: 99 avg_loss: 0.0493, acc: 0.9816 
val --- avg_loss: 0.0642, acc: 0.9713  

epoch: 100 avg_loss: 0.0491, acc: 0.9819 
val --- avg_loss: 0.0681, acc: 0.9713  

epoch: 101 avg_loss: 0.0486, acc: 0.9816 
val --- avg_loss: 0.0637, acc: 0.9713  
update best loss 

epoch: 102 avg_loss: 0.0481, acc: 0.9822 
val --- avg_loss: 0.0639, acc: 0.9713  

epoch: 103 avg_loss: 0.0477, acc: 0.9819 
val --- avg_loss: 0.0624, acc: 0.9713  
update best loss 

epoch: 104 avg_loss: 0.0475, acc: 0.9828 
val --- avg_loss: 0.0678, acc: 0.9713  

epoch: 105 avg_loss: 0.0469, acc: 0.9825 
val --- avg_loss: 0.0642, acc: 0.9713  

epoch: 106 avg_loss: 0.0465, acc: 0.9825 
val --- avg_loss: 0.0629, acc: 0.9713  

epoch: 107 avg_loss: 0.0464, acc: 0.9822 
val --- avg_loss: 0.0644, acc: 0.9713  

epoch: 108 avg_loss: 0.0458, acc: 0.9825 
val --- avg_loss: 0.0624, acc: 0.9761  
update best loss 

epoch: 109 avg_loss: 0.0454, acc: 0.9825 
val --- avg_loss: 0.0626, acc: 0.9713  

epoch: 110 avg_loss: 0.0451, acc: 0.9828 
val --- avg_loss: 0.0619, acc: 0.9761  
update best loss 

epoch: 111 avg_loss: 0.0448, acc: 0.9825 
val --- avg_loss: 0.0618, acc: 0.9713  
update best loss 

epoch: 112 avg_loss: 0.0444, acc: 0.9825 
val --- avg_loss: 0.0617, acc: 0.9713  
update best loss 

epoch: 113 avg_loss: 0.0442, acc: 0.9828 
val --- avg_loss: 0.0597, acc: 0.9713  
update best loss 

epoch: 114 avg_loss: 0.0438, acc: 0.9834 
val --- avg_loss: 0.0635, acc: 0.9713  

epoch: 115 avg_loss: 0.0434, acc: 0.9834 
val --- avg_loss: 0.0620, acc: 0.9713  

epoch: 116 avg_loss: 0.0432, acc: 0.9831 
val --- avg_loss: 0.0601, acc: 0.9761  

epoch: 117 avg_loss: 0.0427, acc: 0.9834 
val --- avg_loss: 0.0610, acc: 0.9761  

epoch: 118 avg_loss: 0.0424, acc: 0.9831 
val --- avg_loss: 0.0598, acc: 0.9761  

epoch: 119 avg_loss: 0.0421, acc: 0.9834 
val --- avg_loss: 0.0598, acc: 0.9761  

epoch: 120 avg_loss: 0.0419, acc: 0.9837 
val --- avg_loss: 0.0617, acc: 0.9713  

epoch: 121 avg_loss: 0.0416, acc: 0.9839 
val --- avg_loss: 0.0614, acc: 0.9713  

epoch: 122 avg_loss: 0.0413, acc: 0.9837 
val --- avg_loss: 0.0590, acc: 0.9761  
update best loss 

epoch: 123 avg_loss: 0.0408, acc: 0.9837 
val --- avg_loss: 0.0583, acc: 0.9761  
update best loss 

epoch: 124 avg_loss: 0.0406, acc: 0.9837 
val --- avg_loss: 0.0611, acc: 0.9761  

epoch: 125 avg_loss: 0.0404, acc: 0.9837 
val --- avg_loss: 0.0572, acc: 0.9761  
update best loss 

epoch: 126 avg_loss: 0.0400, acc: 0.9837 
val --- avg_loss: 0.0589, acc: 0.9761  

epoch: 127 avg_loss: 0.0396, acc: 0.9837 
val --- avg_loss: 0.0582, acc: 0.9761  

epoch: 128 avg_loss: 0.0395, acc: 0.9837 
val --- avg_loss: 0.0599, acc: 0.9761  

epoch: 129 avg_loss: 0.0392, acc: 0.9842 
val --- avg_loss: 0.0579, acc: 0.9761  

epoch: 130 avg_loss: 0.0391, acc: 0.9839 
val --- avg_loss: 0.0565, acc: 0.9761  
update best loss 

epoch: 131 avg_loss: 0.0388, acc: 0.9839 
val --- avg_loss: 0.0586, acc: 0.9761  

epoch: 132 avg_loss: 0.0384, acc: 0.9848 
val --- avg_loss: 0.0577, acc: 0.9761  

epoch: 133 avg_loss: 0.0381, acc: 0.9851 
val --- avg_loss: 0.0577, acc: 0.9761  

epoch: 134 avg_loss: 0.0378, acc: 0.9845 
val --- avg_loss: 0.0574, acc: 0.9761  

epoch: 135 avg_loss: 0.0376, acc: 0.9842 
val --- avg_loss: 0.0565, acc: 0.9761  

epoch: 136 avg_loss: 0.0374, acc: 0.9845 
val --- avg_loss: 0.0561, acc: 0.9761  
update best loss 

epoch: 137 avg_loss: 0.0372, acc: 0.9848 
val --- avg_loss: 0.0568, acc: 0.9761  

epoch: 138 avg_loss: 0.0368, acc: 0.9851 
val --- avg_loss: 0.0555, acc: 0.9761  
update best loss 

epoch: 139 avg_loss: 0.0366, acc: 0.9859 
val --- avg_loss: 0.0597, acc: 0.9761  

epoch: 140 avg_loss: 0.0364, acc: 0.9851 
val --- avg_loss: 0.0552, acc: 0.9761  
update best loss 

epoch: 141 avg_loss: 0.0361, acc: 0.9854 
val --- avg_loss: 0.0568, acc: 0.9761  

epoch: 142 avg_loss: 0.0360, acc: 0.9851 
val --- avg_loss: 0.0545, acc: 0.9761  
update best loss 

epoch: 143 avg_loss: 0.0357, acc: 0.9848 
val --- avg_loss: 0.0544, acc: 0.9761  
update best loss 

epoch: 144 avg_loss: 0.0355, acc: 0.9859 
val --- avg_loss: 0.0555, acc: 0.9761  

epoch: 145 avg_loss: 0.0351, acc: 0.9862 
val --- avg_loss: 0.0553, acc: 0.9761  

epoch: 146 avg_loss: 0.0349, acc: 0.9859 
val --- avg_loss: 0.0551, acc: 0.9761  

epoch: 147 avg_loss: 0.0347, acc: 0.9857 
val --- avg_loss: 0.0544, acc: 0.9761  
update best loss 

epoch: 148 avg_loss: 0.0347, acc: 0.9857 
val --- avg_loss: 0.0575, acc: 0.9761  

epoch: 149 avg_loss: 0.0344, acc: 0.9859 
val --- avg_loss: 0.0523, acc: 0.9761  
update best loss 

epoch: 150 avg_loss: 0.0342, acc: 0.9862 
val --- avg_loss: 0.0529, acc: 0.9761  

epoch: 151 avg_loss: 0.0340, acc: 0.9859 
val --- avg_loss: 0.0552, acc: 0.9761  

epoch: 152 avg_loss: 0.0336, acc: 0.9865 
val --- avg_loss: 0.0533, acc: 0.9761  

epoch: 153 avg_loss: 0.0336, acc: 0.9865 
val --- avg_loss: 0.0515, acc: 0.9761  
update best loss 

epoch: 154 avg_loss: 0.0335, acc: 0.9859 
val --- avg_loss: 0.0561, acc: 0.9761  

epoch: 155 avg_loss: 0.0332, acc: 0.9865 
val --- avg_loss: 0.0541, acc: 0.9761  

epoch: 156 avg_loss: 0.0328, acc: 0.9865 
val --- avg_loss: 0.0534, acc: 0.9761  

epoch: 157 avg_loss: 0.0327, acc: 0.9868 
val --- avg_loss: 0.0540, acc: 0.9761  

epoch: 158 avg_loss: 0.0326, acc: 0.9868 
val --- avg_loss: 0.0512, acc: 0.9761  
update best loss 

epoch: 159 avg_loss: 0.0323, acc: 0.9871 
val --- avg_loss: 0.0550, acc: 0.9761  

epoch: 160 avg_loss: 0.0321, acc: 0.9871 
val --- avg_loss: 0.0520, acc: 0.9761  

epoch: 161 avg_loss: 0.0319, acc: 0.9877 
val --- avg_loss: 0.0524, acc: 0.9761  

epoch: 162 avg_loss: 0.0318, acc: 0.9874 
val --- avg_loss: 0.0518, acc: 0.9761  

epoch: 163 avg_loss: 0.0315, acc: 0.9880 
val --- avg_loss: 0.0524, acc: 0.9761  

epoch: 164 avg_loss: 0.0312, acc: 0.9871 
val --- avg_loss: 0.0510, acc: 0.9761  
update best loss 

epoch: 165 avg_loss: 0.0311, acc: 0.9874 
val --- avg_loss: 0.0531, acc: 0.9761  

epoch: 166 avg_loss: 0.0311, acc: 0.9877 
val --- avg_loss: 0.0526, acc: 0.9761  

epoch: 167 avg_loss: 0.0308, acc: 0.9874 
val --- avg_loss: 0.0518, acc: 0.9761  

epoch: 168 avg_loss: 0.0305, acc: 0.9877 
val --- avg_loss: 0.0530, acc: 0.9761  

epoch: 169 avg_loss: 0.0304, acc: 0.9880 
val --- avg_loss: 0.0510, acc: 0.9761  
update best loss 

epoch: 170 avg_loss: 0.0301, acc: 0.9880 
val --- avg_loss: 0.0511, acc: 0.9761  

epoch: 171 avg_loss: 0.0300, acc: 0.9882 
val --- avg_loss: 0.0501, acc: 0.9761  
update best loss 

epoch: 172 avg_loss: 0.0298, acc: 0.9874 
val --- avg_loss: 0.0506, acc: 0.9761  

epoch: 173 avg_loss: 0.0296, acc: 0.9877 
val --- avg_loss: 0.0530, acc: 0.9761  

epoch: 174 avg_loss: 0.0295, acc: 0.9885 
val --- avg_loss: 0.0502, acc: 0.9761  

epoch: 175 avg_loss: 0.0295, acc: 0.9882 
val --- avg_loss: 0.0539, acc: 0.9761  

epoch: 176 avg_loss: 0.0291, acc: 0.9885 
val --- avg_loss: 0.0509, acc: 0.9761  

epoch: 177 avg_loss: 0.0289, acc: 0.9882 
val --- avg_loss: 0.0494, acc: 0.9761  
update best loss 

epoch: 178 avg_loss: 0.0289, acc: 0.9885 
val --- avg_loss: 0.0507, acc: 0.9761  

epoch: 179 avg_loss: 0.0286, acc: 0.9882 
val --- avg_loss: 0.0498, acc: 0.9761  

epoch: 180 avg_loss: 0.0285, acc: 0.9882 
val --- avg_loss: 0.0487, acc: 0.9761  
update best loss 

epoch: 181 avg_loss: 0.0282, acc: 0.9882 
val --- avg_loss: 0.0507, acc: 0.9761  

epoch: 182 avg_loss: 0.0283, acc: 0.9891 
val --- avg_loss: 0.0499, acc: 0.9761  

epoch: 183 avg_loss: 0.0279, acc: 0.9885 
val --- avg_loss: 0.0515, acc: 0.9761  

epoch: 184 avg_loss: 0.0279, acc: 0.9891 
val --- avg_loss: 0.0497, acc: 0.9761  

epoch: 185 avg_loss: 0.0277, acc: 0.9882 
val --- avg_loss: 0.0472, acc: 0.9809  
update best loss 

epoch: 186 avg_loss: 0.0275, acc: 0.9894 
val --- avg_loss: 0.0496, acc: 0.9761  

epoch: 187 avg_loss: 0.0274, acc: 0.9891 
val --- avg_loss: 0.0483, acc: 0.9761  

epoch: 188 avg_loss: 0.0272, acc: 0.9891 
val --- avg_loss: 0.0496, acc: 0.9761  

epoch: 189 avg_loss: 0.0272, acc: 0.9894 
val --- avg_loss: 0.0500, acc: 0.9761  

epoch: 190 avg_loss: 0.0269, acc: 0.9897 
val --- avg_loss: 0.0502, acc: 0.9761  

epoch: 191 avg_loss: 0.0268, acc: 0.9897 
val --- avg_loss: 0.0480, acc: 0.9761  

epoch: 192 avg_loss: 0.0267, acc: 0.9891 
val --- avg_loss: 0.0487, acc: 0.9761  

epoch: 193 avg_loss: 0.0265, acc: 0.9894 
val --- avg_loss: 0.0513, acc: 0.9761  

epoch: 194 avg_loss: 0.0262, acc: 0.9900 
val --- avg_loss: 0.0494, acc: 0.9761  

epoch: 195 avg_loss: 0.0262, acc: 0.9897 
val --- avg_loss: 0.0452, acc: 0.9809  
update best loss 

epoch: 196 avg_loss: 0.0260, acc: 0.9897 
val --- avg_loss: 0.0472, acc: 0.9761  

epoch: 197 avg_loss: 0.0259, acc: 0.9894 
val --- avg_loss: 0.0498, acc: 0.9761  

epoch: 198 avg_loss: 0.0257, acc: 0.9897 
val --- avg_loss: 0.0485, acc: 0.9761  

epoch: 199 avg_loss: 0.0256, acc: 0.9894 
val --- avg_loss: 0.0482, acc: 0.9761  

epoch: 200 avg_loss: 0.0254, acc: 0.9900 
val --- avg_loss: 0.0481, acc: 0.9761  

epoch: 201 avg_loss: 0.0253, acc: 0.9897 
val --- avg_loss: 0.0489, acc: 0.9761  

epoch: 202 avg_loss: 0.0252, acc: 0.9900 
val --- avg_loss: 0.0466, acc: 0.9761  

epoch: 203 avg_loss: 0.0252, acc: 0.9905 
val --- avg_loss: 0.0477, acc: 0.9761  

epoch: 204 avg_loss: 0.0249, acc: 0.9897 
val --- avg_loss: 0.0469, acc: 0.9761  

epoch: 205 avg_loss: 0.0248, acc: 0.9900 
val --- avg_loss: 0.0484, acc: 0.9761  

epoch: 206 avg_loss: 0.0247, acc: 0.9900 
val --- avg_loss: 0.0458, acc: 0.9761  

epoch: 207 avg_loss: 0.0244, acc: 0.9905 
val --- avg_loss: 0.0485, acc: 0.9761  

epoch: 208 avg_loss: 0.0244, acc: 0.9902 
val --- avg_loss: 0.0486, acc: 0.9761  

epoch: 209 avg_loss: 0.0243, acc: 0.9905 
val --- avg_loss: 0.0482, acc: 0.9761  

epoch: 210 avg_loss: 0.0242, acc: 0.9911 
val --- avg_loss: 0.0465, acc: 0.9761  

epoch: 211 avg_loss: 0.0239, acc: 0.9905 
val --- avg_loss: 0.0460, acc: 0.9761  

epoch: 212 avg_loss: 0.0238, acc: 0.9908 
val --- avg_loss: 0.0460, acc: 0.9761  

epoch: 213 avg_loss: 0.0236, acc: 0.9911 
val --- avg_loss: 0.0470, acc: 0.9761  

epoch: 214 avg_loss: 0.0236, acc: 0.9905 
val --- avg_loss: 0.0490, acc: 0.9761  

epoch: 215 avg_loss: 0.0236, acc: 0.9908 
val --- avg_loss: 0.0442, acc: 0.9761  
update best loss 

epoch: 216 avg_loss: 0.0233, acc: 0.9911 
val --- avg_loss: 0.0470, acc: 0.9761  

epoch: 217 avg_loss: 0.0232, acc: 0.9908 
val --- avg_loss: 0.0461, acc: 0.9761  

epoch: 218 avg_loss: 0.0232, acc: 0.9911 
val --- avg_loss: 0.0457, acc: 0.9761  

epoch: 219 avg_loss: 0.0229, acc: 0.9908 
val --- avg_loss: 0.0472, acc: 0.9761  

epoch: 220 avg_loss: 0.0228, acc: 0.9911 
val --- avg_loss: 0.0446, acc: 0.9761  

epoch: 221 avg_loss: 0.0226, acc: 0.9920 
val --- avg_loss: 0.0450, acc: 0.9761  

epoch: 222 avg_loss: 0.0226, acc: 0.9914 
val --- avg_loss: 0.0478, acc: 0.9761  

epoch: 223 avg_loss: 0.0225, acc: 0.9917 
val --- avg_loss: 0.0443, acc: 0.9761  

epoch: 224 avg_loss: 0.0224, acc: 0.9914 
val --- avg_loss: 0.0469, acc: 0.9761  

epoch: 225 avg_loss: 0.0225, acc: 0.9911 
val --- avg_loss: 0.0449, acc: 0.9761  

epoch: 226 avg_loss: 0.0220, acc: 0.9920 
val --- avg_loss: 0.0457, acc: 0.9761  

epoch: 227 avg_loss: 0.0220, acc: 0.9917 
val --- avg_loss: 0.0455, acc: 0.9761  

epoch: 228 avg_loss: 0.0219, acc: 0.9917 
val --- avg_loss: 0.0479, acc: 0.9761  

epoch: 229 avg_loss: 0.0217, acc: 0.9914 
val --- avg_loss: 0.0452, acc: 0.9761  

epoch: 230 avg_loss: 0.0215, acc: 0.9914 
val --- avg_loss: 0.0446, acc: 0.9761  

epoch: 231 avg_loss: 0.0215, acc: 0.9914 
val --- avg_loss: 0.0456, acc: 0.9761  

epoch: 232 avg_loss: 0.0214, acc: 0.9917 
val --- avg_loss: 0.0460, acc: 0.9761  

epoch: 233 avg_loss: 0.0214, acc: 0.9920 
val --- avg_loss: 0.0427, acc: 0.9761  
update best loss 

epoch: 234 avg_loss: 0.0211, acc: 0.9923 
val --- avg_loss: 0.0441, acc: 0.9761  

epoch: 235 avg_loss: 0.0211, acc: 0.9917 
val --- avg_loss: 0.0448, acc: 0.9761  

epoch: 236 avg_loss: 0.0212, acc: 0.9914 
val --- avg_loss: 0.0474, acc: 0.9761  

epoch: 237 avg_loss: 0.0212, acc: 0.9917 
val --- avg_loss: 0.0427, acc: 0.9761  
update best loss 

epoch: 238 avg_loss: 0.0208, acc: 0.9928 
val --- avg_loss: 0.0458, acc: 0.9761  

epoch: 239 avg_loss: 0.0206, acc: 0.9928 
val --- avg_loss: 0.0461, acc: 0.9761  

epoch: 240 avg_loss: 0.0205, acc: 0.9925 
val --- avg_loss: 0.0444, acc: 0.9761  

epoch: 241 avg_loss: 0.0204, acc: 0.9920 
val --- avg_loss: 0.0433, acc: 0.9809  

epoch: 242 avg_loss: 0.0203, acc: 0.9925 
val --- avg_loss: 0.0456, acc: 0.9761  

epoch: 243 avg_loss: 0.0202, acc: 0.9925 
val --- avg_loss: 0.0429, acc: 0.9761  

epoch: 244 avg_loss: 0.0199, acc: 0.9928 
val --- avg_loss: 0.0441, acc: 0.9761  

epoch: 245 avg_loss: 0.0200, acc: 0.9934 
val --- avg_loss: 0.0455, acc: 0.9761  

epoch: 246 avg_loss: 0.0200, acc: 0.9923 
val --- avg_loss: 0.0421, acc: 0.9809  
update best loss 

epoch: 247 avg_loss: 0.0197, acc: 0.9925 
val --- avg_loss: 0.0438, acc: 0.9761  

epoch: 248 avg_loss: 0.0196, acc: 0.9928 
val --- avg_loss: 0.0444, acc: 0.9761  

epoch: 249 avg_loss: 0.0196, acc: 0.9940 
val --- avg_loss: 0.0453, acc: 0.9761  

epoch: 250 avg_loss: 0.0194, acc: 0.9937 
val --- avg_loss: 0.0421, acc: 0.9761  
update best loss 

epoch: 251 avg_loss: 0.0193, acc: 0.9928 
val --- avg_loss: 0.0436, acc: 0.9809  

epoch: 252 avg_loss: 0.0192, acc: 0.9934 
val --- avg_loss: 0.0433, acc: 0.9761  

epoch: 253 avg_loss: 0.0192, acc: 0.9934 
val --- avg_loss: 0.0427, acc: 0.9761  

epoch: 254 avg_loss: 0.0189, acc: 0.9943 
val --- avg_loss: 0.0445, acc: 0.9761  

epoch: 255 avg_loss: 0.0191, acc: 0.9937 
val --- avg_loss: 0.0425, acc: 0.9809  

epoch: 256 avg_loss: 0.0190, acc: 0.9937 
val --- avg_loss: 0.0446, acc: 0.9761  

epoch: 257 avg_loss: 0.0187, acc: 0.9934 
val --- avg_loss: 0.0439, acc: 0.9761  

epoch: 258 avg_loss: 0.0186, acc: 0.9937 
val --- avg_loss: 0.0427, acc: 0.9761  

epoch: 259 avg_loss: 0.0185, acc: 0.9943 
val --- avg_loss: 0.0428, acc: 0.9761  

epoch: 260 avg_loss: 0.0184, acc: 0.9934 
val --- avg_loss: 0.0434, acc: 0.9761  

epoch: 261 avg_loss: 0.0184, acc: 0.9937 
val --- avg_loss: 0.0433, acc: 0.9809  

epoch: 262 avg_loss: 0.0183, acc: 0.9943 
val --- avg_loss: 0.0420, acc: 0.9761  
update best loss 

epoch: 263 avg_loss: 0.0181, acc: 0.9940 
val --- avg_loss: 0.0426, acc: 0.9761  

epoch: 264 avg_loss: 0.0181, acc: 0.9943 
val --- avg_loss: 0.0443, acc: 0.9809  

epoch: 265 avg_loss: 0.0179, acc: 0.9943 
val --- avg_loss: 0.0426, acc: 0.9761  

epoch: 266 avg_loss: 0.0181, acc: 0.9934 
val --- avg_loss: 0.0404, acc: 0.9856  
update best loss 

epoch: 267 avg_loss: 0.0178, acc: 0.9946 
val --- avg_loss: 0.0435, acc: 0.9809  

epoch: 268 avg_loss: 0.0177, acc: 0.9940 
val --- avg_loss: 0.0414, acc: 0.9809  

epoch: 269 avg_loss: 0.0176, acc: 0.9943 
val --- avg_loss: 0.0415, acc: 0.9761  

epoch: 270 avg_loss: 0.0174, acc: 0.9940 
val --- avg_loss: 0.0412, acc: 0.9809  

epoch: 271 avg_loss: 0.0175, acc: 0.9943 
val --- avg_loss: 0.0439, acc: 0.9761  

epoch: 272 avg_loss: 0.0173, acc: 0.9951 
val --- avg_loss: 0.0441, acc: 0.9809  

epoch: 273 avg_loss: 0.0172, acc: 0.9951 
val --- avg_loss: 0.0428, acc: 0.9761  

epoch: 274 avg_loss: 0.0172, acc: 0.9946 
val --- avg_loss: 0.0421, acc: 0.9761  

epoch: 275 avg_loss: 0.0170, acc: 0.9948 
val --- avg_loss: 0.0429, acc: 0.9761  

epoch: 276 avg_loss: 0.0169, acc: 0.9948 
val --- avg_loss: 0.0412, acc: 0.9809  

epoch: 277 avg_loss: 0.0169, acc: 0.9946 
val --- avg_loss: 0.0427, acc: 0.9761  

epoch: 278 avg_loss: 0.0167, acc: 0.9951 
val --- avg_loss: 0.0411, acc: 0.9809  

epoch: 279 avg_loss: 0.0168, acc: 0.9951 
val --- avg_loss: 0.0410, acc: 0.9809  

epoch: 280 avg_loss: 0.0166, acc: 0.9946 
val --- avg_loss: 0.0413, acc: 0.9761  

epoch: 281 avg_loss: 0.0165, acc: 0.9951 
val --- avg_loss: 0.0427, acc: 0.9761  

epoch: 282 avg_loss: 0.0167, acc: 0.9948 
val --- avg_loss: 0.0404, acc: 0.9856  
update best loss 

epoch: 283 avg_loss: 0.0163, acc: 0.9948 
val --- avg_loss: 0.0434, acc: 0.9761  

epoch: 284 avg_loss: 0.0162, acc: 0.9951 
val --- avg_loss: 0.0418, acc: 0.9761  

epoch: 285 avg_loss: 0.0162, acc: 0.9951 
val --- avg_loss: 0.0420, acc: 0.9809  

epoch: 286 avg_loss: 0.0160, acc: 0.9951 
val --- avg_loss: 0.0415, acc: 0.9761  

epoch: 287 avg_loss: 0.0160, acc: 0.9948 
val --- avg_loss: 0.0402, acc: 0.9809  
update best loss 

epoch: 288 avg_loss: 0.0159, acc: 0.9951 
val --- avg_loss: 0.0422, acc: 0.9761  

epoch: 289 avg_loss: 0.0160, acc: 0.9951 
val --- avg_loss: 0.0424, acc: 0.9761  

epoch: 290 avg_loss: 0.0158, acc: 0.9951 
val --- avg_loss: 0.0389, acc: 0.9856  
update best loss 

epoch: 291 avg_loss: 0.0156, acc: 0.9951 
val --- avg_loss: 0.0423, acc: 0.9761  

epoch: 292 avg_loss: 0.0157, acc: 0.9954 
val --- avg_loss: 0.0444, acc: 0.9761  

epoch: 293 avg_loss: 0.0154, acc: 0.9954 
val --- avg_loss: 0.0402, acc: 0.9809  

epoch: 294 avg_loss: 0.0154, acc: 0.9951 
val --- avg_loss: 0.0400, acc: 0.9809  

epoch: 295 avg_loss: 0.0153, acc: 0.9954 
val --- avg_loss: 0.0420, acc: 0.9761  

epoch: 296 avg_loss: 0.0152, acc: 0.9954 
val --- avg_loss: 0.0415, acc: 0.9761  

epoch: 297 avg_loss: 0.0152, acc: 0.9951 
val --- avg_loss: 0.0400, acc: 0.9809  

epoch: 298 avg_loss: 0.0152, acc: 0.9954 
val --- avg_loss: 0.0416, acc: 0.9761  

epoch: 299 avg_loss: 0.0150, acc: 0.9954 
val --- avg_loss: 0.0405, acc: 0.9761  
