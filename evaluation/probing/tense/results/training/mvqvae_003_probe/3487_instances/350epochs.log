
number of params: 3072 
Namespace(batchsize=128, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=350, fig_path='evaluation/probing/tense/results/training/mvqvae_003_probe/3487_instances/350epochs.png', log_path='evaluation/probing/tense/results/training/mvqvae_003_probe/3487_instances/350epochs.log', logger=<common.utils.Logger object at 0x7efcc81137d0>, lr=0.01, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='mvqvae_003_probe', model=VQVAE_Probe(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_2): Linear(in_features=512, out_features=512, bias=False)
  (linear_3): Linear(in_features=512, out_features=512, bias=False)
  (linear_4): Linear(in_features=512, out_features=512, bias=False)
  (vq_layer): VectorQuantizer(
    (embedding): Embedding(710, 512)
  )
  (vq_layer_2): VectorQuantizer(
    (embedding): Embedding(5, 512)
  )
  (vq_layer_3): VectorQuantizer(
    (embedding): Embedding(6, 512)
  )
  (vq_layer_4): VectorQuantizer(
    (embedding): Embedding(2, 512)
  )
  (linear): Linear(in_features=512, out_features=6, bias=False)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/tense/results/training/mvqvae_003_probe/3487_instances/', nh=512, ni=256, num_embeddings=710, nz=512, opt='Adam', pretrained_model=VQVAE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (vq_layer): VectorQuantizer(
    (embedding): Embedding(710, 512)
  )
  (linear_2): Linear(in_features=512, out_features=512, bias=False)
  (linear_3): Linear(in_features=512, out_features=512, bias=False)
  (linear_4): Linear(in_features=512, out_features=512, bias=False)
  (vq_layer_2): VectorQuantizer(
    (embedding): Embedding(5, 512)
  )
  (vq_layer_3): VectorQuantizer(
    (embedding): Embedding(6, 512)
  )
  (vq_layer_4): VectorQuantizer(
    (embedding): Embedding(2, 512)
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(32, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=32, bias=False)
    (loss): CrossEntropyLoss()
  )
), save_path='evaluation/probing/tense/results/training/mvqvae_003_probe/3487_instances/350epochs.pt', seq_to_no_pad='surface', task='surf2tense', trndata='evaluation/probing/tense/data/sosimple.new.trn.combined.txt', trnsize=3487, tstdata='evaluation/probing/tense/data/sosimple.new.seenroots.val.txt', tstsize=209, valdata='evaluation/probing/tense/data/sosimple.new.seenroots.val.txt', valsize=209)

encoder.embed.weight, torch.Size([32, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
linear_2.weight, torch.Size([512, 512]): False
linear_3.weight, torch.Size([512, 512]): False
linear_4.weight, torch.Size([512, 512]): False
vq_layer.embedding.weight, torch.Size([710, 512]): False
vq_layer_2.embedding.weight, torch.Size([5, 512]): False
vq_layer_3.embedding.weight, torch.Size([6, 512]): False
vq_layer_4.embedding.weight, torch.Size([2, 512]): False
linear.weight, torch.Size([6, 512]): True
epoch: 0 avg_loss: 1.6182, acc: 0.4348 

epoch: 1 avg_loss: 1.5298, acc: 0.4763 

epoch: 2 avg_loss: 1.5645, acc: 0.4130 

epoch: 3 avg_loss: 1.7317, acc: 0.3209 

epoch: 4 avg_loss: 1.4327, acc: 0.4147 

epoch: 5 avg_loss: 1.5497, acc: 0.3937 

epoch: 6 avg_loss: 1.5154, acc: 0.3946 

epoch: 7 avg_loss: 1.7010, acc: 0.4474 

epoch: 8 avg_loss: 1.7451, acc: 0.4574 

epoch: 9 avg_loss: 1.6332, acc: 0.3972 

epoch: 10 avg_loss: 1.5819, acc: 0.3034 

epoch: 11 avg_loss: 1.5640, acc: 0.4419 

epoch: 12 avg_loss: 1.6357, acc: 0.3966 

epoch: 13 avg_loss: 1.6060, acc: 0.4176 

epoch: 14 avg_loss: 1.4921, acc: 0.4497 

epoch: 15 avg_loss: 1.5754, acc: 0.3774 

epoch: 16 avg_loss: 1.7657, acc: 0.3874 

epoch: 17 avg_loss: 1.7014, acc: 0.3995 

epoch: 18 avg_loss: 1.6525, acc: 0.4064 

epoch: 19 avg_loss: 1.7680, acc: 0.4299 

epoch: 20 avg_loss: 1.4887, acc: 0.3662 

epoch: 21 avg_loss: 1.6728, acc: 0.4543 

epoch: 22 avg_loss: 1.4380, acc: 0.4557 

epoch: 23 avg_loss: 1.6232, acc: 0.3740 

epoch: 24 avg_loss: 1.6383, acc: 0.4629 

epoch: 25 avg_loss: 1.6696, acc: 0.4749 

epoch: 26 avg_loss: 1.7712, acc: 0.4110 

epoch: 27 avg_loss: 1.4454, acc: 0.3877 

epoch: 28 avg_loss: 1.5124, acc: 0.3823 

epoch: 29 avg_loss: 1.6925, acc: 0.3387 

epoch: 30 avg_loss: 1.6239, acc: 0.3754 

epoch: 31 avg_loss: 1.6482, acc: 0.4127 

epoch: 32 avg_loss: 1.5819, acc: 0.3768 

epoch: 33 avg_loss: 1.5657, acc: 0.4104 

epoch: 34 avg_loss: 1.7379, acc: 0.3350 

epoch: 35 avg_loss: 1.7605, acc: 0.3424 

epoch: 36 avg_loss: 1.6729, acc: 0.4256 

epoch: 37 avg_loss: 1.5015, acc: 0.4012 

epoch: 38 avg_loss: 1.6558, acc: 0.3857 

epoch: 39 avg_loss: 1.5114, acc: 0.4092 

epoch: 40 avg_loss: 1.6407, acc: 0.4924 

epoch: 41 avg_loss: 1.5771, acc: 0.4738 

epoch: 42 avg_loss: 1.7027, acc: 0.3866 

epoch: 43 avg_loss: 1.5495, acc: 0.3915 

epoch: 44 avg_loss: 1.5980, acc: 0.3527 

epoch: 45 avg_loss: 1.5981, acc: 0.4046 

epoch: 46 avg_loss: 1.5241, acc: 0.3917 

epoch: 47 avg_loss: 1.6075, acc: 0.3720 

epoch: 48 avg_loss: 1.5807, acc: 0.3952 

epoch: 49 avg_loss: 1.5130, acc: 0.4055 

epoch: 50 avg_loss: 1.7477, acc: 0.4399 

epoch: 51 avg_loss: 1.7785, acc: 0.4247 

epoch: 52 avg_loss: 1.6777, acc: 0.3602 

epoch: 53 avg_loss: 1.8213, acc: 0.3972 

epoch: 54 avg_loss: 1.7598, acc: 0.3223 

epoch: 55 avg_loss: 1.7364, acc: 0.4084 

epoch: 56 avg_loss: 1.7867, acc: 0.4221 

epoch: 57 avg_loss: 1.5263, acc: 0.3553 

epoch: 58 avg_loss: 1.7953, acc: 0.3504 

epoch: 59 avg_loss: 1.6515, acc: 0.4155 

epoch: 60 avg_loss: 1.6215, acc: 0.4442 

epoch: 61 avg_loss: 1.5081, acc: 0.4213 

epoch: 62 avg_loss: 1.5946, acc: 0.3917 

epoch: 63 avg_loss: 1.5998, acc: 0.4385 

epoch: 64 avg_loss: 1.5271, acc: 0.4391 

epoch: 65 avg_loss: 1.8628, acc: 0.4141 

epoch: 66 avg_loss: 1.7436, acc: 0.3872 

epoch: 67 avg_loss: 1.7065, acc: 0.4201 

epoch: 68 avg_loss: 1.5905, acc: 0.3900 

epoch: 69 avg_loss: 1.8740, acc: 0.3593 

epoch: 70 avg_loss: 1.5650, acc: 0.4511 

epoch: 71 avg_loss: 1.6321, acc: 0.3456 

epoch: 72 avg_loss: 1.7492, acc: 0.4348 

epoch: 73 avg_loss: 1.6089, acc: 0.3894 

epoch: 74 avg_loss: 1.5567, acc: 0.4296 

epoch: 75 avg_loss: 1.5962, acc: 0.4190 

epoch: 76 avg_loss: 1.4295, acc: 0.4089 

epoch: 77 avg_loss: 1.6911, acc: 0.3915 

epoch: 78 avg_loss: 1.4074, acc: 0.4155 

epoch: 79 avg_loss: 1.7183, acc: 0.4193 

epoch: 80 avg_loss: 1.5236, acc: 0.4391 

epoch: 81 avg_loss: 1.7563, acc: 0.4138 

epoch: 82 avg_loss: 1.5570, acc: 0.4339 

epoch: 83 avg_loss: 1.5486, acc: 0.3631 

epoch: 84 avg_loss: 1.8708, acc: 0.3438 

epoch: 85 avg_loss: 1.5490, acc: 0.4330 

epoch: 86 avg_loss: 1.6356, acc: 0.3542 

epoch: 87 avg_loss: 1.8409, acc: 0.4325 

epoch: 88 avg_loss: 1.6780, acc: 0.4029 

epoch: 89 avg_loss: 1.5759, acc: 0.3714 

epoch: 90 avg_loss: 1.5930, acc: 0.3872 

epoch: 91 avg_loss: 1.7040, acc: 0.4247 

epoch: 92 avg_loss: 1.5419, acc: 0.4204 

epoch: 93 avg_loss: 1.6693, acc: 0.3946 

epoch: 94 avg_loss: 1.7641, acc: 0.4230 

epoch: 95 avg_loss: 1.5477, acc: 0.3665 

epoch: 96 avg_loss: 1.6087, acc: 0.4284 

epoch: 97 avg_loss: 1.4559, acc: 0.4170 

epoch: 98 avg_loss: 1.5417, acc: 0.4219 

epoch: 99 avg_loss: 1.7904, acc: 0.3697 

epoch: 100 avg_loss: 1.9107, acc: 0.3341 

epoch: 101 avg_loss: 1.4948, acc: 0.3808 

epoch: 102 avg_loss: 1.8698, acc: 0.3777 

epoch: 103 avg_loss: 1.8734, acc: 0.4058 

epoch: 104 avg_loss: 1.7292, acc: 0.3568 

epoch: 105 avg_loss: 1.6172, acc: 0.4075 

epoch: 106 avg_loss: 1.5367, acc: 0.4457 

epoch: 107 avg_loss: 1.5687, acc: 0.3665 

epoch: 108 avg_loss: 1.5275, acc: 0.3909 

epoch: 109 avg_loss: 1.5400, acc: 0.3785 

epoch: 110 avg_loss: 1.5344, acc: 0.3897 

epoch: 111 avg_loss: 1.4949, acc: 0.4511 

epoch: 112 avg_loss: 1.4718, acc: 0.3889 

epoch: 113 avg_loss: 1.5974, acc: 0.4213 

epoch: 114 avg_loss: 1.6873, acc: 0.3952 

epoch: 115 avg_loss: 1.6255, acc: 0.3573 

epoch: 116 avg_loss: 1.5026, acc: 0.4482 

epoch: 117 avg_loss: 1.6405, acc: 0.3545 

epoch: 118 avg_loss: 1.5036, acc: 0.4302 

epoch: 119 avg_loss: 1.5238, acc: 0.3656 

epoch: 120 avg_loss: 1.4669, acc: 0.4276 

epoch: 121 avg_loss: 1.5223, acc: 0.4566 

epoch: 122 avg_loss: 1.8721, acc: 0.4439 

epoch: 123 avg_loss: 1.5034, acc: 0.4046 

epoch: 124 avg_loss: 1.4398, acc: 0.4451 

epoch: 125 avg_loss: 1.5167, acc: 0.3788 

epoch: 126 avg_loss: 1.6241, acc: 0.4170 

epoch: 127 avg_loss: 1.7662, acc: 0.3851 

epoch: 128 avg_loss: 1.6095, acc: 0.3582 

epoch: 129 avg_loss: 1.5205, acc: 0.4262 

epoch: 130 avg_loss: 1.6902, acc: 0.4147 

epoch: 131 avg_loss: 1.6197, acc: 0.3963 

epoch: 132 avg_loss: 1.7147, acc: 0.4230 

epoch: 133 avg_loss: 1.5556, acc: 0.4161 

epoch: 134 avg_loss: 1.6042, acc: 0.4147 

epoch: 135 avg_loss: 1.5075, acc: 0.4305 

epoch: 136 avg_loss: 1.5781, acc: 0.4270 

epoch: 137 avg_loss: 1.4791, acc: 0.3373 

epoch: 138 avg_loss: 1.4857, acc: 0.3952 

epoch: 139 avg_loss: 1.6637, acc: 0.3909 

epoch: 140 avg_loss: 1.7033, acc: 0.3705 

epoch: 141 avg_loss: 1.7250, acc: 0.3628 

epoch: 142 avg_loss: 1.5165, acc: 0.4434 

epoch: 143 avg_loss: 1.5966, acc: 0.3917 

epoch: 144 avg_loss: 1.4812, acc: 0.4305 

epoch: 145 avg_loss: 1.5665, acc: 0.3364 

epoch: 146 avg_loss: 1.8439, acc: 0.3685 

epoch: 147 avg_loss: 1.7442, acc: 0.3054 

epoch: 148 avg_loss: 1.5854, acc: 0.3751 

epoch: 149 avg_loss: 1.8492, acc: 0.3579 

epoch: 150 avg_loss: 1.7894, acc: 0.4201 

epoch: 151 avg_loss: 1.7986, acc: 0.3674 

epoch: 152 avg_loss: 1.4030, acc: 0.4282 

epoch: 153 avg_loss: 1.4846, acc: 0.4921 

epoch: 154 avg_loss: 1.5382, acc: 0.4029 

epoch: 155 avg_loss: 1.4238, acc: 0.3734 

epoch: 156 avg_loss: 1.6263, acc: 0.3751 

epoch: 157 avg_loss: 1.5032, acc: 0.4244 

epoch: 158 avg_loss: 1.4330, acc: 0.4560 

epoch: 159 avg_loss: 1.9058, acc: 0.3654 

epoch: 160 avg_loss: 1.6051, acc: 0.3109 

epoch: 161 avg_loss: 1.6247, acc: 0.3872 

epoch: 162 avg_loss: 1.7359, acc: 0.4368 

epoch: 163 avg_loss: 1.7997, acc: 0.4069 

epoch: 164 avg_loss: 1.6551, acc: 0.3840 

epoch: 165 avg_loss: 1.8511, acc: 0.3935 

epoch: 166 avg_loss: 1.8794, acc: 0.3507 

epoch: 167 avg_loss: 1.8232, acc: 0.4293 

epoch: 168 avg_loss: 1.6288, acc: 0.3619 

epoch: 169 avg_loss: 1.5175, acc: 0.3969 

epoch: 170 avg_loss: 1.5476, acc: 0.3811 

epoch: 171 avg_loss: 1.6837, acc: 0.4118 

epoch: 172 avg_loss: 1.4682, acc: 0.4881 

epoch: 173 avg_loss: 1.5063, acc: 0.4505 

epoch: 174 avg_loss: 1.6167, acc: 0.3421 

epoch: 175 avg_loss: 1.5629, acc: 0.4176 

epoch: 176 avg_loss: 1.5538, acc: 0.3846 

epoch: 177 avg_loss: 1.4692, acc: 0.4359 

epoch: 178 avg_loss: 1.6073, acc: 0.3499 

epoch: 179 avg_loss: 1.7958, acc: 0.4798 

epoch: 180 avg_loss: 1.8071, acc: 0.3209 

epoch: 181 avg_loss: 1.5285, acc: 0.3754 

epoch: 182 avg_loss: 1.4985, acc: 0.3897 

epoch: 183 avg_loss: 1.6021, acc: 0.4184 

epoch: 184 avg_loss: 1.4698, acc: 0.3829 

epoch: 185 avg_loss: 1.5177, acc: 0.4219 

epoch: 186 avg_loss: 1.8096, acc: 0.4178 

epoch: 187 avg_loss: 1.6651, acc: 0.3651 

epoch: 188 avg_loss: 1.5316, acc: 0.3880 

epoch: 189 avg_loss: 1.5305, acc: 0.4388 

epoch: 190 avg_loss: 1.5216, acc: 0.3421 

epoch: 191 avg_loss: 1.4214, acc: 0.3869 

epoch: 192 avg_loss: 1.6956, acc: 0.3777 

epoch: 193 avg_loss: 1.5223, acc: 0.4132 

epoch: 194 avg_loss: 1.6075, acc: 0.4348 

epoch: 195 avg_loss: 1.4914, acc: 0.3361 

epoch: 196 avg_loss: 1.9459, acc: 0.4084 

epoch: 197 avg_loss: 1.7029, acc: 0.3811 

epoch: 198 avg_loss: 1.6518, acc: 0.3894 

epoch: 199 avg_loss: 1.6719, acc: 0.4497 

epoch: 200 avg_loss: 1.4864, acc: 0.4677 

epoch: 201 avg_loss: 1.8919, acc: 0.3972 

epoch: 202 avg_loss: 1.6120, acc: 0.3642 

epoch: 203 avg_loss: 1.5436, acc: 0.3860 

epoch: 204 avg_loss: 1.6490, acc: 0.3986 

epoch: 205 avg_loss: 1.7155, acc: 0.4150 

epoch: 206 avg_loss: 1.6022, acc: 0.4514 

epoch: 207 avg_loss: 1.5657, acc: 0.4101 

epoch: 208 avg_loss: 1.5065, acc: 0.3794 

epoch: 209 avg_loss: 1.6241, acc: 0.4210 

epoch: 210 avg_loss: 1.7829, acc: 0.3679 

epoch: 211 avg_loss: 1.6698, acc: 0.3682 

epoch: 212 avg_loss: 1.6579, acc: 0.4095 

epoch: 213 avg_loss: 1.4699, acc: 0.4313 

epoch: 214 avg_loss: 1.4519, acc: 0.4078 

epoch: 215 avg_loss: 1.6008, acc: 0.4388 

epoch: 216 avg_loss: 1.7120, acc: 0.3708 

epoch: 217 avg_loss: 1.5561, acc: 0.3877 

epoch: 218 avg_loss: 1.4972, acc: 0.3980 

epoch: 219 avg_loss: 1.4371, acc: 0.4224 

epoch: 220 avg_loss: 1.5822, acc: 0.3943 

epoch: 221 avg_loss: 1.6272, acc: 0.4118 

epoch: 222 avg_loss: 1.8388, acc: 0.3516 

epoch: 223 avg_loss: 1.8916, acc: 0.4038 

epoch: 224 avg_loss: 1.5201, acc: 0.3998 

epoch: 225 avg_loss: 1.5041, acc: 0.3814 

epoch: 226 avg_loss: 1.5608, acc: 0.4078 

epoch: 227 avg_loss: 1.7481, acc: 0.3659 

epoch: 228 avg_loss: 1.6438, acc: 0.4141 

epoch: 229 avg_loss: 1.7628, acc: 0.3648 

epoch: 230 avg_loss: 1.5437, acc: 0.4428 

epoch: 231 avg_loss: 1.4858, acc: 0.4508 

epoch: 232 avg_loss: 1.5193, acc: 0.3728 

epoch: 233 avg_loss: 1.5637, acc: 0.3436 

epoch: 234 avg_loss: 1.6536, acc: 0.3894 

epoch: 235 avg_loss: 1.6466, acc: 0.4055 

epoch: 236 avg_loss: 1.7933, acc: 0.3863 

epoch: 237 avg_loss: 1.6155, acc: 0.3780 

epoch: 238 avg_loss: 1.8489, acc: 0.4061 

epoch: 239 avg_loss: 1.6763, acc: 0.3711 

epoch: 240 avg_loss: 1.6242, acc: 0.4511 

epoch: 241 avg_loss: 1.7361, acc: 0.3935 

epoch: 242 avg_loss: 1.7038, acc: 0.4204 

epoch: 243 avg_loss: 1.6544, acc: 0.3791 

epoch: 244 avg_loss: 1.8218, acc: 0.3955 

epoch: 245 avg_loss: 1.5930, acc: 0.3843 

epoch: 246 avg_loss: 1.6689, acc: 0.4236 

epoch: 247 avg_loss: 1.6264, acc: 0.3877 

epoch: 248 avg_loss: 1.4193, acc: 0.4517 

epoch: 249 avg_loss: 1.5020, acc: 0.3484 

epoch: 250 avg_loss: 1.5965, acc: 0.4087 

epoch: 251 avg_loss: 1.5506, acc: 0.3298 

epoch: 252 avg_loss: 1.5620, acc: 0.4046 

epoch: 253 avg_loss: 1.8116, acc: 0.4276 

epoch: 254 avg_loss: 1.5634, acc: 0.3593 

epoch: 255 avg_loss: 1.3780, acc: 0.4253 

epoch: 256 avg_loss: 1.6032, acc: 0.3949 

epoch: 257 avg_loss: 1.7188, acc: 0.3407 

epoch: 258 avg_loss: 1.5781, acc: 0.4213 

epoch: 259 avg_loss: 1.4732, acc: 0.3943 

epoch: 260 avg_loss: 1.6249, acc: 0.3352 

epoch: 261 avg_loss: 1.5864, acc: 0.3605 

epoch: 262 avg_loss: 1.6814, acc: 0.4551 

epoch: 263 avg_loss: 1.7020, acc: 0.4253 

epoch: 264 avg_loss: 1.5553, acc: 0.4150 

epoch: 265 avg_loss: 1.7289, acc: 0.4061 

epoch: 266 avg_loss: 1.6436, acc: 0.4038 

epoch: 267 avg_loss: 1.5730, acc: 0.4700 

epoch: 268 avg_loss: 1.5281, acc: 0.3992 

epoch: 269 avg_loss: 1.3891, acc: 0.4035 

epoch: 270 avg_loss: 1.5211, acc: 0.4147 

epoch: 271 avg_loss: 1.5095, acc: 0.4689 

epoch: 272 avg_loss: 1.6692, acc: 0.3851 

epoch: 273 avg_loss: 1.5567, acc: 0.4371 

epoch: 274 avg_loss: 1.6207, acc: 0.4284 

epoch: 275 avg_loss: 1.6688, acc: 0.3685 

epoch: 276 avg_loss: 1.5950, acc: 0.4448 

epoch: 277 avg_loss: 1.5892, acc: 0.3777 

epoch: 278 avg_loss: 1.6114, acc: 0.3699 

epoch: 279 avg_loss: 1.6175, acc: 0.4606 

epoch: 280 avg_loss: 1.5158, acc: 0.4465 

epoch: 281 avg_loss: 1.5802, acc: 0.4067 

epoch: 282 avg_loss: 1.5193, acc: 0.4089 

epoch: 283 avg_loss: 1.5725, acc: 0.3840 

epoch: 284 avg_loss: 1.5728, acc: 0.3783 

epoch: 285 avg_loss: 1.5030, acc: 0.4411 

epoch: 286 avg_loss: 1.5462, acc: 0.4330 

epoch: 287 avg_loss: 1.5022, acc: 0.3568 

epoch: 288 avg_loss: 1.5538, acc: 0.3823 

epoch: 289 avg_loss: 1.6470, acc: 0.4150 

epoch: 290 avg_loss: 1.5128, acc: 0.4207 

epoch: 291 avg_loss: 1.6135, acc: 0.3923 

epoch: 292 avg_loss: 1.6789, acc: 0.3570 

epoch: 293 avg_loss: 1.6146, acc: 0.3579 

epoch: 294 avg_loss: 1.7018, acc: 0.4359 

epoch: 295 avg_loss: 1.6379, acc: 0.3937 

epoch: 296 avg_loss: 1.4927, acc: 0.3714 

epoch: 297 avg_loss: 1.5398, acc: 0.4571 

epoch: 298 avg_loss: 1.4409, acc: 0.4342 

epoch: 299 avg_loss: 1.6618, acc: 0.3694 

epoch: 300 avg_loss: 1.6223, acc: 0.3550 

epoch: 301 avg_loss: 1.7673, acc: 0.4196 

epoch: 302 avg_loss: 1.5737, acc: 0.4436 

epoch: 303 avg_loss: 1.5932, acc: 0.3702 

epoch: 304 avg_loss: 1.6866, acc: 0.4184 

epoch: 305 avg_loss: 1.7066, acc: 0.3613 

epoch: 306 avg_loss: 1.8789, acc: 0.3688 

epoch: 307 avg_loss: 1.5373, acc: 0.3863 

epoch: 308 avg_loss: 1.5816, acc: 0.4081 

epoch: 309 avg_loss: 1.6048, acc: 0.3900 

epoch: 310 avg_loss: 1.6352, acc: 0.3811 

epoch: 311 avg_loss: 1.6877, acc: 0.3998 

epoch: 312 avg_loss: 1.5965, acc: 0.3355 

epoch: 313 avg_loss: 1.5603, acc: 0.3969 

epoch: 314 avg_loss: 1.6331, acc: 0.3946 

epoch: 315 avg_loss: 1.5736, acc: 0.4216 

epoch: 316 avg_loss: 1.5704, acc: 0.4207 

epoch: 317 avg_loss: 1.7174, acc: 0.4224 

epoch: 318 avg_loss: 1.9860, acc: 0.3631 

epoch: 319 avg_loss: 1.6030, acc: 0.3734 

epoch: 320 avg_loss: 1.5138, acc: 0.3972 

epoch: 321 avg_loss: 1.6577, acc: 0.4485 

epoch: 322 avg_loss: 1.9673, acc: 0.4015 

epoch: 323 avg_loss: 1.5861, acc: 0.4256 

epoch: 324 avg_loss: 1.8053, acc: 0.4170 

epoch: 325 avg_loss: 1.4596, acc: 0.4528 

epoch: 326 avg_loss: 1.7635, acc: 0.3547 

epoch: 327 avg_loss: 1.5153, acc: 0.4319 

epoch: 328 avg_loss: 1.5276, acc: 0.4307 

epoch: 329 avg_loss: 1.6036, acc: 0.4273 

epoch: 330 avg_loss: 1.5844, acc: 0.3599 

epoch: 331 avg_loss: 1.6174, acc: 0.4170 

epoch: 332 avg_loss: 1.5980, acc: 0.4118 

epoch: 333 avg_loss: 1.6510, acc: 0.3436 

epoch: 334 avg_loss: 1.5073, acc: 0.3998 

epoch: 335 avg_loss: 1.5685, acc: 0.4305 

epoch: 336 avg_loss: 1.3951, acc: 0.3883 

epoch: 337 avg_loss: 1.5201, acc: 0.4135 

epoch: 338 avg_loss: 1.6129, acc: 0.4551 

epoch: 339 avg_loss: 1.6056, acc: 0.3562 

epoch: 340 avg_loss: 1.5651, acc: 0.3892 

epoch: 341 avg_loss: 1.6022, acc: 0.4322 

epoch: 342 avg_loss: 1.4221, acc: 0.3989 

epoch: 343 avg_loss: 1.5021, acc: 0.3699 

epoch: 344 avg_loss: 1.5731, acc: 0.3631 

epoch: 345 avg_loss: 1.8263, acc: 0.4164 

epoch: 346 avg_loss: 1.5595, acc: 0.3963 

epoch: 347 avg_loss: 1.4793, acc: 0.4310 

epoch: 348 avg_loss: 1.8340, acc: 0.3103 

epoch: 349 avg_loss: 1.7593, acc: 0.4256 
