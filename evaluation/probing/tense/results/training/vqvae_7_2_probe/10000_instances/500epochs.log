
number of params: 3078 
Namespace(batchsize=128, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=500, fig_path='evaluation/probing/tense/results/training/vqvae_7_2_probe/10000_instances/500epochs.png', log_path='evaluation/probing/tense/results/training/vqvae_7_2_probe/10000_instances/500epochs.log', logger=<common.utils.Logger object at 0x7fa440636110>, lr=0.001, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='vqvae_7_2_probe', model=VQVAE_Probe(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(35, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_root): Linear(in_features=512, out_features=320, bias=True)
  (vq_layer_root): VectorQuantizer(
    (embedding): Embedding(2000, 320)
  )
  (ord_linears): ModuleList(
    (0): Linear(in_features=512, out_features=32, bias=True)
    (1): Linear(in_features=512, out_features=32, bias=True)
    (2): Linear(in_features=512, out_features=32, bias=True)
    (3): Linear(in_features=512, out_features=32, bias=True)
    (4): Linear(in_features=512, out_features=32, bias=True)
    (5): Linear(in_features=512, out_features=32, bias=True)
  )
  (ord_vq_layers): ModuleList(
    (0): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (1): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (2): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (3): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (4): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (5): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
  )
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/tense/results/training/vqvae_7_2_probe/10000_instances/', nh=512, ni=256, num_dicts=7, nz=512, opt='Adam', orddict_emb_num=100, pretrained_model=VQVAE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(35, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_root): Linear(in_features=512, out_features=320, bias=True)
  (vq_layer_root): VectorQuantizer(
    (embedding): Embedding(2000, 320)
  )
  (ord_linears): ModuleList(
    (0): Linear(in_features=512, out_features=32, bias=True)
    (1): Linear(in_features=512, out_features=32, bias=True)
    (2): Linear(in_features=512, out_features=32, bias=True)
    (3): Linear(in_features=512, out_features=32, bias=True)
    (4): Linear(in_features=512, out_features=32, bias=True)
    (5): Linear(in_features=512, out_features=32, bias=True)
  )
  (ord_vq_layers): ModuleList(
    (0): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (1): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (2): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (3): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (4): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (5): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(35, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=35, bias=False)
    (loss): CrossEntropyLoss()
  )
), rootdict_emb_dim=320, rootdict_emb_num=2000, save_path='evaluation/probing/tense/results/training/vqvae_7_2_probe/10000_instances/500epochs.pt', seq_to_no_pad='surface', task='surf2tense', trndata='model/vqvae/data/trmor2018.uniquesurfs.verbs.uniquerooted.trn.txt', trnsize=10000, tstdata='model/vqvae/data/trmor2018.uniquesurfs.verbs.seenroots.val.txt', tstsize=3000, valdata='model/vqvae/data/trmor2018.uniquesurfs.verbs.seenroots.val.txt', valsize=3000)

encoder.embed.weight, torch.Size([35, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
linear_root.weight, torch.Size([320, 512]): False
linear_root.bias, torch.Size([320]): False
vq_layer_root.embedding.weight, torch.Size([2000, 320]): False
ord_linears.0.weight, torch.Size([32, 512]): False
ord_linears.0.bias, torch.Size([32]): False
ord_linears.1.weight, torch.Size([32, 512]): False
ord_linears.1.bias, torch.Size([32]): False
ord_linears.2.weight, torch.Size([32, 512]): False
ord_linears.2.bias, torch.Size([32]): False
ord_linears.3.weight, torch.Size([32, 512]): False
ord_linears.3.bias, torch.Size([32]): False
ord_linears.4.weight, torch.Size([32, 512]): False
ord_linears.4.bias, torch.Size([32]): False
ord_linears.5.weight, torch.Size([32, 512]): False
ord_linears.5.bias, torch.Size([32]): False
ord_vq_layers.0.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.1.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.2.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.3.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.4.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.5.embedding.weight, torch.Size([100, 32]): False
linear.weight, torch.Size([6, 512]): True
linear.bias, torch.Size([6]): True
epoch: 0 avg_loss: 1.1431, acc: 0.5702 
val --- avg_loss: 0.9545, acc: 0.6717  
update best loss 

epoch: 1 avg_loss: 0.7712, acc: 0.7323 
val --- avg_loss: 0.8293, acc: 0.7110  
update best loss 

epoch: 2 avg_loss: 0.6899, acc: 0.7555 
val --- avg_loss: 0.7613, acc: 0.7310  
update best loss 

epoch: 3 avg_loss: 0.6515, acc: 0.7663 
val --- avg_loss: 0.7952, acc: 0.7197  

epoch: 4 avg_loss: 0.6304, acc: 0.7693 
val --- avg_loss: 0.7439, acc: 0.7337  
update best loss 

epoch: 5 avg_loss: 0.6139, acc: 0.7730 
val --- avg_loss: 0.7321, acc: 0.7323  
update best loss 

epoch: 6 avg_loss: 0.6011, acc: 0.7744 
val --- avg_loss: 0.7520, acc: 0.7387  

epoch: 7 avg_loss: 0.5924, acc: 0.7806 
