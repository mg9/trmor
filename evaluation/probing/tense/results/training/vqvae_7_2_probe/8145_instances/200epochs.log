
number of params: 3078 
Namespace(batchsize=128, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=200, fig_path='evaluation/probing/tense/results/training/vqvae_7_2_probe/8145_instances/200epochs.png', log_path='evaluation/probing/tense/results/training/vqvae_7_2_probe/8145_instances/200epochs.log', logger=<common.utils.Logger object at 0x7f37c9bc9f10>, lr=0.001, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='vqvae_7_2_probe', model=VQVAE_Probe(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(35, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_root): Linear(in_features=512, out_features=320, bias=True)
  (vq_layer_root): VectorQuantizer(
    (embedding): Embedding(2000, 320)
  )
  (ord_linears): ModuleList(
    (0): Linear(in_features=512, out_features=32, bias=True)
    (1): Linear(in_features=512, out_features=32, bias=True)
    (2): Linear(in_features=512, out_features=32, bias=True)
    (3): Linear(in_features=512, out_features=32, bias=True)
    (4): Linear(in_features=512, out_features=32, bias=True)
    (5): Linear(in_features=512, out_features=32, bias=True)
  )
  (ord_vq_layers): ModuleList(
    (0): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (1): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (2): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (3): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (4): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (5): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
  )
  (linear): Linear(in_features=512, out_features=6, bias=True)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/tense/results/training/vqvae_7_2_probe/8145_instances/', nh=512, ni=256, num_dicts=7, nz=512, opt='Adam', orddict_emb_num=100, pretrained_model=VQVAE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(35, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_root): Linear(in_features=512, out_features=320, bias=True)
  (vq_layer_root): VectorQuantizer(
    (embedding): Embedding(2000, 320)
  )
  (ord_linears): ModuleList(
    (0): Linear(in_features=512, out_features=32, bias=True)
    (1): Linear(in_features=512, out_features=32, bias=True)
    (2): Linear(in_features=512, out_features=32, bias=True)
    (3): Linear(in_features=512, out_features=32, bias=True)
    (4): Linear(in_features=512, out_features=32, bias=True)
    (5): Linear(in_features=512, out_features=32, bias=True)
  )
  (ord_vq_layers): ModuleList(
    (0): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (1): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (2): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (3): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (4): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
    (5): VectorQuantizer(
      (embedding): Embedding(100, 32)
    )
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(35, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=35, bias=False)
    (loss): CrossEntropyLoss()
  )
), rootdict_emb_dim=320, rootdict_emb_num=2000, save_path='evaluation/probing/tense/results/training/vqvae_7_2_probe/8145_instances/200epochs.pt', seq_to_no_pad='surface', task='surf2tense', trndata='model/vqvae/data/trmor2018.uniquesurfs.verbs.uniquerooted.trn.txt', trnsize=8145, tstdata='model/vqvae/data/trmor2018.uniquesurfs.verbs.seenroots.val.txt', tstsize=2412, valdata='model/vqvae/data/trmor2018.uniquesurfs.verbs.seenroots.val.txt', valsize=2412)

encoder.embed.weight, torch.Size([35, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
linear_root.weight, torch.Size([320, 512]): False
linear_root.bias, torch.Size([320]): False
vq_layer_root.embedding.weight, torch.Size([2000, 320]): False
ord_linears.0.weight, torch.Size([32, 512]): False
ord_linears.0.bias, torch.Size([32]): False
ord_linears.1.weight, torch.Size([32, 512]): False
ord_linears.1.bias, torch.Size([32]): False
ord_linears.2.weight, torch.Size([32, 512]): False
ord_linears.2.bias, torch.Size([32]): False
ord_linears.3.weight, torch.Size([32, 512]): False
ord_linears.3.bias, torch.Size([32]): False
ord_linears.4.weight, torch.Size([32, 512]): False
ord_linears.4.bias, torch.Size([32]): False
ord_linears.5.weight, torch.Size([32, 512]): False
ord_linears.5.bias, torch.Size([32]): False
ord_vq_layers.0.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.1.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.2.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.3.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.4.embedding.weight, torch.Size([100, 32]): False
ord_vq_layers.5.embedding.weight, torch.Size([100, 32]): False
linear.weight, torch.Size([6, 512]): True
linear.bias, torch.Size([6]): True
epoch: 0 avg_loss: 0.8986, acc: 0.6835 
val --- avg_loss: 0.6653, acc: 0.7927  
update best loss 

epoch: 1 avg_loss: 0.4950, acc: 0.8447 
val --- avg_loss: 0.5665, acc: 0.8155  
update best loss 

epoch: 2 avg_loss: 0.4082, acc: 0.8641 
val --- avg_loss: 0.4992, acc: 0.8400  
update best loss 

epoch: 3 avg_loss: 0.3697, acc: 0.8735 
val --- avg_loss: 0.4541, acc: 0.8512  
update best loss 

epoch: 4 avg_loss: 0.3454, acc: 0.8776 
val --- avg_loss: 0.4330, acc: 0.8599  
update best loss 

epoch: 5 avg_loss: 0.3348, acc: 0.8858 
val --- avg_loss: 0.4336, acc: 0.8545  

epoch: 6 avg_loss: 0.3188, acc: 0.8823 
val --- avg_loss: 0.4210, acc: 0.8611  
update best loss 

epoch: 7 avg_loss: 0.3086, acc: 0.8882 
val --- avg_loss: 0.4264, acc: 0.8615  

epoch: 8 avg_loss: 0.3038, acc: 0.8900 
val --- avg_loss: 0.4287, acc: 0.8599  

epoch: 9 avg_loss: 0.2976, acc: 0.8895 
val --- avg_loss: 0.4155, acc: 0.8640  
update best loss 

epoch: 10 avg_loss: 0.2923, acc: 0.8944 
val --- avg_loss: 0.4188, acc: 0.8644  

epoch: 11 avg_loss: 0.2914, acc: 0.8931 
val --- avg_loss: 0.4099, acc: 0.8644  
update best loss 

epoch: 12 avg_loss: 0.2830, acc: 0.8949 
val --- avg_loss: 0.4333, acc: 0.8632  

epoch: 13 avg_loss: 0.2821, acc: 0.8953 
val --- avg_loss: 0.4066, acc: 0.8686  
update best loss 

epoch: 14 avg_loss: 0.2792, acc: 0.8971 
val --- avg_loss: 0.4335, acc: 0.8615  

epoch: 15 avg_loss: 0.2795, acc: 0.8931 
val --- avg_loss: 0.4207, acc: 0.8723  

epoch: 16 avg_loss: 0.2739, acc: 0.8967 
val --- avg_loss: 0.4487, acc: 0.8545  

epoch: 17 avg_loss: 0.2741, acc: 0.8966 
val --- avg_loss: 0.4397, acc: 0.8673  

epoch: 18 avg_loss: 0.2740, acc: 0.8969 
val --- avg_loss: 0.4191, acc: 0.8657  

epoch: 19 avg_loss: 0.2717, acc: 0.8963 
val --- avg_loss: 0.4353, acc: 0.8665  

epoch: 20 avg_loss: 0.2718, acc: 0.8976 
val --- avg_loss: 0.4064, acc: 0.8702  
update best loss 

epoch: 21 avg_loss: 0.2669, acc: 0.8997 
val --- avg_loss: 0.4292, acc: 0.8669  

epoch: 22 avg_loss: 0.2681, acc: 0.9001 
val --- avg_loss: 0.4120, acc: 0.8694  

epoch: 23 avg_loss: 0.2639, acc: 0.9017 
val --- avg_loss: 0.4532, acc: 0.8644  

epoch: 24 avg_loss: 0.2642, acc: 0.9007 
val --- avg_loss: 0.4424, acc: 0.8669  

epoch: 25 avg_loss: 0.2642, acc: 0.8998 
val --- avg_loss: 0.4581, acc: 0.8615  

epoch: 26 avg_loss: 0.2612, acc: 0.9014 
val --- avg_loss: 0.4786, acc: 0.8586  

epoch: 27 avg_loss: 0.2606, acc: 0.8986 
val --- avg_loss: 0.4640, acc: 0.8628  

epoch: 28 avg_loss: 0.2607, acc: 0.8991 
val --- avg_loss: 0.4334, acc: 0.8702  

epoch: 29 avg_loss: 0.2599, acc: 0.9019 
val --- avg_loss: 0.4484, acc: 0.8648  

epoch: 30 avg_loss: 0.2576, acc: 0.9034 
val --- avg_loss: 0.4348, acc: 0.8661  

epoch: 31 avg_loss: 0.2562, acc: 0.9015 
val --- avg_loss: 0.4193, acc: 0.8702  

epoch: 32 avg_loss: 0.2560, acc: 0.9010 
val --- avg_loss: 0.4234, acc: 0.8723  

epoch: 33 avg_loss: 0.2540, acc: 0.9031 
val --- avg_loss: 0.4364, acc: 0.8686  

epoch: 34 avg_loss: 0.2539, acc: 0.9030 
val --- avg_loss: 0.4068, acc: 0.8756  

epoch: 35 avg_loss: 0.2557, acc: 0.9034 
val --- avg_loss: 0.4440, acc: 0.8698  

epoch: 36 avg_loss: 0.2503, acc: 0.9030 
val --- avg_loss: 0.4575, acc: 0.8648  

epoch: 37 avg_loss: 0.2540, acc: 0.9036 
val --- avg_loss: 0.4279, acc: 0.8677  

epoch: 38 avg_loss: 0.2536, acc: 0.9035 
val --- avg_loss: 0.4503, acc: 0.8698  

epoch: 39 avg_loss: 0.2531, acc: 0.9017 
val --- avg_loss: 0.4385, acc: 0.8690  

epoch: 40 avg_loss: 0.2532, acc: 0.9051 
val --- avg_loss: 0.4414, acc: 0.8715  

epoch: 41 avg_loss: 0.2488, acc: 0.9046 
val --- avg_loss: 0.4275, acc: 0.8706  

epoch: 42 avg_loss: 0.2519, acc: 0.9040 
val --- avg_loss: 0.4094, acc: 0.8690  

epoch: 43 avg_loss: 0.2507, acc: 0.9023 
val --- avg_loss: 0.4508, acc: 0.8686  

epoch: 44 avg_loss: 0.2503, acc: 0.9048 
val --- avg_loss: 0.4202, acc: 0.8702  

epoch: 45 avg_loss: 0.2469, acc: 0.9055 
val --- avg_loss: 0.4281, acc: 0.8719  

epoch: 46 avg_loss: 0.2479, acc: 0.9055 
val --- avg_loss: 0.4534, acc: 0.8694  

epoch: 47 avg_loss: 0.2473, acc: 0.9064 
val --- avg_loss: 0.4504, acc: 0.8690  

epoch: 48 avg_loss: 0.2471, acc: 0.9053 
val --- avg_loss: 0.4306, acc: 0.8706  

epoch: 49 avg_loss: 0.2452, acc: 0.9058 
val --- avg_loss: 0.4240, acc: 0.8740  

epoch: 50 avg_loss: 0.2475, acc: 0.9067 
val --- avg_loss: 0.4267, acc: 0.8719  

epoch: 51 avg_loss: 0.2469, acc: 0.9029 
val --- avg_loss: 0.4191, acc: 0.8752  

epoch: 52 avg_loss: 0.2469, acc: 0.9037 
val --- avg_loss: 0.4458, acc: 0.8673  

epoch: 53 avg_loss: 0.2457, acc: 0.9062 
val --- avg_loss: 0.4644, acc: 0.8673  

epoch: 54 avg_loss: 0.2450, acc: 0.9068 
val --- avg_loss: 0.4625, acc: 0.8669  

epoch: 55 avg_loss: 0.2454, acc: 0.9077 
val --- avg_loss: 0.4482, acc: 0.8690  

epoch: 56 avg_loss: 0.2442, acc: 0.9052 
val --- avg_loss: 0.4910, acc: 0.8636  

epoch: 57 avg_loss: 0.2444, acc: 0.9051 
val --- avg_loss: 0.4537, acc: 0.8723  

epoch: 58 avg_loss: 0.2432, acc: 0.9045 
val --- avg_loss: 0.4153, acc: 0.8731  

epoch: 59 avg_loss: 0.2423, acc: 0.9074 
val --- avg_loss: 0.4163, acc: 0.8769  

epoch: 60 avg_loss: 0.2463, acc: 0.9063 
val --- avg_loss: 0.4528, acc: 0.8665  

epoch: 61 avg_loss: 0.2398, acc: 0.9073 
val --- avg_loss: 0.4254, acc: 0.8723  

epoch: 62 avg_loss: 0.2443, acc: 0.9077 
val --- avg_loss: 0.4641, acc: 0.8702  

epoch: 63 avg_loss: 0.2403, acc: 0.9060 
val --- avg_loss: 0.4252, acc: 0.8723  

epoch: 64 avg_loss: 0.2422, acc: 0.9077 
val --- avg_loss: 0.4699, acc: 0.8694  

epoch: 65 avg_loss: 0.2396, acc: 0.9078 
val --- avg_loss: 0.4650, acc: 0.8632  

epoch: 66 avg_loss: 0.2382, acc: 0.9057 
val --- avg_loss: 0.4596, acc: 0.8702  

epoch: 67 avg_loss: 0.2406, acc: 0.9084 
val --- avg_loss: 0.4665, acc: 0.8711  

epoch: 68 avg_loss: 0.2371, acc: 0.9073 
val --- avg_loss: 0.4451, acc: 0.8706  

epoch: 69 avg_loss: 0.2410, acc: 0.9079 
val --- avg_loss: 0.4393, acc: 0.8719  

epoch: 70 avg_loss: 0.2361, acc: 0.9079 
val --- avg_loss: 0.4354, acc: 0.8744  

epoch: 71 avg_loss: 0.2395, acc: 0.9077 
val --- avg_loss: 0.4340, acc: 0.8686  

epoch: 72 avg_loss: 0.2407, acc: 0.9071 
val --- avg_loss: 0.4653, acc: 0.8694  

epoch: 73 avg_loss: 0.2384, acc: 0.9071 
val --- avg_loss: 0.4405, acc: 0.8711  

epoch: 74 avg_loss: 0.2363, acc: 0.9090 
val --- avg_loss: 0.4445, acc: 0.8740  

epoch: 75 avg_loss: 0.2359, acc: 0.9093 
val --- avg_loss: 0.4201, acc: 0.8723  

epoch: 76 avg_loss: 0.2423, acc: 0.9073 
val --- avg_loss: 0.4518, acc: 0.8711  

epoch: 77 avg_loss: 0.2361, acc: 0.9093 
val --- avg_loss: 0.4486, acc: 0.8735  

epoch: 78 avg_loss: 0.2379, acc: 0.9078 
val --- avg_loss: 0.4773, acc: 0.8665  

epoch: 79 avg_loss: 0.2403, acc: 0.9078 
val --- avg_loss: 0.4693, acc: 0.8711  

epoch: 80 avg_loss: 0.2325, acc: 0.9099 
val --- avg_loss: 0.4501, acc: 0.8673  

epoch: 81 avg_loss: 0.2354, acc: 0.9105 
val --- avg_loss: 0.4844, acc: 0.8682  

epoch: 82 avg_loss: 0.2365, acc: 0.9085 
val --- avg_loss: 0.4448, acc: 0.8719  

epoch: 83 avg_loss: 0.2395, acc: 0.9048 
val --- avg_loss: 0.4958, acc: 0.8636  

epoch: 84 avg_loss: 0.2337, acc: 0.9103 
val --- avg_loss: 0.4671, acc: 0.8719  

epoch: 85 avg_loss: 0.2324, acc: 0.9085 
val --- avg_loss: 0.4411, acc: 0.8711  

epoch: 86 avg_loss: 0.2353, acc: 0.9105 
val --- avg_loss: 0.4515, acc: 0.8723  

epoch: 87 avg_loss: 0.2318, acc: 0.9101 
val --- avg_loss: 0.4801, acc: 0.8698  

epoch: 88 avg_loss: 0.2353, acc: 0.9077 
val --- avg_loss: 0.4907, acc: 0.8628  

epoch: 89 avg_loss: 0.2309, acc: 0.9103 
val --- avg_loss: 0.4347, acc: 0.8706  

epoch: 90 avg_loss: 0.2361, acc: 0.9093 
val --- avg_loss: 0.4545, acc: 0.8723  

epoch: 91 avg_loss: 0.2340, acc: 0.9101 
val --- avg_loss: 0.4646, acc: 0.8698  

epoch: 92 avg_loss: 0.2333, acc: 0.9079 
val --- avg_loss: 0.4412, acc: 0.8735  

epoch: 93 avg_loss: 0.2322, acc: 0.9110 
val --- avg_loss: 0.4732, acc: 0.8694  

epoch: 94 avg_loss: 0.2312, acc: 0.9110 
val --- avg_loss: 0.4573, acc: 0.8686  

epoch: 95 avg_loss: 0.2314, acc: 0.9095 
val --- avg_loss: 0.4367, acc: 0.8719  

epoch: 96 avg_loss: 0.2317, acc: 0.9093 
val --- avg_loss: 0.4773, acc: 0.8690  

epoch: 97 avg_loss: 0.2290, acc: 0.9112 
val --- avg_loss: 0.4431, acc: 0.8744  

epoch: 98 avg_loss: 0.2313, acc: 0.9098 
val --- avg_loss: 0.4577, acc: 0.8682  

epoch: 99 avg_loss: 0.2300, acc: 0.9126 
val --- avg_loss: 0.4492, acc: 0.8694  

epoch: 100 avg_loss: 0.2299, acc: 0.9088 
val --- avg_loss: 0.4610, acc: 0.8748  

epoch: 101 avg_loss: 0.2309, acc: 0.9112 
val --- avg_loss: 0.4473, acc: 0.8744  

epoch: 102 avg_loss: 0.2329, acc: 0.9082 
val --- avg_loss: 0.4581, acc: 0.8719  

epoch: 103 avg_loss: 0.2292, acc: 0.9114 
val --- avg_loss: 0.4925, acc: 0.8698  

epoch: 104 avg_loss: 0.2293, acc: 0.9107 
val --- avg_loss: 0.4656, acc: 0.8706  

epoch: 105 avg_loss: 0.2299, acc: 0.9125 
val --- avg_loss: 0.4543, acc: 0.8748  

epoch: 106 avg_loss: 0.2296, acc: 0.9117 
val --- avg_loss: 0.4628, acc: 0.8752  

epoch: 107 avg_loss: 0.2299, acc: 0.9137 
val --- avg_loss: 0.4776, acc: 0.8711  

epoch: 108 avg_loss: 0.2278, acc: 0.9116 
val --- avg_loss: 0.4452, acc: 0.8715  

epoch: 109 avg_loss: 0.2288, acc: 0.9112 
val --- avg_loss: 0.4430, acc: 0.8719  

epoch: 110 avg_loss: 0.2282, acc: 0.9130 
val --- avg_loss: 0.4295, acc: 0.8748  

epoch: 111 avg_loss: 0.2305, acc: 0.9112 
val --- avg_loss: 0.4482, acc: 0.8690  

epoch: 112 avg_loss: 0.2289, acc: 0.9128 
val --- avg_loss: 0.4423, acc: 0.8706  

epoch: 113 avg_loss: 0.2282, acc: 0.9121 
val --- avg_loss: 0.4736, acc: 0.8731  

epoch: 114 avg_loss: 0.2255, acc: 0.9115 
val --- avg_loss: 0.4795, acc: 0.8740  

epoch: 115 avg_loss: 0.2255, acc: 0.9117 
val --- avg_loss: 0.4268, acc: 0.8773  

epoch: 116 avg_loss: 0.2289, acc: 0.9105 
val --- avg_loss: 0.4592, acc: 0.8723  

epoch: 117 avg_loss: 0.2253, acc: 0.9104 
val --- avg_loss: 0.4453, acc: 0.8706  

epoch: 118 avg_loss: 0.2267, acc: 0.9114 
val --- avg_loss: 0.4610, acc: 0.8723  

epoch: 119 avg_loss: 0.2249, acc: 0.9143 
val --- avg_loss: 0.4491, acc: 0.8727  

epoch: 120 avg_loss: 0.2250, acc: 0.9112 
val --- avg_loss: 0.4503, acc: 0.8715  

epoch: 121 avg_loss: 0.2278, acc: 0.9094 
val --- avg_loss: 0.4563, acc: 0.8740  

epoch: 122 avg_loss: 0.2261, acc: 0.9117 
val --- avg_loss: 0.4527, acc: 0.8715  

epoch: 123 avg_loss: 0.2262, acc: 0.9114 
val --- avg_loss: 0.4516, acc: 0.8744  

epoch: 124 avg_loss: 0.2257, acc: 0.9137 
val --- avg_loss: 0.4721, acc: 0.8711  

epoch: 125 avg_loss: 0.2245, acc: 0.9099 
val --- avg_loss: 0.4492, acc: 0.8698  

epoch: 126 avg_loss: 0.2283, acc: 0.9112 
val --- avg_loss: 0.4512, acc: 0.8731  

epoch: 127 avg_loss: 0.2233, acc: 0.9147 
val --- avg_loss: 0.4635, acc: 0.8715  

epoch: 128 avg_loss: 0.2260, acc: 0.9112 
val --- avg_loss: 0.4803, acc: 0.8719  

epoch: 129 avg_loss: 0.2264, acc: 0.9128 
val --- avg_loss: 0.4643, acc: 0.8723  

epoch: 130 avg_loss: 0.2239, acc: 0.9105 
val --- avg_loss: 0.4561, acc: 0.8694  

epoch: 131 avg_loss: 0.2239, acc: 0.9142 
val --- avg_loss: 0.4725, acc: 0.8735  

epoch: 132 avg_loss: 0.2234, acc: 0.9133 
val --- avg_loss: 0.4538, acc: 0.8785  

epoch: 133 avg_loss: 0.2255, acc: 0.9125 
val --- avg_loss: 0.4472, acc: 0.8727  

epoch: 134 avg_loss: 0.2229, acc: 0.9138 
val --- avg_loss: 0.4753, acc: 0.8702  

epoch: 135 avg_loss: 0.2228, acc: 0.9139 
val --- avg_loss: 0.4824, acc: 0.8624  

epoch: 136 avg_loss: 0.2245, acc: 0.9096 
val --- avg_loss: 0.4659, acc: 0.8715  

epoch: 137 avg_loss: 0.2259, acc: 0.9128 
val --- avg_loss: 0.4428, acc: 0.8760  

epoch: 138 avg_loss: 0.2240, acc: 0.9103 
val --- avg_loss: 0.4722, acc: 0.8748  

epoch: 139 avg_loss: 0.2225, acc: 0.9122 
val --- avg_loss: 0.5165, acc: 0.8603  

epoch: 140 avg_loss: 0.2227, acc: 0.9137 
val --- avg_loss: 0.4498, acc: 0.8744  

epoch: 141 avg_loss: 0.2225, acc: 0.9145 
val --- avg_loss: 0.4807, acc: 0.8740  

epoch: 142 avg_loss: 0.2225, acc: 0.9133 
val --- avg_loss: 0.4913, acc: 0.8698  

epoch: 143 avg_loss: 0.2245, acc: 0.9099 
val --- avg_loss: 0.4626, acc: 0.8682  

epoch: 144 avg_loss: 0.2231, acc: 0.9145 
val --- avg_loss: 0.4693, acc: 0.8740  

epoch: 145 avg_loss: 0.2196, acc: 0.9147 
val --- avg_loss: 0.4545, acc: 0.8698  

epoch: 146 avg_loss: 0.2228, acc: 0.9136 
val --- avg_loss: 0.4552, acc: 0.8702  

epoch: 147 avg_loss: 0.2211, acc: 0.9138 
val --- avg_loss: 0.4533, acc: 0.8727  

epoch: 148 avg_loss: 0.2196, acc: 0.9139 
val --- avg_loss: 0.4480, acc: 0.8740  

epoch: 149 avg_loss: 0.2246, acc: 0.9085 
val --- avg_loss: 0.4762, acc: 0.8686  

epoch: 150 avg_loss: 0.2207, acc: 0.9115 
val --- avg_loss: 0.4754, acc: 0.8719  

epoch: 151 avg_loss: 0.2206, acc: 0.9153 
val --- avg_loss: 0.4496, acc: 0.8735  

epoch: 152 avg_loss: 0.2215, acc: 0.9142 
val --- avg_loss: 0.4526, acc: 0.8731  

epoch: 153 avg_loss: 0.2198, acc: 0.9125 
val --- avg_loss: 0.4591, acc: 0.8744  

epoch: 154 avg_loss: 0.2210, acc: 0.9145 
val --- avg_loss: 0.4606, acc: 0.8773  

epoch: 155 avg_loss: 0.2216, acc: 0.9144 
val --- avg_loss: 0.4560, acc: 0.8727  

epoch: 156 avg_loss: 0.2198, acc: 0.9142 
val --- avg_loss: 0.4750, acc: 0.8756  

epoch: 157 avg_loss: 0.2174, acc: 0.9154 
val --- avg_loss: 0.4406, acc: 0.8744  

epoch: 158 avg_loss: 0.2220, acc: 0.9136 
val --- avg_loss: 0.4741, acc: 0.8723  

epoch: 159 avg_loss: 0.2215, acc: 0.9133 
val --- avg_loss: 0.4688, acc: 0.8706  

epoch: 160 avg_loss: 0.2179, acc: 0.9138 
val --- avg_loss: 0.4635, acc: 0.8682  

epoch: 161 avg_loss: 0.2183, acc: 0.9160 
val --- avg_loss: 0.4421, acc: 0.8731  

epoch: 162 avg_loss: 0.2209, acc: 0.9136 
val --- avg_loss: 0.4523, acc: 0.8727  

epoch: 163 avg_loss: 0.2205, acc: 0.9153 
val --- avg_loss: 0.4574, acc: 0.8715  

epoch: 164 avg_loss: 0.2199, acc: 0.9123 
val --- avg_loss: 0.4975, acc: 0.8661  

epoch: 165 avg_loss: 0.2177, acc: 0.9130 
val --- avg_loss: 0.4485, acc: 0.8731  

epoch: 166 avg_loss: 0.2197, acc: 0.9158 
val --- avg_loss: 0.4925, acc: 0.8673  

epoch: 167 avg_loss: 0.2188, acc: 0.9142 
val --- avg_loss: 0.4482, acc: 0.8748  

epoch: 168 avg_loss: 0.2187, acc: 0.9137 
val --- avg_loss: 0.5003, acc: 0.8632  

epoch: 169 avg_loss: 0.2168, acc: 0.9169 
val --- avg_loss: 0.4668, acc: 0.8715  

epoch: 170 avg_loss: 0.2198, acc: 0.9150 
val --- avg_loss: 0.4523, acc: 0.8723  

epoch: 171 avg_loss: 0.2191, acc: 0.9137 
val --- avg_loss: 0.4946, acc: 0.8624  

epoch: 172 avg_loss: 0.2170, acc: 0.9152 
val --- avg_loss: 0.4655, acc: 0.8702  

epoch: 173 avg_loss: 0.2184, acc: 0.9150 
val --- avg_loss: 0.4607, acc: 0.8752  

epoch: 174 avg_loss: 0.2180, acc: 0.9143 
val --- avg_loss: 0.4741, acc: 0.8682  

epoch: 175 avg_loss: 0.2171, acc: 0.9141 
val --- avg_loss: 0.4756, acc: 0.8727  

epoch: 176 avg_loss: 0.2162, acc: 0.9161 
val --- avg_loss: 0.4537, acc: 0.8735  

epoch: 177 avg_loss: 0.2177, acc: 0.9150 
val --- avg_loss: 0.4593, acc: 0.8744  

epoch: 178 avg_loss: 0.2177, acc: 0.9138 
val --- avg_loss: 0.4648, acc: 0.8719  

epoch: 179 avg_loss: 0.2215, acc: 0.9139 
val --- avg_loss: 0.4680, acc: 0.8727  

epoch: 180 avg_loss: 0.2176, acc: 0.9143 
val --- avg_loss: 0.4758, acc: 0.8740  

epoch: 181 avg_loss: 0.2147, acc: 0.9148 
val --- avg_loss: 0.4836, acc: 0.8702  

epoch: 182 avg_loss: 0.2190, acc: 0.9141 
val --- avg_loss: 0.4528, acc: 0.8711  

epoch: 183 avg_loss: 0.2155, acc: 0.9152 
val --- avg_loss: 0.4724, acc: 0.8715  

epoch: 184 avg_loss: 0.2161, acc: 0.9166 
val --- avg_loss: 0.4640, acc: 0.8740  

epoch: 185 avg_loss: 0.2145, acc: 0.9165 
val --- avg_loss: 0.4586, acc: 0.8748  

epoch: 186 avg_loss: 0.2149, acc: 0.9181 
val --- avg_loss: 0.4723, acc: 0.8723  

epoch: 187 avg_loss: 0.2183, acc: 0.9130 
val --- avg_loss: 0.4847, acc: 0.8715  

epoch: 188 avg_loss: 0.2179, acc: 0.9157 
val --- avg_loss: 0.4810, acc: 0.8735  

epoch: 189 avg_loss: 0.2171, acc: 0.9139 
val --- avg_loss: 0.4671, acc: 0.8735  

epoch: 190 avg_loss: 0.2155, acc: 0.9153 
val --- avg_loss: 0.4599, acc: 0.8719  

epoch: 191 avg_loss: 0.2164, acc: 0.9166 
val --- avg_loss: 0.4733, acc: 0.8706  

epoch: 192 avg_loss: 0.2141, acc: 0.9166 
val --- avg_loss: 0.4548, acc: 0.8760  

epoch: 193 avg_loss: 0.2126, acc: 0.9164 
val --- avg_loss: 0.4479, acc: 0.8781  

epoch: 194 avg_loss: 0.2175, acc: 0.9165 
val --- avg_loss: 0.4758, acc: 0.8731  

epoch: 195 avg_loss: 0.2141, acc: 0.9152 
val --- avg_loss: 0.4783, acc: 0.8735  

epoch: 196 avg_loss: 0.2158, acc: 0.9153 
val --- avg_loss: 0.4790, acc: 0.8706  

epoch: 197 avg_loss: 0.2139, acc: 0.9164 
val --- avg_loss: 0.4635, acc: 0.8727  

epoch: 198 avg_loss: 0.2166, acc: 0.9152 
val --- avg_loss: 0.4620, acc: 0.8765  

epoch: 199 avg_loss: 0.2168, acc: 0.9149 
val --- avg_loss: 0.4756, acc: 0.8727  
