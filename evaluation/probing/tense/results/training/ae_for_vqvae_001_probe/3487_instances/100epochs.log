
number of params: 3072 
Namespace(batchsize=128, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=100, fig_path='evaluation/probing/tense/results/training/ae_for_vqvae_001_probe/3487_instances/100epochs.png', log_path='evaluation/probing/tense/results/training/ae_for_vqvae_001_probe/3487_instances/100epochs.log', logger=<common.utils.Logger object at 0x7fb5d09f1a50>, lr=0.001, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='ae_for_vqvae_001_probe', model=AE_Probe(
  (encoder): AE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=512, out_features=512, bias=False)
  )
  (linear): Linear(in_features=512, out_features=6, bias=False)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/tense/results/training/ae_for_vqvae_001_probe/3487_instances/', nh=512, ni=256, num_embeddings=704, nz=512, opt='Adam', pretrained_model=AE(
  (encoder): AE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=512, out_features=512, bias=False)
  )
  (decoder): AE_Decoder(
    (embed): Embedding(32, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (trans_linear): Linear(in_features=512, out_features=512, bias=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=32, bias=False)
    (loss): CrossEntropyLoss()
  )
), save_path='evaluation/probing/tense/results/training/ae_for_vqvae_001_probe/3487_instances/100epochs.pt', seq_to_no_pad='surface', task='surf2tense', trndata='evaluation/probing/tense/data/sosimple.new.trn.combined.txt', trnsize=3487, tstdata='evaluation/probing/tense/data/sosimple.new.seenroots.val.txt', tstsize=209, valdata='evaluation/probing/tense/data/sosimple.new.seenroots.val.txt', valsize=209)

encoder.embed.weight, torch.Size([32, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
encoder.linear.weight, torch.Size([512, 512]): False
linear.weight, torch.Size([6, 512]): True
epoch: 0 avg_loss: 1.5449, acc: 0.3946 

epoch: 1 avg_loss: 1.0421, acc: 0.6232 

epoch: 2 avg_loss: 0.8277, acc: 0.7582 

epoch: 3 avg_loss: 0.6734, acc: 0.8342 

epoch: 4 avg_loss: 0.5822, acc: 0.8621 

epoch: 5 avg_loss: 0.5166, acc: 0.8750 

epoch: 6 avg_loss: 0.4610, acc: 0.9002 

epoch: 7 avg_loss: 0.4231, acc: 0.9059 

epoch: 8 avg_loss: 0.3895, acc: 0.9200 

epoch: 9 avg_loss: 0.3624, acc: 0.9200 

epoch: 10 avg_loss: 0.3334, acc: 0.9243 

epoch: 11 avg_loss: 0.3129, acc: 0.9300 

epoch: 12 avg_loss: 0.2991, acc: 0.9320 

epoch: 13 avg_loss: 0.2795, acc: 0.9381 

epoch: 14 avg_loss: 0.2720, acc: 0.9378 

epoch: 15 avg_loss: 0.2542, acc: 0.9401 

epoch: 16 avg_loss: 0.2472, acc: 0.9441 

epoch: 17 avg_loss: 0.2341, acc: 0.9432 

epoch: 18 avg_loss: 0.2226, acc: 0.9524 

epoch: 19 avg_loss: 0.2145, acc: 0.9490 

epoch: 20 avg_loss: 0.2045, acc: 0.9533 

epoch: 21 avg_loss: 0.1970, acc: 0.9558 

epoch: 22 avg_loss: 0.1906, acc: 0.9573 

epoch: 23 avg_loss: 0.1843, acc: 0.9590 

epoch: 24 avg_loss: 0.1782, acc: 0.9619 

epoch: 25 avg_loss: 0.1747, acc: 0.9599 

epoch: 26 avg_loss: 0.1676, acc: 0.9653 

epoch: 27 avg_loss: 0.1629, acc: 0.9627 

epoch: 28 avg_loss: 0.1608, acc: 0.9596 

epoch: 29 avg_loss: 0.1527, acc: 0.9653 

epoch: 30 avg_loss: 0.1504, acc: 0.9647 

epoch: 31 avg_loss: 0.1459, acc: 0.9676 

epoch: 32 avg_loss: 0.1432, acc: 0.9676 

epoch: 33 avg_loss: 0.1383, acc: 0.9699 

epoch: 34 avg_loss: 0.1372, acc: 0.9673 

epoch: 35 avg_loss: 0.1322, acc: 0.9710 

epoch: 36 avg_loss: 0.1301, acc: 0.9690 

epoch: 37 avg_loss: 0.1273, acc: 0.9716 

epoch: 38 avg_loss: 0.1222, acc: 0.9739 

epoch: 39 avg_loss: 0.1209, acc: 0.9739 

epoch: 40 avg_loss: 0.1182, acc: 0.9722 

epoch: 41 avg_loss: 0.1167, acc: 0.9753 

epoch: 42 avg_loss: 0.1122, acc: 0.9733 

epoch: 43 avg_loss: 0.1100, acc: 0.9759 

epoch: 44 avg_loss: 0.1090, acc: 0.9759 

epoch: 45 avg_loss: 0.1053, acc: 0.9771 

epoch: 46 avg_loss: 0.1038, acc: 0.9771 

epoch: 47 avg_loss: 0.1017, acc: 0.9773 

epoch: 48 avg_loss: 0.1007, acc: 0.9773 

epoch: 49 avg_loss: 0.0982, acc: 0.9782 

epoch: 50 avg_loss: 0.0980, acc: 0.9756 

epoch: 51 avg_loss: 0.0952, acc: 0.9796 

epoch: 52 avg_loss: 0.0923, acc: 0.9808 

epoch: 53 avg_loss: 0.0905, acc: 0.9794 

epoch: 54 avg_loss: 0.0902, acc: 0.9802 

epoch: 55 avg_loss: 0.0882, acc: 0.9822 

epoch: 56 avg_loss: 0.0848, acc: 0.9819 

epoch: 57 avg_loss: 0.0837, acc: 0.9825 

epoch: 58 avg_loss: 0.0840, acc: 0.9822 

epoch: 59 avg_loss: 0.0817, acc: 0.9811 

epoch: 60 avg_loss: 0.0803, acc: 0.9839 

epoch: 61 avg_loss: 0.0790, acc: 0.9845 

epoch: 62 avg_loss: 0.0794, acc: 0.9825 

epoch: 63 avg_loss: 0.0759, acc: 0.9845 

epoch: 64 avg_loss: 0.0764, acc: 0.9848 

epoch: 65 avg_loss: 0.0757, acc: 0.9834 

epoch: 66 avg_loss: 0.0725, acc: 0.9845 

epoch: 67 avg_loss: 0.0717, acc: 0.9848 

epoch: 68 avg_loss: 0.0704, acc: 0.9854 

epoch: 69 avg_loss: 0.0697, acc: 0.9848 

epoch: 70 avg_loss: 0.0704, acc: 0.9848 

epoch: 71 avg_loss: 0.0672, acc: 0.9862 

epoch: 72 avg_loss: 0.0662, acc: 0.9859 

epoch: 73 avg_loss: 0.0658, acc: 0.9854 

epoch: 74 avg_loss: 0.0644, acc: 0.9862 

epoch: 75 avg_loss: 0.0628, acc: 0.9871 

epoch: 76 avg_loss: 0.0624, acc: 0.9859 

epoch: 77 avg_loss: 0.0623, acc: 0.9871 

epoch: 78 avg_loss: 0.0597, acc: 0.9880 

epoch: 79 avg_loss: 0.0598, acc: 0.9885 

epoch: 80 avg_loss: 0.0596, acc: 0.9874 

epoch: 81 avg_loss: 0.0578, acc: 0.9880 

epoch: 82 avg_loss: 0.0570, acc: 0.9888 

epoch: 83 avg_loss: 0.0554, acc: 0.9891 

epoch: 84 avg_loss: 0.0561, acc: 0.9894 

epoch: 85 avg_loss: 0.0551, acc: 0.9897 

epoch: 86 avg_loss: 0.0537, acc: 0.9894 

epoch: 87 avg_loss: 0.0530, acc: 0.9897 

epoch: 88 avg_loss: 0.0535, acc: 0.9897 

epoch: 89 avg_loss: 0.0519, acc: 0.9897 

epoch: 90 avg_loss: 0.0507, acc: 0.9914 

epoch: 91 avg_loss: 0.0500, acc: 0.9911 

epoch: 92 avg_loss: 0.0493, acc: 0.9908 

epoch: 93 avg_loss: 0.0512, acc: 0.9897 

epoch: 94 avg_loss: 0.0489, acc: 0.9905 

epoch: 95 avg_loss: 0.0478, acc: 0.9917 

epoch: 96 avg_loss: 0.0473, acc: 0.9914 

epoch: 97 avg_loss: 0.0467, acc: 0.9920 

epoch: 98 avg_loss: 0.0456, acc: 0.9914 

epoch: 99 avg_loss: 0.0456, acc: 0.9920 
