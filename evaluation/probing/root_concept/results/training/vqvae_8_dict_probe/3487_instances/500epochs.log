
number of params: 45760 
Namespace(batchsize=128, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=500, fig_path='evaluation/probing/root_concept/results/training/vqvae_8_dict_probe/3487_instances/500epochs.png', log_path='evaluation/probing/root_concept/results/training/vqvae_8_dict_probe/3487_instances/500epochs.log', logger=<common.utils.Logger object at 0x7fe3f8704190>, lr=0.01, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='vqvae_8_dict_probe', model=VQVAE_Probe(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_2): Linear(in_features=512, out_features=64, bias=True)
  (linear_3): Linear(in_features=512, out_features=64, bias=True)
  (linear_4): Linear(in_features=512, out_features=64, bias=True)
  (linear_5): Linear(in_features=512, out_features=64, bias=True)
  (linear_6): Linear(in_features=512, out_features=64, bias=True)
  (linear_7): Linear(in_features=512, out_features=64, bias=True)
  (linear_8): Linear(in_features=512, out_features=64, bias=True)
  (linear_9): Linear(in_features=512, out_features=64, bias=True)
  (vq_layer_2): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_3): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_4): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_5): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_6): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_7): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_8): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_9): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (linear): Linear(in_features=64, out_features=704, bias=True)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/root_concept/results/training/vqvae_8_dict_probe/3487_instances/', nh=512, ni=256, num_embeddings=704, nz=512, opt='Adam', pretrained_model=VQVAE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_2): Linear(in_features=512, out_features=64, bias=True)
  (linear_3): Linear(in_features=512, out_features=64, bias=True)
  (linear_4): Linear(in_features=512, out_features=64, bias=True)
  (linear_5): Linear(in_features=512, out_features=64, bias=True)
  (linear_6): Linear(in_features=512, out_features=64, bias=True)
  (linear_7): Linear(in_features=512, out_features=64, bias=True)
  (linear_8): Linear(in_features=512, out_features=64, bias=True)
  (linear_9): Linear(in_features=512, out_features=64, bias=True)
  (vq_layer_2): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_3): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_4): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_5): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_6): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_7): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_8): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_9): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(32, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=32, bias=False)
    (loss): CrossEntropyLoss()
  )
), save_path='evaluation/probing/root_concept/results/training/vqvae_8_dict_probe/3487_instances/500epochs.pt', seq_to_no_pad='surface', task='surf2root_concept', trndata='evaluation/probing/root_concept/data/sosimple.new.trn.combined.txt', trnsize=3487, tstdata='evaluation/probing/root_concept/data/sosimple.new.seenroots.val.txt', tstsize=209, valdata='evaluation/probing/root_concept/data/sosimple.new.seenroots.val.txt', valsize=209)

encoder.embed.weight, torch.Size([32, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
linear_2.weight, torch.Size([64, 512]): False
linear_2.bias, torch.Size([64]): False
linear_3.weight, torch.Size([64, 512]): False
linear_3.bias, torch.Size([64]): False
linear_4.weight, torch.Size([64, 512]): False
linear_4.bias, torch.Size([64]): False
linear_5.weight, torch.Size([64, 512]): False
linear_5.bias, torch.Size([64]): False
linear_6.weight, torch.Size([64, 512]): False
linear_6.bias, torch.Size([64]): False
linear_7.weight, torch.Size([64, 512]): False
linear_7.bias, torch.Size([64]): False
linear_8.weight, torch.Size([64, 512]): False
linear_8.bias, torch.Size([64]): False
linear_9.weight, torch.Size([64, 512]): False
linear_9.bias, torch.Size([64]): False
vq_layer_2.embedding.weight, torch.Size([16, 64]): False
vq_layer_3.embedding.weight, torch.Size([16, 64]): False
vq_layer_4.embedding.weight, torch.Size([16, 64]): False
vq_layer_5.embedding.weight, torch.Size([16, 64]): False
vq_layer_6.embedding.weight, torch.Size([16, 64]): False
vq_layer_7.embedding.weight, torch.Size([16, 64]): False
vq_layer_8.embedding.weight, torch.Size([16, 64]): False
vq_layer_9.embedding.weight, torch.Size([16, 64]): False
linear.weight, torch.Size([704, 64]): True
linear.bias, torch.Size([704]): True
epoch: 0 avg_loss: 5.9035, acc: 0.0241 

epoch: 1 avg_loss: 5.1519, acc: 0.0358 

epoch: 2 avg_loss: 4.9206, acc: 0.0313 

epoch: 3 avg_loss: 4.8457, acc: 0.0353 

epoch: 4 avg_loss: 4.8030, acc: 0.0327 

epoch: 5 avg_loss: 4.7883, acc: 0.0333 

epoch: 6 avg_loss: 4.7277, acc: 0.0327 

epoch: 7 avg_loss: 4.7160, acc: 0.0290 

epoch: 8 avg_loss: 4.7501, acc: 0.0298 

epoch: 9 avg_loss: 4.7594, acc: 0.0347 

epoch: 10 avg_loss: 4.6984, acc: 0.0313 

epoch: 11 avg_loss: 4.6763, acc: 0.0324 

epoch: 12 avg_loss: 4.7097, acc: 0.0324 

epoch: 13 avg_loss: 4.7176, acc: 0.0327 

epoch: 14 avg_loss: 4.6878, acc: 0.0264 

epoch: 15 avg_loss: 4.6662, acc: 0.0304 

epoch: 16 avg_loss: 4.6492, acc: 0.0313 

epoch: 17 avg_loss: 4.6794, acc: 0.0310 

epoch: 18 avg_loss: 4.6515, acc: 0.0261 

epoch: 19 avg_loss: 4.6812, acc: 0.0333 

epoch: 20 avg_loss: 4.6599, acc: 0.0321 

epoch: 21 avg_loss: 4.6763, acc: 0.0307 

epoch: 22 avg_loss: 4.6607, acc: 0.0315 

epoch: 23 avg_loss: 4.6586, acc: 0.0295 

epoch: 24 avg_loss: 4.6395, acc: 0.0295 

epoch: 25 avg_loss: 4.6611, acc: 0.0344 

epoch: 26 avg_loss: 4.6256, acc: 0.0318 

epoch: 27 avg_loss: 4.6176, acc: 0.0313 

epoch: 28 avg_loss: 4.7072, acc: 0.0324 

epoch: 29 avg_loss: 4.6414, acc: 0.0301 

epoch: 30 avg_loss: 4.6098, acc: 0.0301 

epoch: 31 avg_loss: 4.6508, acc: 0.0293 

epoch: 32 avg_loss: 4.6867, acc: 0.0270 

epoch: 33 avg_loss: 4.6329, acc: 0.0310 

epoch: 34 avg_loss: 4.6809, acc: 0.0287 

epoch: 35 avg_loss: 4.6468, acc: 0.0321 

epoch: 36 avg_loss: 4.6852, acc: 0.0290 

epoch: 37 avg_loss: 4.6631, acc: 0.0330 

epoch: 38 avg_loss: 4.6316, acc: 0.0313 

epoch: 39 avg_loss: 4.6111, acc: 0.0356 

epoch: 40 avg_loss: 4.6318, acc: 0.0278 

epoch: 41 avg_loss: 4.6669, acc: 0.0272 

epoch: 42 avg_loss: 4.6324, acc: 0.0249 

epoch: 43 avg_loss: 4.6357, acc: 0.0347 

epoch: 44 avg_loss: 4.6092, acc: 0.0270 

epoch: 45 avg_loss: 4.6391, acc: 0.0301 

epoch: 46 avg_loss: 4.6347, acc: 0.0307 

epoch: 47 avg_loss: 4.6214, acc: 0.0313 

epoch: 48 avg_loss: 4.6575, acc: 0.0321 

epoch: 49 avg_loss: 4.6423, acc: 0.0321 

epoch: 50 avg_loss: 4.6210, acc: 0.0293 

epoch: 51 avg_loss: 4.6313, acc: 0.0333 

epoch: 52 avg_loss: 4.6067, acc: 0.0324 

epoch: 53 avg_loss: 4.5958, acc: 0.0272 

epoch: 54 avg_loss: 4.6673, acc: 0.0301 

epoch: 55 avg_loss: 4.6591, acc: 0.0318 

epoch: 56 avg_loss: 4.5958, acc: 0.0324 

epoch: 57 avg_loss: 4.6511, acc: 0.0252 

epoch: 58 avg_loss: 4.6125, acc: 0.0275 

epoch: 59 avg_loss: 4.6180, acc: 0.0338 

epoch: 60 avg_loss: 4.6366, acc: 0.0267 

epoch: 61 avg_loss: 4.5863, acc: 0.0307 

epoch: 62 avg_loss: 4.6650, acc: 0.0258 

epoch: 63 avg_loss: 4.5798, acc: 0.0313 

epoch: 64 avg_loss: 4.6223, acc: 0.0341 

epoch: 65 avg_loss: 4.6064, acc: 0.0298 

epoch: 66 avg_loss: 4.6080, acc: 0.0321 

epoch: 67 avg_loss: 4.6438, acc: 0.0293 

epoch: 68 avg_loss: 4.6262, acc: 0.0298 

epoch: 69 avg_loss: 4.6394, acc: 0.0293 

epoch: 70 avg_loss: 4.5801, acc: 0.0267 

epoch: 71 avg_loss: 4.6127, acc: 0.0367 

epoch: 72 avg_loss: 4.5842, acc: 0.0295 

epoch: 73 avg_loss: 4.6371, acc: 0.0272 

epoch: 74 avg_loss: 4.6497, acc: 0.0290 

epoch: 75 avg_loss: 4.5933, acc: 0.0293 

epoch: 76 avg_loss: 4.6039, acc: 0.0301 

epoch: 77 avg_loss: 4.6142, acc: 0.0310 

epoch: 78 avg_loss: 4.6248, acc: 0.0344 

epoch: 79 avg_loss: 4.6047, acc: 0.0278 

epoch: 80 avg_loss: 4.6314, acc: 0.0358 

epoch: 81 avg_loss: 4.6800, acc: 0.0298 

epoch: 82 avg_loss: 4.6011, acc: 0.0321 

epoch: 83 avg_loss: 4.6462, acc: 0.0315 

epoch: 84 avg_loss: 4.5953, acc: 0.0264 

epoch: 85 avg_loss: 4.5884, acc: 0.0341 

epoch: 86 avg_loss: 4.6012, acc: 0.0313 

epoch: 87 avg_loss: 4.6370, acc: 0.0318 

epoch: 88 avg_loss: 4.6133, acc: 0.0310 

epoch: 89 avg_loss: 4.5957, acc: 0.0301 

epoch: 90 avg_loss: 4.6227, acc: 0.0336 

epoch: 91 avg_loss: 4.6226, acc: 0.0313 

epoch: 92 avg_loss: 4.5924, acc: 0.0338 

epoch: 93 avg_loss: 4.5798, acc: 0.0310 

epoch: 94 avg_loss: 4.5966, acc: 0.0258 

epoch: 95 avg_loss: 4.6396, acc: 0.0304 

epoch: 96 avg_loss: 4.5967, acc: 0.0310 

epoch: 97 avg_loss: 4.6449, acc: 0.0293 

epoch: 98 avg_loss: 4.6152, acc: 0.0261 

epoch: 99 avg_loss: 4.6205, acc: 0.0281 

epoch: 100 avg_loss: 4.6236, acc: 0.0315 

epoch: 101 avg_loss: 4.5991, acc: 0.0293 

epoch: 102 avg_loss: 4.6013, acc: 0.0364 

epoch: 103 avg_loss: 4.6111, acc: 0.0290 

epoch: 104 avg_loss: 4.6243, acc: 0.0318 

epoch: 105 avg_loss: 4.6110, acc: 0.0290 

epoch: 106 avg_loss: 4.6817, acc: 0.0310 

epoch: 107 avg_loss: 4.6510, acc: 0.0281 

epoch: 108 avg_loss: 4.6339, acc: 0.0321 

epoch: 109 avg_loss: 4.6579, acc: 0.0295 

epoch: 110 avg_loss: 4.6307, acc: 0.0324 

epoch: 111 avg_loss: 4.6095, acc: 0.0338 

epoch: 112 avg_loss: 4.6401, acc: 0.0298 

epoch: 113 avg_loss: 4.6519, acc: 0.0278 

epoch: 114 avg_loss: 4.6443, acc: 0.0301 

epoch: 115 avg_loss: 4.6215, acc: 0.0295 

epoch: 116 avg_loss: 4.5678, acc: 0.0330 

epoch: 117 avg_loss: 4.5944, acc: 0.0330 

epoch: 118 avg_loss: 4.6331, acc: 0.0272 

epoch: 119 avg_loss: 4.6226, acc: 0.0287 

epoch: 120 avg_loss: 4.6142, acc: 0.0313 

epoch: 121 avg_loss: 4.6113, acc: 0.0304 

epoch: 122 avg_loss: 4.6041, acc: 0.0272 

epoch: 123 avg_loss: 4.6040, acc: 0.0278 

epoch: 124 avg_loss: 4.6252, acc: 0.0333 

epoch: 125 avg_loss: 4.6042, acc: 0.0324 

epoch: 126 avg_loss: 4.5989, acc: 0.0301 

epoch: 127 avg_loss: 4.6217, acc: 0.0330 

epoch: 128 avg_loss: 4.5963, acc: 0.0281 

epoch: 129 avg_loss: 4.6135, acc: 0.0304 

epoch: 130 avg_loss: 4.7093, acc: 0.0270 

epoch: 131 avg_loss: 4.5865, acc: 0.0315 

epoch: 132 avg_loss: 4.6111, acc: 0.0321 

epoch: 133 avg_loss: 4.6122, acc: 0.0350 

epoch: 134 avg_loss: 4.6322, acc: 0.0272 

epoch: 135 avg_loss: 4.6253, acc: 0.0298 

epoch: 136 avg_loss: 4.5692, acc: 0.0313 

epoch: 137 avg_loss: 4.6481, acc: 0.0293 

epoch: 138 avg_loss: 4.6240, acc: 0.0344 

epoch: 139 avg_loss: 4.5854, acc: 0.0261 

epoch: 140 avg_loss: 4.5975, acc: 0.0313 

epoch: 141 avg_loss: 4.6281, acc: 0.0313 

epoch: 142 avg_loss: 4.5941, acc: 0.0307 

epoch: 143 avg_loss: 4.6112, acc: 0.0313 

epoch: 144 avg_loss: 4.6152, acc: 0.0324 

epoch: 145 avg_loss: 4.6122, acc: 0.0321 

epoch: 146 avg_loss: 4.6007, acc: 0.0318 

epoch: 147 avg_loss: 4.6199, acc: 0.0327 

epoch: 148 avg_loss: 4.5901, acc: 0.0333 

epoch: 149 avg_loss: 4.5866, acc: 0.0310 

epoch: 150 avg_loss: 4.6410, acc: 0.0304 

epoch: 151 avg_loss: 4.6091, acc: 0.0290 

epoch: 152 avg_loss: 4.6087, acc: 0.0275 

epoch: 153 avg_loss: 4.6096, acc: 0.0307 

epoch: 154 avg_loss: 4.6157, acc: 0.0318 

epoch: 155 avg_loss: 4.6022, acc: 0.0295 

epoch: 156 avg_loss: 4.5766, acc: 0.0290 

epoch: 157 avg_loss: 4.6324, acc: 0.0284 

epoch: 158 avg_loss: 4.5909, acc: 0.0275 

epoch: 159 avg_loss: 4.6284, acc: 0.0301 

epoch: 160 avg_loss: 4.6043, acc: 0.0298 

epoch: 161 avg_loss: 4.5948, acc: 0.0272 

epoch: 162 avg_loss: 4.5734, acc: 0.0313 

epoch: 163 avg_loss: 4.5972, acc: 0.0324 

epoch: 164 avg_loss: 4.6078, acc: 0.0298 

epoch: 165 avg_loss: 4.5924, acc: 0.0304 

epoch: 166 avg_loss: 4.6068, acc: 0.0264 

epoch: 167 avg_loss: 4.6285, acc: 0.0301 

epoch: 168 avg_loss: 4.6071, acc: 0.0327 

epoch: 169 avg_loss: 4.5928, acc: 0.0353 

epoch: 170 avg_loss: 4.5771, acc: 0.0298 

epoch: 171 avg_loss: 4.6142, acc: 0.0341 

epoch: 172 avg_loss: 4.6124, acc: 0.0298 

epoch: 173 avg_loss: 4.5940, acc: 0.0293 

epoch: 174 avg_loss: 4.6012, acc: 0.0270 

epoch: 175 avg_loss: 4.6112, acc: 0.0295 

epoch: 176 avg_loss: 4.5883, acc: 0.0270 

epoch: 177 avg_loss: 4.6325, acc: 0.0301 

epoch: 178 avg_loss: 4.6039, acc: 0.0270 

epoch: 179 avg_loss: 4.6419, acc: 0.0304 

epoch: 180 avg_loss: 4.6062, acc: 0.0333 

epoch: 181 avg_loss: 4.5854, acc: 0.0313 

epoch: 182 avg_loss: 4.6259, acc: 0.0295 

epoch: 183 avg_loss: 4.6406, acc: 0.0364 

epoch: 184 avg_loss: 4.6428, acc: 0.0327 

epoch: 185 avg_loss: 4.5879, acc: 0.0295 

epoch: 186 avg_loss: 4.5816, acc: 0.0284 

epoch: 187 avg_loss: 4.5865, acc: 0.0298 

epoch: 188 avg_loss: 4.6209, acc: 0.0270 

epoch: 189 avg_loss: 4.5999, acc: 0.0241 

epoch: 190 avg_loss: 4.6321, acc: 0.0324 

epoch: 191 avg_loss: 4.6220, acc: 0.0301 

epoch: 192 avg_loss: 4.5782, acc: 0.0321 

epoch: 193 avg_loss: 4.6161, acc: 0.0293 

epoch: 194 avg_loss: 4.6157, acc: 0.0215 

epoch: 195 avg_loss: 4.6170, acc: 0.0295 

epoch: 196 avg_loss: 4.6639, acc: 0.0330 

epoch: 197 avg_loss: 4.6034, acc: 0.0261 

epoch: 198 avg_loss: 4.5951, acc: 0.0304 

epoch: 199 avg_loss: 4.6383, acc: 0.0238 

epoch: 200 avg_loss: 4.6197, acc: 0.0324 

epoch: 201 avg_loss: 4.5692, acc: 0.0270 

epoch: 202 avg_loss: 4.5812, acc: 0.0249 

epoch: 203 avg_loss: 4.6013, acc: 0.0252 

epoch: 204 avg_loss: 4.6188, acc: 0.0336 

epoch: 205 avg_loss: 4.6468, acc: 0.0278 

epoch: 206 avg_loss: 4.5957, acc: 0.0275 

epoch: 207 avg_loss: 4.6022, acc: 0.0307 

epoch: 208 avg_loss: 4.5975, acc: 0.0249 

epoch: 209 avg_loss: 4.6297, acc: 0.0301 

epoch: 210 avg_loss: 4.5893, acc: 0.0275 

epoch: 211 avg_loss: 4.6578, acc: 0.0307 

epoch: 212 avg_loss: 4.5772, acc: 0.0327 

epoch: 213 avg_loss: 4.5942, acc: 0.0338 

epoch: 214 avg_loss: 4.5766, acc: 0.0290 

epoch: 215 avg_loss: 4.5996, acc: 0.0353 

epoch: 216 avg_loss: 4.5942, acc: 0.0275 

epoch: 217 avg_loss: 4.6101, acc: 0.0264 

epoch: 218 avg_loss: 4.6516, acc: 0.0327 

epoch: 219 avg_loss: 4.6116, acc: 0.0275 

epoch: 220 avg_loss: 4.5991, acc: 0.0301 

epoch: 221 avg_loss: 4.6277, acc: 0.0287 

epoch: 222 avg_loss: 4.6271, acc: 0.0293 

epoch: 223 avg_loss: 4.6181, acc: 0.0324 

epoch: 224 avg_loss: 4.5885, acc: 0.0284 

epoch: 225 avg_loss: 4.6202, acc: 0.0367 

epoch: 226 avg_loss: 4.5993, acc: 0.0287 

epoch: 227 avg_loss: 4.6047, acc: 0.0304 

epoch: 228 avg_loss: 4.5942, acc: 0.0313 

epoch: 229 avg_loss: 4.6006, acc: 0.0399 

epoch: 230 avg_loss: 4.6139, acc: 0.0272 

epoch: 231 avg_loss: 4.6317, acc: 0.0287 

epoch: 232 avg_loss: 4.6164, acc: 0.0298 

epoch: 233 avg_loss: 4.6262, acc: 0.0324 

epoch: 234 avg_loss: 4.6700, acc: 0.0301 

epoch: 235 avg_loss: 4.6560, acc: 0.0315 

epoch: 236 avg_loss: 4.6208, acc: 0.0293 

epoch: 237 avg_loss: 4.6613, acc: 0.0310 

epoch: 238 avg_loss: 4.5902, acc: 0.0281 

epoch: 239 avg_loss: 4.6264, acc: 0.0315 

epoch: 240 avg_loss: 4.5852, acc: 0.0278 

epoch: 241 avg_loss: 4.6389, acc: 0.0364 

epoch: 242 avg_loss: 4.6215, acc: 0.0278 

epoch: 243 avg_loss: 4.5952, acc: 0.0264 

epoch: 244 avg_loss: 4.6230, acc: 0.0298 

epoch: 245 avg_loss: 4.5662, acc: 0.0315 

epoch: 246 avg_loss: 4.6235, acc: 0.0327 

epoch: 247 avg_loss: 4.5825, acc: 0.0324 

epoch: 248 avg_loss: 4.5912, acc: 0.0304 

epoch: 249 avg_loss: 4.5932, acc: 0.0290 

epoch: 250 avg_loss: 4.6209, acc: 0.0313 

epoch: 251 avg_loss: 4.5998, acc: 0.0336 

epoch: 252 avg_loss: 4.5958, acc: 0.0307 

epoch: 253 avg_loss: 4.6505, acc: 0.0267 

epoch: 254 avg_loss: 4.5787, acc: 0.0310 

epoch: 255 avg_loss: 4.5799, acc: 0.0264 

epoch: 256 avg_loss: 4.5998, acc: 0.0270 

epoch: 257 avg_loss: 4.5689, acc: 0.0338 

epoch: 258 avg_loss: 4.6280, acc: 0.0275 

epoch: 259 avg_loss: 4.5932, acc: 0.0324 

epoch: 260 avg_loss: 4.5923, acc: 0.0301 

epoch: 261 avg_loss: 4.5963, acc: 0.0287 

epoch: 262 avg_loss: 4.5673, acc: 0.0304 

epoch: 263 avg_loss: 4.5904, acc: 0.0304 

epoch: 264 avg_loss: 4.6116, acc: 0.0267 

epoch: 265 avg_loss: 4.5834, acc: 0.0298 

epoch: 266 avg_loss: 4.6141, acc: 0.0304 

epoch: 267 avg_loss: 4.6034, acc: 0.0324 

epoch: 268 avg_loss: 4.6173, acc: 0.0307 

epoch: 269 avg_loss: 4.5799, acc: 0.0301 

epoch: 270 avg_loss: 4.5919, acc: 0.0358 

epoch: 271 avg_loss: 4.6097, acc: 0.0333 

epoch: 272 avg_loss: 4.6704, acc: 0.0350 

epoch: 273 avg_loss: 4.6293, acc: 0.0318 

epoch: 274 avg_loss: 4.6157, acc: 0.0287 

epoch: 275 avg_loss: 4.5816, acc: 0.0307 

epoch: 276 avg_loss: 4.6007, acc: 0.0321 

epoch: 277 avg_loss: 4.6053, acc: 0.0341 

epoch: 278 avg_loss: 4.5824, acc: 0.0278 

epoch: 279 avg_loss: 4.6074, acc: 0.0295 

epoch: 280 avg_loss: 4.6356, acc: 0.0281 

epoch: 281 avg_loss: 4.5931, acc: 0.0281 

epoch: 282 avg_loss: 4.6308, acc: 0.0298 

epoch: 283 avg_loss: 4.5900, acc: 0.0298 

epoch: 284 avg_loss: 4.6183, acc: 0.0293 

epoch: 285 avg_loss: 4.6273, acc: 0.0290 

epoch: 286 avg_loss: 4.5829, acc: 0.0341 

epoch: 287 avg_loss: 4.5605, acc: 0.0298 

epoch: 288 avg_loss: 4.5709, acc: 0.0338 

epoch: 289 avg_loss: 4.5825, acc: 0.0307 

epoch: 290 avg_loss: 4.5878, acc: 0.0278 

epoch: 291 avg_loss: 4.5887, acc: 0.0295 

epoch: 292 avg_loss: 4.6042, acc: 0.0307 

epoch: 293 avg_loss: 4.6211, acc: 0.0307 

epoch: 294 avg_loss: 4.6038, acc: 0.0284 

epoch: 295 avg_loss: 4.5724, acc: 0.0290 

epoch: 296 avg_loss: 4.5919, acc: 0.0330 

epoch: 297 avg_loss: 4.6066, acc: 0.0275 

epoch: 298 avg_loss: 4.6085, acc: 0.0284 

epoch: 299 avg_loss: 4.5953, acc: 0.0290 

epoch: 300 avg_loss: 4.5922, acc: 0.0267 

epoch: 301 avg_loss: 4.6127, acc: 0.0272 

epoch: 302 avg_loss: 4.5715, acc: 0.0278 

epoch: 303 avg_loss: 4.6083, acc: 0.0318 

epoch: 304 avg_loss: 4.5993, acc: 0.0333 

epoch: 305 avg_loss: 4.6153, acc: 0.0278 

epoch: 306 avg_loss: 4.6096, acc: 0.0298 

epoch: 307 avg_loss: 4.5811, acc: 0.0318 

epoch: 308 avg_loss: 4.6293, acc: 0.0293 

epoch: 309 avg_loss: 4.6261, acc: 0.0267 

epoch: 310 avg_loss: 4.6017, acc: 0.0313 

epoch: 311 avg_loss: 4.5816, acc: 0.0327 

epoch: 312 avg_loss: 4.5962, acc: 0.0244 
