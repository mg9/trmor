
number of params: 360448 
Namespace(batchsize=1, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=300, fig_path='evaluation/probing/root_concept/results/training/ae_for_vqvae_001_probe/3487_instances/300epochs.png', log_path='evaluation/probing/root_concept/results/training/ae_for_vqvae_001_probe/3487_instances/300epochs.log', logger=<common.utils.Logger object at 0x7f5bd1133510>, lr=0.01, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='ae_for_vqvae_001_probe', model=AE_Probe(
  (encoder): AE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=512, out_features=512, bias=False)
  )
  (linear): Linear(in_features=512, out_features=704, bias=False)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/root_concept/results/training/ae_for_vqvae_001_probe/3487_instances/', nh=512, ni=256, nz=512, opt='Adam', pretrained_model=AE(
  (encoder): AE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=512, out_features=512, bias=False)
  )
  (decoder): AE_Decoder(
    (embed): Embedding(32, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (trans_linear): Linear(in_features=512, out_features=512, bias=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=32, bias=False)
    (loss): CrossEntropyLoss()
  )
), save_path='evaluation/probing/root_concept/results/training/ae_for_vqvae_001_probe/3487_instances/300epochs.pt', seq_to_no_pad='surface', task='surf2root_concept', trndata='evaluation/probing/root_concept/data/sosimple.new.trn.combined.txt', trnsize=3487, tstdata='evaluation/probing/root_concept/data/sosimple.new.seenroots.val.txt', tstsize=209, valdata='evaluation/probing/root_concept/data/sosimple.new.seenroots.val.txt', valsize=209)

encoder.embed.weight, torch.Size([32, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
encoder.linear.weight, torch.Size([512, 512]): False
linear.weight, torch.Size([704, 512]): True
epoch: 0 avg_loss: 10.8678, acc: 0.3820 
val --- avg_loss: 7.7168, acc: 0.5167  
update best loss 

epoch: 1 avg_loss: 6.0847, acc: 0.6481 
val --- avg_loss: 6.7668, acc: 0.6316  
update best loss 

epoch: 2 avg_loss: 3.4769, acc: 0.7780 
val --- avg_loss: 4.3027, acc: 0.7368  
update best loss 

epoch: 3 avg_loss: 2.1087, acc: 0.8474 
val --- avg_loss: 5.9569, acc: 0.7368  

epoch: 4 avg_loss: 1.5876, acc: 0.8798 
val --- avg_loss: 4.1223, acc: 0.8182  
update best loss 

epoch: 5 avg_loss: 1.1317, acc: 0.9183 
val --- avg_loss: 3.5173, acc: 0.8325  
update best loss 

epoch: 6 avg_loss: 0.7504, acc: 0.9435 
val --- avg_loss: 3.0536, acc: 0.8373  
update best loss 

epoch: 7 avg_loss: 0.5609, acc: 0.9533 
val --- avg_loss: 3.9974, acc: 0.7847  

epoch: 8 avg_loss: 0.6243, acc: 0.9527 
val --- avg_loss: 4.2657, acc: 0.8278  

epoch: 9 avg_loss: 0.4738, acc: 0.9642 
val --- avg_loss: 3.2163, acc: 0.8565  

epoch: 10 avg_loss: 0.3750, acc: 0.9719 
val --- avg_loss: 2.9358, acc: 0.8373  
update best loss 

epoch: 11 avg_loss: 0.3573, acc: 0.9716 
val --- avg_loss: 3.1324, acc: 0.8469  

epoch: 12 avg_loss: 0.2305, acc: 0.9805 
val --- avg_loss: 2.8828, acc: 0.8325  
update best loss 

epoch: 13 avg_loss: 0.1151, acc: 0.9920 
val --- avg_loss: 2.5265, acc: 0.8373  
update best loss 

epoch: 14 avg_loss: 0.1601, acc: 0.9865 
val --- avg_loss: 2.2955, acc: 0.8469  
update best loss 

epoch: 15 avg_loss: 0.0791, acc: 0.9931 
val --- avg_loss: 2.9668, acc: 0.8565  

epoch: 16 avg_loss: 0.1485, acc: 0.9874 
val --- avg_loss: 3.2135, acc: 0.8373  

epoch: 17 avg_loss: 0.1668, acc: 0.9834 
val --- avg_loss: 2.9944, acc: 0.8421  

epoch: 18 avg_loss: 0.2299, acc: 0.9805 
val --- avg_loss: 3.2734, acc: 0.8565  

epoch: 19 avg_loss: 0.2122, acc: 0.9842 
val --- avg_loss: 2.7951, acc: 0.8660  

epoch: 20 avg_loss: 0.0950, acc: 0.9937 
val --- avg_loss: 3.1339, acc: 0.8565  

epoch: 21 avg_loss: 0.0847, acc: 0.9937 
val --- avg_loss: 3.1426, acc: 0.8612  

epoch: 22 avg_loss: 0.0555, acc: 0.9960 
val --- avg_loss: 3.0462, acc: 0.8708  

epoch: 23 avg_loss: 0.0268, acc: 0.9977 
val --- avg_loss: 2.9639, acc: 0.8660  

epoch: 24 avg_loss: 0.0339, acc: 0.9974 
val --- avg_loss: 2.7268, acc: 0.8708  

epoch: 25 avg_loss: 0.0094, acc: 0.9991 
val --- avg_loss: 2.7461, acc: 0.8708  

epoch: 26 avg_loss: 0.0212, acc: 0.9997 
val --- avg_loss: 2.7266, acc: 0.8708  

epoch: 27 avg_loss: 0.0028, acc: 0.9997 
val --- avg_loss: 2.7159, acc: 0.8708  

epoch: 28 avg_loss: 0.0012, acc: 0.9994 
val --- avg_loss: 2.6778, acc: 0.8756  

epoch: 29 avg_loss: 0.0000, acc: 1.0000 
val --- avg_loss: 2.6723, acc: 0.8804  

epoch: 30 avg_loss: 0.0000, acc: 1.0000 
val --- avg_loss: 2.6682, acc: 0.8804  

epoch: 31 avg_loss: 0.0000, acc: 1.0000 
val --- avg_loss: 2.6644, acc: 0.8804  
