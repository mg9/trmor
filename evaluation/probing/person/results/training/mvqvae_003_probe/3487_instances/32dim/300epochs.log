
number of params: 3584 
Namespace(batchsize=128, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=300, fig_path='evaluation/probing/person/results/training/mvqvae_003_probe/3487_instances/32dim/300epochs.png', log_path='evaluation/probing/person/results/training/mvqvae_003_probe/3487_instances/32dim/300epochs.log', logger=<common.utils.Logger object at 0x7f7dcfb8ccd0>, lr=0.001, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='mvqvae_003_probe', model=VQVAE_Probe(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_2): Linear(in_features=512, out_features=512, bias=False)
  (linear_3): Linear(in_features=512, out_features=512, bias=False)
  (linear_4): Linear(in_features=512, out_features=512, bias=False)
  (vq_layer): VectorQuantizer(
    (embedding): Embedding(710, 512)
  )
  (vq_layer_2): VectorQuantizer(
    (embedding): Embedding(5, 512)
  )
  (vq_layer_3): VectorQuantizer(
    (embedding): Embedding(6, 512)
  )
  (vq_layer_4): VectorQuantizer(
    (embedding): Embedding(2, 512)
  )
  (linear): Linear(in_features=512, out_features=7, bias=False)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/person/results/training/mvqvae_003_probe/3487_instances/32dim/', nh=512, ni=256, num_embeddings=710, nz=512, opt='Adam', pretrained_model=VQVAE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (vq_layer): VectorQuantizer(
    (embedding): Embedding(710, 512)
  )
  (linear_2): Linear(in_features=512, out_features=512, bias=False)
  (linear_3): Linear(in_features=512, out_features=512, bias=False)
  (linear_4): Linear(in_features=512, out_features=512, bias=False)
  (vq_layer_2): VectorQuantizer(
    (embedding): Embedding(5, 512)
  )
  (vq_layer_3): VectorQuantizer(
    (embedding): Embedding(6, 512)
  )
  (vq_layer_4): VectorQuantizer(
    (embedding): Embedding(2, 512)
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(32, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=32, bias=False)
    (loss): CrossEntropyLoss()
  )
), save_path='evaluation/probing/person/results/training/mvqvae_003_probe/3487_instances/32dim/300epochs.pt', seq_to_no_pad='surface', task='surf2person', trndata='evaluation/probing/person/data/sosimple.new.trn.combined.txt', trnsize=3487, tstdata='evaluation/probing/person/data/sosimple.new.seenroots.val.txt', tstsize=209, valdata='evaluation/probing/person/data/sosimple.new.seenroots.val.txt', valsize=209)

encoder.embed.weight, torch.Size([32, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
linear_2.weight, torch.Size([512, 512]): False
linear_3.weight, torch.Size([512, 512]): False
linear_4.weight, torch.Size([512, 512]): False
vq_layer.embedding.weight, torch.Size([710, 512]): False
vq_layer_2.embedding.weight, torch.Size([5, 512]): False
vq_layer_3.embedding.weight, torch.Size([6, 512]): False
vq_layer_4.embedding.weight, torch.Size([2, 512]): False
linear.weight, torch.Size([7, 512]): True
epoch: 0 avg_loss: 1.6941, acc: 0.3980 

epoch: 1 avg_loss: 1.5367, acc: 0.4680 

epoch: 2 avg_loss: 1.5437, acc: 0.4680 

epoch: 3 avg_loss: 1.5366, acc: 0.4680 

epoch: 4 avg_loss: 1.5345, acc: 0.4680 

epoch: 5 avg_loss: 1.5294, acc: 0.4680 

epoch: 6 avg_loss: 1.5223, acc: 0.4680 

epoch: 7 avg_loss: 1.5284, acc: 0.4680 

epoch: 8 avg_loss: 1.5273, acc: 0.4680 

epoch: 9 avg_loss: 1.5276, acc: 0.4680 

epoch: 10 avg_loss: 1.5263, acc: 0.4680 

epoch: 11 avg_loss: 1.5240, acc: 0.4680 

epoch: 12 avg_loss: 1.5337, acc: 0.4680 

epoch: 13 avg_loss: 1.5234, acc: 0.4680 

epoch: 14 avg_loss: 1.5304, acc: 0.4680 

epoch: 15 avg_loss: 1.5313, acc: 0.4680 

epoch: 16 avg_loss: 1.5251, acc: 0.4680 

epoch: 17 avg_loss: 1.5399, acc: 0.4680 

epoch: 18 avg_loss: 1.5167, acc: 0.4680 

epoch: 19 avg_loss: 1.5225, acc: 0.4680 

epoch: 20 avg_loss: 1.5315, acc: 0.4680 

epoch: 21 avg_loss: 1.5338, acc: 0.4680 

epoch: 22 avg_loss: 1.5336, acc: 0.4680 

epoch: 23 avg_loss: 1.5205, acc: 0.4680 

epoch: 24 avg_loss: 1.5339, acc: 0.4680 

epoch: 25 avg_loss: 1.5304, acc: 0.4680 

epoch: 26 avg_loss: 1.5241, acc: 0.4680 

epoch: 27 avg_loss: 1.5254, acc: 0.4680 

epoch: 28 avg_loss: 1.5160, acc: 0.4680 

epoch: 29 avg_loss: 1.5144, acc: 0.4680 

epoch: 30 avg_loss: 1.5250, acc: 0.4680 

epoch: 31 avg_loss: 1.5304, acc: 0.4680 

epoch: 32 avg_loss: 1.5212, acc: 0.4680 

epoch: 33 avg_loss: 1.5202, acc: 0.4680 

epoch: 34 avg_loss: 1.5259, acc: 0.4680 

epoch: 35 avg_loss: 1.5233, acc: 0.4680 

epoch: 36 avg_loss: 1.5207, acc: 0.4680 

epoch: 37 avg_loss: 1.5206, acc: 0.4680 

epoch: 38 avg_loss: 1.5209, acc: 0.4680 

epoch: 39 avg_loss: 1.5234, acc: 0.4680 

epoch: 40 avg_loss: 1.5227, acc: 0.4680 

epoch: 41 avg_loss: 1.5336, acc: 0.4680 

epoch: 42 avg_loss: 1.5184, acc: 0.4680 

epoch: 43 avg_loss: 1.5208, acc: 0.4680 

epoch: 44 avg_loss: 1.5266, acc: 0.4680 

epoch: 45 avg_loss: 1.5206, acc: 0.4680 

epoch: 46 avg_loss: 1.5265, acc: 0.4680 

epoch: 47 avg_loss: 1.5220, acc: 0.4680 

epoch: 48 avg_loss: 1.5293, acc: 0.4680 

epoch: 49 avg_loss: 1.5252, acc: 0.4680 

epoch: 50 avg_loss: 1.5261, acc: 0.4680 

epoch: 51 avg_loss: 1.5318, acc: 0.4680 

epoch: 52 avg_loss: 1.5227, acc: 0.4680 

epoch: 53 avg_loss: 1.5262, acc: 0.4680 

epoch: 54 avg_loss: 1.5204, acc: 0.4680 

epoch: 55 avg_loss: 1.5260, acc: 0.4680 

epoch: 56 avg_loss: 1.5218, acc: 0.4680 

epoch: 57 avg_loss: 1.5257, acc: 0.4680 

epoch: 58 avg_loss: 1.5193, acc: 0.4680 

epoch: 59 avg_loss: 1.5252, acc: 0.4680 

epoch: 60 avg_loss: 1.5328, acc: 0.4680 

epoch: 61 avg_loss: 1.5304, acc: 0.4680 

epoch: 62 avg_loss: 1.5532, acc: 0.4680 

epoch: 63 avg_loss: 1.5300, acc: 0.4680 

epoch: 64 avg_loss: 1.5297, acc: 0.4680 

epoch: 65 avg_loss: 1.5341, acc: 0.4680 

epoch: 66 avg_loss: 1.5358, acc: 0.4680 

epoch: 67 avg_loss: 1.5321, acc: 0.4680 

epoch: 68 avg_loss: 1.5358, acc: 0.4680 

epoch: 69 avg_loss: 1.5246, acc: 0.4680 

epoch: 70 avg_loss: 1.5194, acc: 0.4680 

epoch: 71 avg_loss: 1.5354, acc: 0.4680 

epoch: 72 avg_loss: 1.5334, acc: 0.4680 

epoch: 73 avg_loss: 1.5178, acc: 0.4680 

epoch: 74 avg_loss: 1.5260, acc: 0.4680 
