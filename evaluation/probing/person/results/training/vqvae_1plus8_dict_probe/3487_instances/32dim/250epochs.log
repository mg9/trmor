
number of params: 3584 
Namespace(batchsize=64, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=250, fig_path='evaluation/probing/person/results/training/vqvae_1plus8_dict_probe/3487_instances/32dim/250epochs.png', log_path='evaluation/probing/person/results/training/vqvae_1plus8_dict_probe/3487_instances/32dim/250epochs.log', logger=<common.utils.Logger object at 0x7f1ab3608350>, lr=0.001, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='vqvae_1plus8_dict_probe', model=VQVAE_Probe(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (linear_2): Linear(in_features=512, out_features=64, bias=True)
  (linear_3): Linear(in_features=512, out_features=64, bias=True)
  (linear_4): Linear(in_features=512, out_features=64, bias=True)
  (linear_5): Linear(in_features=512, out_features=64, bias=True)
  (linear_6): Linear(in_features=512, out_features=64, bias=True)
  (linear_7): Linear(in_features=512, out_features=64, bias=True)
  (linear_8): Linear(in_features=512, out_features=64, bias=True)
  (linear_9): Linear(in_features=512, out_features=64, bias=True)
  (vq_layer): VectorQuantizer(
    (embedding): Embedding(704, 512)
  )
  (vq_layer_2): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_3): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_4): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_5): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_6): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_7): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_8): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_9): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (linear): Linear(in_features=512, out_features=7, bias=False)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/person/results/training/vqvae_1plus8_dict_probe/3487_instances/32dim/', nh=512, ni=256, num_embeddings=704, nz=512, opt='Adam', pretrained_model=VQVAE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
  )
  (vq_layer): VectorQuantizer(
    (embedding): Embedding(704, 512)
  )
  (linear_2): Linear(in_features=512, out_features=64, bias=True)
  (linear_3): Linear(in_features=512, out_features=64, bias=True)
  (linear_4): Linear(in_features=512, out_features=64, bias=True)
  (linear_5): Linear(in_features=512, out_features=64, bias=True)
  (linear_6): Linear(in_features=512, out_features=64, bias=True)
  (linear_7): Linear(in_features=512, out_features=64, bias=True)
  (linear_8): Linear(in_features=512, out_features=64, bias=True)
  (linear_9): Linear(in_features=512, out_features=64, bias=True)
  (vq_layer_2): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_3): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_4): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_5): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_6): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_7): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_8): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (vq_layer_9): VectorQuantizer(
    (embedding): Embedding(16, 64)
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(32, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=32, bias=False)
    (loss): CrossEntropyLoss()
  )
), save_path='evaluation/probing/person/results/training/vqvae_1plus8_dict_probe/3487_instances/32dim/250epochs.pt', seq_to_no_pad='surface', task='surf2person', trndata='evaluation/probing/person/data/sosimple.new.trn.combined.txt', trnsize=3487, tstdata='evaluation/probing/person/data/sosimple.new.seenroots.val.txt', tstsize=209, valdata='evaluation/probing/person/data/sosimple.new.seenroots.val.txt', valsize=209)

encoder.embed.weight, torch.Size([32, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
linear_2.weight, torch.Size([64, 512]): False
linear_2.bias, torch.Size([64]): False
linear_3.weight, torch.Size([64, 512]): False
linear_3.bias, torch.Size([64]): False
linear_4.weight, torch.Size([64, 512]): False
linear_4.bias, torch.Size([64]): False
linear_5.weight, torch.Size([64, 512]): False
linear_5.bias, torch.Size([64]): False
linear_6.weight, torch.Size([64, 512]): False
linear_6.bias, torch.Size([64]): False
linear_7.weight, torch.Size([64, 512]): False
linear_7.bias, torch.Size([64]): False
linear_8.weight, torch.Size([64, 512]): False
linear_8.bias, torch.Size([64]): False
linear_9.weight, torch.Size([64, 512]): False
linear_9.bias, torch.Size([64]): False
vq_layer.embedding.weight, torch.Size([704, 512]): False
vq_layer_2.embedding.weight, torch.Size([16, 64]): False
vq_layer_3.embedding.weight, torch.Size([16, 64]): False
vq_layer_4.embedding.weight, torch.Size([16, 64]): False
vq_layer_5.embedding.weight, torch.Size([16, 64]): False
vq_layer_6.embedding.weight, torch.Size([16, 64]): False
vq_layer_7.embedding.weight, torch.Size([16, 64]): False
vq_layer_8.embedding.weight, torch.Size([16, 64]): False
vq_layer_9.embedding.weight, torch.Size([16, 64]): False
linear.weight, torch.Size([7, 512]): True
epoch: 0 avg_loss: 1.2456, acc: 0.6874 

epoch: 1 avg_loss: 0.7370, acc: 0.8099 

epoch: 2 avg_loss: 0.6291, acc: 0.8325 

epoch: 3 avg_loss: 0.5773, acc: 0.8388 

epoch: 4 avg_loss: 0.5497, acc: 0.8480 

epoch: 5 avg_loss: 0.5309, acc: 0.8497 

epoch: 6 avg_loss: 0.5197, acc: 0.8489 

epoch: 7 avg_loss: 0.5101, acc: 0.8486 

epoch: 8 avg_loss: 0.5068, acc: 0.8494 

epoch: 9 avg_loss: 0.4985, acc: 0.8543 

epoch: 10 avg_loss: 0.4944, acc: 0.8555 

epoch: 11 avg_loss: 0.4913, acc: 0.8543 

epoch: 12 avg_loss: 0.4858, acc: 0.8589 

epoch: 13 avg_loss: 0.4835, acc: 0.8555 

epoch: 14 avg_loss: 0.4809, acc: 0.8546 

epoch: 15 avg_loss: 0.4795, acc: 0.8569 

epoch: 16 avg_loss: 0.4786, acc: 0.8586 

epoch: 17 avg_loss: 0.4769, acc: 0.8560 

epoch: 18 avg_loss: 0.4764, acc: 0.8578 

epoch: 19 avg_loss: 0.4741, acc: 0.8595 

epoch: 20 avg_loss: 0.4743, acc: 0.8557 

epoch: 21 avg_loss: 0.4719, acc: 0.8595 

epoch: 22 avg_loss: 0.4727, acc: 0.8572 

epoch: 23 avg_loss: 0.4707, acc: 0.8583 

epoch: 24 avg_loss: 0.4712, acc: 0.8586 

epoch: 25 avg_loss: 0.4689, acc: 0.8569 

epoch: 26 avg_loss: 0.4670, acc: 0.8595 

epoch: 27 avg_loss: 0.4670, acc: 0.8603 

epoch: 28 avg_loss: 0.4696, acc: 0.8569 

epoch: 29 avg_loss: 0.4672, acc: 0.8603 

epoch: 30 avg_loss: 0.4639, acc: 0.8615 

epoch: 31 avg_loss: 0.4647, acc: 0.8580 

epoch: 32 avg_loss: 0.4663, acc: 0.8575 

epoch: 33 avg_loss: 0.4642, acc: 0.8578 

epoch: 34 avg_loss: 0.4627, acc: 0.8580 

epoch: 35 avg_loss: 0.4644, acc: 0.8592 

epoch: 36 avg_loss: 0.4619, acc: 0.8572 

epoch: 37 avg_loss: 0.4613, acc: 0.8598 

epoch: 38 avg_loss: 0.4620, acc: 0.8557 

epoch: 39 avg_loss: 0.4640, acc: 0.8580 

epoch: 40 avg_loss: 0.4599, acc: 0.8555 

epoch: 41 avg_loss: 0.4601, acc: 0.8623 

epoch: 42 avg_loss: 0.4578, acc: 0.8603 

epoch: 43 avg_loss: 0.4597, acc: 0.8592 

epoch: 44 avg_loss: 0.4596, acc: 0.8606 

epoch: 45 avg_loss: 0.4604, acc: 0.8615 

epoch: 46 avg_loss: 0.4579, acc: 0.8572 

epoch: 47 avg_loss: 0.4565, acc: 0.8603 

epoch: 48 avg_loss: 0.4587, acc: 0.8615 

epoch: 49 avg_loss: 0.4578, acc: 0.8575 

epoch: 50 avg_loss: 0.4556, acc: 0.8606 

epoch: 51 avg_loss: 0.4591, acc: 0.8566 

epoch: 52 avg_loss: 0.4563, acc: 0.8586 

epoch: 53 avg_loss: 0.4550, acc: 0.8609 

epoch: 54 avg_loss: 0.4557, acc: 0.8618 

epoch: 55 avg_loss: 0.4545, acc: 0.8621 

epoch: 56 avg_loss: 0.4548, acc: 0.8623 

epoch: 57 avg_loss: 0.4543, acc: 0.8609 

epoch: 58 avg_loss: 0.4551, acc: 0.8612 

epoch: 59 avg_loss: 0.4561, acc: 0.8609 

epoch: 60 avg_loss: 0.4536, acc: 0.8626 

epoch: 61 avg_loss: 0.4515, acc: 0.8603 

epoch: 62 avg_loss: 0.4531, acc: 0.8638 

epoch: 63 avg_loss: 0.4552, acc: 0.8560 

epoch: 64 avg_loss: 0.4528, acc: 0.8632 

epoch: 65 avg_loss: 0.4513, acc: 0.8623 

epoch: 66 avg_loss: 0.4524, acc: 0.8572 

epoch: 67 avg_loss: 0.4499, acc: 0.8612 

epoch: 68 avg_loss: 0.4525, acc: 0.8618 

epoch: 69 avg_loss: 0.4497, acc: 0.8621 

epoch: 70 avg_loss: 0.4498, acc: 0.8603 

epoch: 71 avg_loss: 0.4513, acc: 0.8612 

epoch: 72 avg_loss: 0.4497, acc: 0.8626 

epoch: 73 avg_loss: 0.4500, acc: 0.8612 

epoch: 74 avg_loss: 0.4505, acc: 0.8612 

epoch: 75 avg_loss: 0.4507, acc: 0.8618 

epoch: 76 avg_loss: 0.4510, acc: 0.8644 

epoch: 77 avg_loss: 0.4474, acc: 0.8609 

epoch: 78 avg_loss: 0.4476, acc: 0.8635 

epoch: 79 avg_loss: 0.4491, acc: 0.8609 

epoch: 80 avg_loss: 0.4485, acc: 0.8618 

epoch: 81 avg_loss: 0.4493, acc: 0.8598 

epoch: 82 avg_loss: 0.4478, acc: 0.8609 

epoch: 83 avg_loss: 0.4465, acc: 0.8621 

epoch: 84 avg_loss: 0.4457, acc: 0.8635 

epoch: 85 avg_loss: 0.4456, acc: 0.8655 

epoch: 86 avg_loss: 0.4482, acc: 0.8612 

epoch: 87 avg_loss: 0.4451, acc: 0.8641 

epoch: 88 avg_loss: 0.4487, acc: 0.8638 

epoch: 89 avg_loss: 0.4440, acc: 0.8618 

epoch: 90 avg_loss: 0.4443, acc: 0.8638 

epoch: 91 avg_loss: 0.4463, acc: 0.8655 

epoch: 92 avg_loss: 0.4452, acc: 0.8621 

epoch: 93 avg_loss: 0.4450, acc: 0.8612 

epoch: 94 avg_loss: 0.4462, acc: 0.8629 

epoch: 95 avg_loss: 0.4448, acc: 0.8621 

epoch: 96 avg_loss: 0.4439, acc: 0.8644 

epoch: 97 avg_loss: 0.4424, acc: 0.8632 

epoch: 98 avg_loss: 0.4438, acc: 0.8655 

epoch: 99 avg_loss: 0.4419, acc: 0.8623 

epoch: 100 avg_loss: 0.4423, acc: 0.8641 

epoch: 101 avg_loss: 0.4412, acc: 0.8644 

epoch: 102 avg_loss: 0.4428, acc: 0.8652 

epoch: 103 avg_loss: 0.4425, acc: 0.8635 

epoch: 104 avg_loss: 0.4415, acc: 0.8649 

epoch: 105 avg_loss: 0.4428, acc: 0.8652 

epoch: 106 avg_loss: 0.4412, acc: 0.8649 

epoch: 107 avg_loss: 0.4401, acc: 0.8649 

epoch: 108 avg_loss: 0.4408, acc: 0.8658 

epoch: 109 avg_loss: 0.4423, acc: 0.8626 

epoch: 110 avg_loss: 0.4399, acc: 0.8615 

epoch: 111 avg_loss: 0.4399, acc: 0.8644 

epoch: 112 avg_loss: 0.4381, acc: 0.8661 

epoch: 113 avg_loss: 0.4408, acc: 0.8661 

epoch: 114 avg_loss: 0.4390, acc: 0.8678 

epoch: 115 avg_loss: 0.4403, acc: 0.8635 

epoch: 116 avg_loss: 0.4460, acc: 0.8612 

epoch: 117 avg_loss: 0.4387, acc: 0.8658 

epoch: 118 avg_loss: 0.4402, acc: 0.8664 

epoch: 119 avg_loss: 0.4393, acc: 0.8629 

epoch: 120 avg_loss: 0.4378, acc: 0.8664 

epoch: 121 avg_loss: 0.4395, acc: 0.8623 

epoch: 122 avg_loss: 0.4380, acc: 0.8646 

epoch: 123 avg_loss: 0.4384, acc: 0.8638 

epoch: 124 avg_loss: 0.4380, acc: 0.8655 

epoch: 125 avg_loss: 0.4378, acc: 0.8669 

epoch: 126 avg_loss: 0.4359, acc: 0.8646 

epoch: 127 avg_loss: 0.4374, acc: 0.8649 

epoch: 128 avg_loss: 0.4370, acc: 0.8646 

epoch: 129 avg_loss: 0.4365, acc: 0.8658 

epoch: 130 avg_loss: 0.4374, acc: 0.8655 

epoch: 131 avg_loss: 0.4372, acc: 0.8629 

epoch: 132 avg_loss: 0.4363, acc: 0.8669 

epoch: 133 avg_loss: 0.4379, acc: 0.8687 

epoch: 134 avg_loss: 0.4350, acc: 0.8649 

epoch: 135 avg_loss: 0.4391, acc: 0.8638 

epoch: 136 avg_loss: 0.4349, acc: 0.8641 

epoch: 137 avg_loss: 0.4374, acc: 0.8669 

epoch: 138 avg_loss: 0.4372, acc: 0.8646 

epoch: 139 avg_loss: 0.4356, acc: 0.8638 

epoch: 140 avg_loss: 0.4362, acc: 0.8669 

epoch: 141 avg_loss: 0.4334, acc: 0.8666 

epoch: 142 avg_loss: 0.4325, acc: 0.8652 

epoch: 143 avg_loss: 0.4349, acc: 0.8666 

epoch: 144 avg_loss: 0.4317, acc: 0.8658 

epoch: 145 avg_loss: 0.4345, acc: 0.8678 

epoch: 146 avg_loss: 0.4359, acc: 0.8649 

epoch: 147 avg_loss: 0.4343, acc: 0.8664 

epoch: 148 avg_loss: 0.4379, acc: 0.8621 

epoch: 149 avg_loss: 0.4339, acc: 0.8664 

epoch: 150 avg_loss: 0.4329, acc: 0.8649 

epoch: 151 avg_loss: 0.4306, acc: 0.8644 

epoch: 152 avg_loss: 0.4320, acc: 0.8669 

epoch: 153 avg_loss: 0.4309, acc: 0.8672 

epoch: 154 avg_loss: 0.4321, acc: 0.8641 

epoch: 155 avg_loss: 0.4319, acc: 0.8672 

epoch: 156 avg_loss: 0.4316, acc: 0.8646 

epoch: 157 avg_loss: 0.4325, acc: 0.8669 

epoch: 158 avg_loss: 0.4332, acc: 0.8649 

epoch: 159 avg_loss: 0.4311, acc: 0.8701 

epoch: 160 avg_loss: 0.4307, acc: 0.8635 

epoch: 161 avg_loss: 0.4298, acc: 0.8672 

epoch: 162 avg_loss: 0.4321, acc: 0.8675 

epoch: 163 avg_loss: 0.4305, acc: 0.8666 

epoch: 164 avg_loss: 0.4316, acc: 0.8666 

epoch: 165 avg_loss: 0.4299, acc: 0.8661 

epoch: 166 avg_loss: 0.4313, acc: 0.8641 

epoch: 167 avg_loss: 0.4312, acc: 0.8664 

epoch: 168 avg_loss: 0.4284, acc: 0.8669 

epoch: 169 avg_loss: 0.4285, acc: 0.8655 

epoch: 170 avg_loss: 0.4288, acc: 0.8687 

epoch: 171 avg_loss: 0.4299, acc: 0.8678 

epoch: 172 avg_loss: 0.4299, acc: 0.8664 

epoch: 173 avg_loss: 0.4298, acc: 0.8652 

epoch: 174 avg_loss: 0.4284, acc: 0.8678 

epoch: 175 avg_loss: 0.4283, acc: 0.8661 

epoch: 176 avg_loss: 0.4288, acc: 0.8661 

epoch: 177 avg_loss: 0.4296, acc: 0.8675 

epoch: 178 avg_loss: 0.4280, acc: 0.8672 

epoch: 179 avg_loss: 0.4282, acc: 0.8675 

epoch: 180 avg_loss: 0.4265, acc: 0.8701 

epoch: 181 avg_loss: 0.4297, acc: 0.8655 

epoch: 182 avg_loss: 0.4314, acc: 0.8661 

epoch: 183 avg_loss: 0.4290, acc: 0.8666 

epoch: 184 avg_loss: 0.4282, acc: 0.8687 

epoch: 185 avg_loss: 0.4276, acc: 0.8678 

epoch: 186 avg_loss: 0.4293, acc: 0.8629 

epoch: 187 avg_loss: 0.4249, acc: 0.8692 

epoch: 188 avg_loss: 0.4263, acc: 0.8658 

epoch: 189 avg_loss: 0.4280, acc: 0.8658 

epoch: 190 avg_loss: 0.4278, acc: 0.8678 

epoch: 191 avg_loss: 0.4266, acc: 0.8661 

epoch: 192 avg_loss: 0.4265, acc: 0.8692 

epoch: 193 avg_loss: 0.4241, acc: 0.8709 

epoch: 194 avg_loss: 0.4260, acc: 0.8655 

epoch: 195 avg_loss: 0.4255, acc: 0.8675 

epoch: 196 avg_loss: 0.4256, acc: 0.8692 

epoch: 197 avg_loss: 0.4256, acc: 0.8655 

epoch: 198 avg_loss: 0.4255, acc: 0.8646 

epoch: 199 avg_loss: 0.4255, acc: 0.8684 

epoch: 200 avg_loss: 0.4249, acc: 0.8678 

epoch: 201 avg_loss: 0.4241, acc: 0.8687 

epoch: 202 avg_loss: 0.4231, acc: 0.8687 

epoch: 203 avg_loss: 0.4236, acc: 0.8666 

epoch: 204 avg_loss: 0.4258, acc: 0.8707 

epoch: 205 avg_loss: 0.4229, acc: 0.8675 

epoch: 206 avg_loss: 0.4266, acc: 0.8675 

epoch: 207 avg_loss: 0.4240, acc: 0.8669 

epoch: 208 avg_loss: 0.4249, acc: 0.8664 

epoch: 209 avg_loss: 0.4244, acc: 0.8687 

epoch: 210 avg_loss: 0.4230, acc: 0.8664 

epoch: 211 avg_loss: 0.4227, acc: 0.8669 

epoch: 212 avg_loss: 0.4237, acc: 0.8652 

epoch: 213 avg_loss: 0.4219, acc: 0.8666 

epoch: 214 avg_loss: 0.4246, acc: 0.8698 

epoch: 215 avg_loss: 0.4245, acc: 0.8678 

epoch: 216 avg_loss: 0.4231, acc: 0.8704 

epoch: 217 avg_loss: 0.4212, acc: 0.8684 

epoch: 218 avg_loss: 0.4227, acc: 0.8669 

epoch: 219 avg_loss: 0.4222, acc: 0.8678 

epoch: 220 avg_loss: 0.4220, acc: 0.8684 

epoch: 221 avg_loss: 0.4223, acc: 0.8701 

epoch: 222 avg_loss: 0.4238, acc: 0.8658 

epoch: 223 avg_loss: 0.4223, acc: 0.8681 

epoch: 224 avg_loss: 0.4214, acc: 0.8712 

epoch: 225 avg_loss: 0.4204, acc: 0.8701 

epoch: 226 avg_loss: 0.4221, acc: 0.8669 

epoch: 227 avg_loss: 0.4209, acc: 0.8661 

epoch: 228 avg_loss: 0.4200, acc: 0.8704 

epoch: 229 avg_loss: 0.4199, acc: 0.8692 

epoch: 230 avg_loss: 0.4202, acc: 0.8689 

epoch: 231 avg_loss: 0.4198, acc: 0.8718 

epoch: 232 avg_loss: 0.4198, acc: 0.8658 

epoch: 233 avg_loss: 0.4195, acc: 0.8689 

epoch: 234 avg_loss: 0.4211, acc: 0.8675 

epoch: 235 avg_loss: 0.4218, acc: 0.8675 

epoch: 236 avg_loss: 0.4178, acc: 0.8698 

epoch: 237 avg_loss: 0.4214, acc: 0.8689 

epoch: 238 avg_loss: 0.4201, acc: 0.8704 

epoch: 239 avg_loss: 0.4195, acc: 0.8684 

epoch: 240 avg_loss: 0.4203, acc: 0.8692 

epoch: 241 avg_loss: 0.4219, acc: 0.8715 

epoch: 242 avg_loss: 0.4189, acc: 0.8689 

epoch: 243 avg_loss: 0.4194, acc: 0.8681 

epoch: 244 avg_loss: 0.4206, acc: 0.8684 

epoch: 245 avg_loss: 0.4180, acc: 0.8707 

epoch: 246 avg_loss: 0.4196, acc: 0.8664 

epoch: 247 avg_loss: 0.4200, acc: 0.8695 

epoch: 248 avg_loss: 0.4182, acc: 0.8709 

epoch: 249 avg_loss: 0.4189, acc: 0.8681 
