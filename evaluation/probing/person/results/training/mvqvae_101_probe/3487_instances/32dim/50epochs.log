
number of params: 3584 
Namespace(batchsize=64, beta=0.25, dec_dropout_in=0.0, dec_dropout_out=0.0, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=512, epochs=50, fig_path='evaluation/probing/person/results/training/mvqvae_101_probe/3487_instances/32dim/50epochs.png', log_path='evaluation/probing/person/results/training/mvqvae_101_probe/3487_instances/32dim/50epochs.log', logger=<common.utils.Logger object at 0x7fd76efefe90>, lr=0.001, maxtrnsize=57769, maxtstsize=10000, maxvalsize=10000, mname='mvqvae_101_probe', model=AE_Probe(
  (encoder): AE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=512, out_features=512, bias=False)
  )
  (linear): Linear(in_features=512, out_features=7, bias=False)
  (loss): CrossEntropyLoss()
), modelname='evaluation/probing/person/results/training/mvqvae_101_probe/3487_instances/32dim/', nh=512, ni=256, num_embeddings=704, nz=512, opt='Adam', pretrained_model=AE(
  (encoder): AE_Encoder(
    (embed): Embedding(32, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=512, out_features=512, bias=False)
  )
  (decoder): AE_Decoder(
    (embed): Embedding(32, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (dropout_out): Dropout(p=0.0, inplace=False)
    (trans_linear): Linear(in_features=512, out_features=512, bias=False)
    (lstm): LSTM(768, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=32, bias=False)
    (loss): CrossEntropyLoss()
  )
), save_path='evaluation/probing/person/results/training/mvqvae_101_probe/3487_instances/32dim/50epochs.pt', seq_to_no_pad='surface', task='surf2person', trndata='evaluation/probing/person/data/sosimple.new.trn.combined.txt', trnsize=3487, tstdata='evaluation/probing/person/data/sosimple.new.seenroots.val.txt', tstsize=209, valdata='evaluation/probing/person/data/sosimple.new.seenroots.val.txt', valsize=209)

encoder.embed.weight, torch.Size([32, 256]): False
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): False
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): False
encoder.lstm.bias_ih_l0, torch.Size([2048]): False
encoder.lstm.bias_hh_l0, torch.Size([2048]): False
encoder.linear.weight, torch.Size([512, 512]): False
linear.weight, torch.Size([7, 512]): True
epoch: 0 avg_loss: 1.2565, acc: 0.5784 

epoch: 1 avg_loss: 0.6121, acc: 0.8741 

epoch: 2 avg_loss: 0.3752, acc: 0.9633 

epoch: 3 avg_loss: 0.2599, acc: 0.9842 

epoch: 4 avg_loss: 0.1923, acc: 0.9908 

epoch: 5 avg_loss: 0.1514, acc: 0.9934 

epoch: 6 avg_loss: 0.1235, acc: 0.9943 

epoch: 7 avg_loss: 0.1038, acc: 0.9951 

epoch: 8 avg_loss: 0.0883, acc: 0.9957 

epoch: 9 avg_loss: 0.0772, acc: 0.9963 

epoch: 10 avg_loss: 0.0678, acc: 0.9968 

epoch: 11 avg_loss: 0.0603, acc: 0.9971 

epoch: 12 avg_loss: 0.0541, acc: 0.9977 

epoch: 13 avg_loss: 0.0488, acc: 0.9980 

epoch: 14 avg_loss: 0.0443, acc: 0.9980 

epoch: 15 avg_loss: 0.0406, acc: 0.9983 

epoch: 16 avg_loss: 0.0373, acc: 0.9983 

epoch: 17 avg_loss: 0.0344, acc: 0.9983 

epoch: 18 avg_loss: 0.0320, acc: 0.9989 

epoch: 19 avg_loss: 0.0297, acc: 0.9991 

epoch: 20 avg_loss: 0.0277, acc: 0.9991 

epoch: 21 avg_loss: 0.0260, acc: 0.9991 

epoch: 22 avg_loss: 0.0243, acc: 0.9991 

epoch: 23 avg_loss: 0.0228, acc: 0.9991 

epoch: 24 avg_loss: 0.0214, acc: 0.9991 

epoch: 25 avg_loss: 0.0202, acc: 0.9991 

epoch: 26 avg_loss: 0.0191, acc: 0.9991 

epoch: 27 avg_loss: 0.0180, acc: 0.9991 

epoch: 28 avg_loss: 0.0171, acc: 0.9991 

epoch: 29 avg_loss: 0.0162, acc: 0.9991 

epoch: 30 avg_loss: 0.0154, acc: 0.9991 

epoch: 31 avg_loss: 0.0147, acc: 0.9991 

epoch: 32 avg_loss: 0.0139, acc: 0.9991 

epoch: 33 avg_loss: 0.0133, acc: 0.9994 

epoch: 34 avg_loss: 0.0127, acc: 0.9994 

epoch: 35 avg_loss: 0.0121, acc: 0.9994 

epoch: 36 avg_loss: 0.0115, acc: 0.9994 

epoch: 37 avg_loss: 0.0110, acc: 0.9994 

epoch: 38 avg_loss: 0.0105, acc: 0.9994 

epoch: 39 avg_loss: 0.0101, acc: 0.9994 

epoch: 40 avg_loss: 0.0096, acc: 0.9994 

epoch: 41 avg_loss: 0.0092, acc: 0.9994 

epoch: 42 avg_loss: 0.0089, acc: 0.9994 

epoch: 43 avg_loss: 0.0085, acc: 0.9994 

epoch: 44 avg_loss: 0.0081, acc: 0.9994 

epoch: 45 avg_loss: 0.0078, acc: 0.9994 

epoch: 46 avg_loss: 0.0075, acc: 0.9994 

epoch: 47 avg_loss: 0.0072, acc: 0.9997 

epoch: 48 avg_loss: 0.0069, acc: 0.9994 

epoch: 49 avg_loss: 0.0066, acc: 0.9997 
