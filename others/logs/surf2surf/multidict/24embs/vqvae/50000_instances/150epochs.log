VQVAE(
  (model): EncoderDecoder(
    (encoder): Encoder(
      (rnn): GRU(512, 256, batch_first=True, dropout=0.2, bidirectional=True)
    )
    (decoder): Decoder(
      (attention): BahdanauAttention(
        (key_layer): Linear(in_features=512, out_features=256, bias=False)
        (query_layer): Linear(in_features=256, out_features=256, bias=False)
        (energy_layer): Linear(in_features=256, out_features=1, bias=False)
      )
      (rnn): GRU(1024, 256, batch_first=True, dropout=0.2)
      (bridge): Linear(in_features=512, out_features=256, bias=True)
      (dropout_layer): Dropout(p=0.2, inplace=False)
      (pre_output_layer): Linear(in_features=1280, out_features=256, bias=False)
    )
    (src_embed): Embedding(39, 512)
    (trg_embed): Embedding(39, 512)
    (generator): Generator(
      (proj): Linear(in_features=256, out_features=39, bias=False)
    )
  )
  (multi_vq_layer): MultiVectorQuantizer(
    (embedding_1): Embedding(6, 128)
    (embedding_2): Embedding(6, 128)
    (embedding_3): Embedding(6, 128)
    (embedding_4): Embedding(6, 128)
  )
)beta:0.25
----- Parameters: -----
model.encoder.rnn.weight_ih_l0, torch.Size([768, 512]): True
model.encoder.rnn.weight_hh_l0, torch.Size([768, 256]): True
model.encoder.rnn.bias_ih_l0, torch.Size([768]): True
model.encoder.rnn.bias_hh_l0, torch.Size([768]): True
model.encoder.rnn.weight_ih_l0_reverse, torch.Size([768, 512]): True
model.encoder.rnn.weight_hh_l0_reverse, torch.Size([768, 256]): True
model.encoder.rnn.bias_ih_l0_reverse, torch.Size([768]): True
model.encoder.rnn.bias_hh_l0_reverse, torch.Size([768]): True
model.decoder.attention.key_layer.weight, torch.Size([256, 512]): True
model.decoder.attention.query_layer.weight, torch.Size([256, 256]): True
model.decoder.attention.energy_layer.weight, torch.Size([1, 256]): True
model.decoder.rnn.weight_ih_l0, torch.Size([768, 1024]): True
model.decoder.rnn.weight_hh_l0, torch.Size([768, 256]): True
model.decoder.rnn.bias_ih_l0, torch.Size([768]): True
model.decoder.rnn.bias_hh_l0, torch.Size([768]): True
model.decoder.bridge.weight, torch.Size([256, 512]): True
model.decoder.bridge.bias, torch.Size([256]): True
model.decoder.pre_output_layer.weight, torch.Size([256, 1280]): True
model.src_embed.weight, torch.Size([39, 512]): True
model.trg_embed.weight, torch.Size([39, 512]): True
model.generator.proj.weight, torch.Size([39, 256]): True
multi_vq_layer.embedding_1.weight, torch.Size([6, 128]): True
multi_vq_layer.embedding_2.weight, torch.Size([6, 128]): True
multi_vq_layer.embedding_3.weight, torch.Size([6, 128]): True
multi_vq_layer.embedding_4.weight, torch.Size([6, 128]): True
Epoch 0, ppl: 1.0166,  recon_loss: 18.6235, vq_loss: 2.2974, acc: 0.4654
val -- ppl: 1.0146,  recon_loss: 12.5616, vq_loss: 2.8949, acc: 0.6844 
update best loss
Epoch 1, ppl: 1.0082,  recon_loss: 7.4814, vq_loss: 2.9021, acc: 0.7854
val -- ppl: 1.0085,  recon_loss: 6.1638, vq_loss: 2.8592, acc: 0.8568 
update best loss
Epoch 2, ppl: 1.0057,  recon_loss: 4.3337, vq_loss: 2.8085, acc: 0.8734
val -- ppl: 1.0070,  recon_loss: 4.6674, vq_loss: 2.7548, acc: 0.8904 
update best loss
Epoch 3, ppl: 1.0047,  recon_loss: 3.2345, vq_loss: 2.7060, acc: 0.9057
val -- ppl: 1.0060,  recon_loss: 3.7036, vq_loss: 2.6603, acc: 0.9159 
update best loss
Epoch 4, ppl: 1.0040,  recon_loss: 2.4651, vq_loss: 2.6270, acc: 0.9293
val -- ppl: 1.0052,  recon_loss: 2.8913, vq_loss: 2.5990, acc: 0.9363 
update best loss
Epoch 5, ppl: 1.0037,  recon_loss: 2.0823, vq_loss: 2.5710, acc: 0.9409
val -- ppl: 1.0050,  recon_loss: 2.8040, vq_loss: 2.5666, acc: 0.9379 
update best loss
Epoch 6, ppl: 1.0035,  recon_loss: 1.9339, vq_loss: 2.5503, acc: 0.9461
val -- ppl: 1.0046,  recon_loss: 2.3633, vq_loss: 2.5503, acc: 0.9494 
update best loss
Epoch 7, ppl: 1.0033,  recon_loss: 1.5928, vq_loss: 2.5357, acc: 0.9552
val -- ppl: 1.0043,  recon_loss: 2.0340, vq_loss: 2.5347, acc: 0.9573 
update best loss
Epoch 8, ppl: 1.0031,  recon_loss: 1.3952, vq_loss: 2.5229, acc: 0.9604
val -- ppl: 1.0044,  recon_loss: 2.1490, vq_loss: 2.5287, acc: 0.9557 
Epoch 9, ppl: 1.0030,  recon_loss: 1.3222, vq_loss: 2.5262, acc: 0.9628
val -- ppl: 1.0042,  recon_loss: 1.9036, vq_loss: 2.5383, acc: 0.9626 
update best loss
Epoch 10, ppl: 1.0030,  recon_loss: 1.2284, vq_loss: 2.5286, acc: 0.9652
val -- ppl: 1.0042,  recon_loss: 1.9228, vq_loss: 2.5528, acc: 0.9621 
Epoch 11, ppl: 1.0029,  recon_loss: 1.1116, vq_loss: 2.5324, acc: 0.9687
val -- ppl: 1.0040,  recon_loss: 1.6851, vq_loss: 2.5359, acc: 0.9682 
update best loss
Epoch 12, ppl: 1.0030,  recon_loss: 1.2784, vq_loss: 2.5416, acc: 0.9655
val -- ppl: 1.0040,  recon_loss: 1.7417, vq_loss: 2.5671, acc: 0.9660 
Epoch 13, ppl: 1.0028,  recon_loss: 0.9360, vq_loss: 2.5452, acc: 0.9737
val -- ppl: 1.0041,  recon_loss: 1.7791, vq_loss: 2.5639, acc: 0.9666 
Epoch 14, ppl: 1.0027,  recon_loss: 0.8476, vq_loss: 2.5432, acc: 0.9763
val -- ppl: 1.0038,  recon_loss: 1.4508, vq_loss: 2.5613, acc: 0.9717 
update best loss