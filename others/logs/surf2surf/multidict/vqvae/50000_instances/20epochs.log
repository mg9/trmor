VQVAE(
  (model): EncoderDecoder(
    (encoder): Encoder(
      (rnn): GRU(512, 256, batch_first=True, dropout=0.2, bidirectional=True)
    )
    (decoder): Decoder(
      (attention): BahdanauAttention(
        (key_layer): Linear(in_features=512, out_features=256, bias=False)
        (query_layer): Linear(in_features=256, out_features=256, bias=False)
        (energy_layer): Linear(in_features=256, out_features=1, bias=False)
      )
      (rnn): GRU(1024, 256, batch_first=True, dropout=0.2)
      (bridge): Linear(in_features=512, out_features=256, bias=True)
      (dropout_layer): Dropout(p=0.2, inplace=False)
      (pre_output_layer): Linear(in_features=1280, out_features=256, bias=False)
    )
    (src_embed): Embedding(39, 512)
    (trg_embed): Embedding(39, 512)
    (generator): Generator(
      (proj): Linear(in_features=256, out_features=39, bias=False)
    )
  )
  (multi_vq_layer): MultiVectorQuantizer(
    (embedding_1): Embedding(12, 128)
    (embedding_2): Embedding(12, 128)
    (embedding_3): Embedding(12, 128)
    (embedding_4): Embedding(12, 128)
  )
)beta:0.25
----- Parameters: -----
model.encoder.rnn.weight_ih_l0, torch.Size([768, 512]): True
model.encoder.rnn.weight_hh_l0, torch.Size([768, 256]): True
model.encoder.rnn.bias_ih_l0, torch.Size([768]): True
model.encoder.rnn.bias_hh_l0, torch.Size([768]): True
model.encoder.rnn.weight_ih_l0_reverse, torch.Size([768, 512]): True
model.encoder.rnn.weight_hh_l0_reverse, torch.Size([768, 256]): True
model.encoder.rnn.bias_ih_l0_reverse, torch.Size([768]): True
model.encoder.rnn.bias_hh_l0_reverse, torch.Size([768]): True
model.decoder.attention.key_layer.weight, torch.Size([256, 512]): True
model.decoder.attention.query_layer.weight, torch.Size([256, 256]): True
model.decoder.attention.energy_layer.weight, torch.Size([1, 256]): True
model.decoder.rnn.weight_ih_l0, torch.Size([768, 1024]): True
model.decoder.rnn.weight_hh_l0, torch.Size([768, 256]): True
model.decoder.rnn.bias_ih_l0, torch.Size([768]): True
model.decoder.rnn.bias_hh_l0, torch.Size([768]): True
model.decoder.bridge.weight, torch.Size([256, 512]): True
model.decoder.bridge.bias, torch.Size([256]): True
model.decoder.pre_output_layer.weight, torch.Size([256, 1280]): True
model.src_embed.weight, torch.Size([39, 512]): True
model.trg_embed.weight, torch.Size([39, 512]): True
model.generator.proj.weight, torch.Size([39, 256]): True
multi_vq_layer.embedding_1.weight, torch.Size([12, 128]): True
multi_vq_layer.embedding_2.weight, torch.Size([12, 128]): True
multi_vq_layer.embedding_3.weight, torch.Size([12, 128]): True
multi_vq_layer.embedding_4.weight, torch.Size([12, 128]): True
Epoch 0, ppl: 1.0172,  recon_loss: 19.1655, vq_loss: 2.4154, acc: 0.4515
val -- ppl: 1.0159,  recon_loss: 13.9482, vq_loss: 2.8624, acc: 0.6484 
update best loss
Epoch 1, ppl: 1.0084,  recon_loss: 7.6803, vq_loss: 2.9256, acc: 0.7835
val -- ppl: 1.0072,  recon_loss: 4.7455, vq_loss: 2.8835, acc: 0.8976 
update best loss
Epoch 2, ppl: 1.0044,  recon_loss: 2.7323, vq_loss: 2.7734, acc: 0.9249
val -- ppl: 1.0061,  recon_loss: 3.8539, vq_loss: 2.6769, acc: 0.9211 
update best loss
Epoch 3, ppl: 1.0034,  recon_loss: 1.7316, vq_loss: 2.5841, acc: 0.9524
val -- ppl: 1.0041,  recon_loss: 1.9109, vq_loss: 2.4999, acc: 0.9659 
update best loss
Epoch 4, ppl: 1.0028,  recon_loss: 1.1825, vq_loss: 2.4227, acc: 0.9679
val -- ppl: 1.0036,  recon_loss: 1.4210, vq_loss: 2.3676, acc: 0.9717 
update best loss
Epoch 5, ppl: 1.0025,  recon_loss: 0.9042, vq_loss: 2.2924, acc: 0.9754
val -- ppl: 1.0034,  recon_loss: 1.3894, vq_loss: 2.2588, acc: 0.9707 
update best loss
Epoch 6, ppl: 1.0024,  recon_loss: 0.7760, vq_loss: 2.2044, acc: 0.9795
val -- ppl: 1.0030,  recon_loss: 1.0233, vq_loss: 2.1816, acc: 0.9813 
update best loss
Epoch 7, ppl: 1.0021,  recon_loss: 0.5583, vq_loss: 2.1255, acc: 0.9846
val -- ppl: 1.0027,  recon_loss: 0.7972, vq_loss: 2.1135, acc: 0.9853 
update best loss
Epoch 8, ppl: 1.0020,  recon_loss: 0.4828, vq_loss: 2.0648, acc: 0.9869
val -- ppl: 1.0037,  recon_loss: 1.9190, vq_loss: 2.0631, acc: 0.9705 
Epoch 9, ppl: 1.0020,  recon_loss: 0.5197, vq_loss: 2.0458, acc: 0.9862
val -- ppl: 1.0027,  recon_loss: 0.8442, vq_loss: 2.0424, acc: 0.9873 
Epoch 10, ppl: 1.0019,  recon_loss: 0.4422, vq_loss: 2.0086, acc: 0.9881
val -- ppl: 1.0027,  recon_loss: 0.8218, vq_loss: 2.0314, acc: 0.9872 
Epoch 11, ppl: 1.0020,  recon_loss: 0.5208, vq_loss: 2.0044, acc: 0.9869
val -- ppl: 1.0025,  recon_loss: 0.6707, vq_loss: 2.0101, acc: 0.9902 
update best loss
Epoch 12, ppl: 1.0018,  recon_loss: 0.3033, vq_loss: 1.9602, acc: 0.9921
val -- ppl: 1.0025,  recon_loss: 0.6917, vq_loss: 1.9759, acc: 0.9881 
Epoch 13, ppl: 1.0018,  recon_loss: 0.3687, vq_loss: 1.9524, acc: 0.9908
val -- ppl: 1.0026,  recon_loss: 0.8161, vq_loss: 1.9934, acc: 0.9874 
Epoch 14, ppl: 1.0018,  recon_loss: 0.3114, vq_loss: 1.9477, acc: 0.9919
val -- ppl: 1.0025,  recon_loss: 0.7429, vq_loss: 1.9549, acc: 0.9907 
Epoch 15, ppl: 1.0018,  recon_loss: 0.3942, vq_loss: 1.9180, acc: 0.9904
val -- ppl: 1.0027,  recon_loss: 0.8352, vq_loss: 1.9906, acc: 0.9897 
Epoch 16, ppl: 1.0018,  recon_loss: 0.3040, vq_loss: 1.9213, acc: 0.9927
val -- ppl: 1.0025,  recon_loss: 0.7173, vq_loss: 1.9435, acc: 0.9915 
Epoch 17, ppl: 1.0017,  recon_loss: 0.2682, vq_loss: 1.8984, acc: 0.9933
val -- ppl: 1.0023,  recon_loss: 0.5654, vq_loss: 1.9107, acc: 0.9934 
update best loss
Epoch 18, ppl: 1.0016,  recon_loss: 0.1329, vq_loss: 1.8441, acc: 0.9965
val -- ppl: 1.0021,  recon_loss: 0.4232, vq_loss: 1.8449, acc: 0.9946 
update best loss
Epoch 19, ppl: 1.0016,  recon_loss: 0.2453, vq_loss: 1.8180, acc: 0.9942
val -- ppl: 1.0023,  recon_loss: 0.6283, vq_loss: 1.8697, acc: 0.9893 