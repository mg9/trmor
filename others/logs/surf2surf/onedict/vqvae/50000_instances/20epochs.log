VQVAE(
  (model): EncoderDecoder(
    (encoder): Encoder(
      (rnn): GRU(512, 256, batch_first=True, dropout=0.2, bidirectional=True)
    )
    (decoder): Decoder(
      (attention): BahdanauAttention(
        (key_layer): Linear(in_features=512, out_features=256, bias=False)
        (query_layer): Linear(in_features=256, out_features=256, bias=False)
        (energy_layer): Linear(in_features=256, out_features=1, bias=False)
      )
      (rnn): GRU(1024, 256, batch_first=True, dropout=0.2)
      (bridge): Linear(in_features=512, out_features=256, bias=True)
      (dropout_layer): Dropout(p=0.2, inplace=False)
      (pre_output_layer): Linear(in_features=1280, out_features=256, bias=False)
    )
    (src_embed): Embedding(39, 512)
    (trg_embed): Embedding(39, 512)
    (generator): Generator(
      (proj): Linear(in_features=256, out_features=39, bias=False)
    )
  )
  (vq_layer): VectorQuantizer(
    (embedding): Embedding(48, 512)
  )
)beta:0.25
----- Parameters: -----
model.encoder.rnn.weight_ih_l0, torch.Size([768, 512]): True
model.encoder.rnn.weight_hh_l0, torch.Size([768, 256]): True
model.encoder.rnn.bias_ih_l0, torch.Size([768]): True
model.encoder.rnn.bias_hh_l0, torch.Size([768]): True
model.encoder.rnn.weight_ih_l0_reverse, torch.Size([768, 512]): True
model.encoder.rnn.weight_hh_l0_reverse, torch.Size([768, 256]): True
model.encoder.rnn.bias_ih_l0_reverse, torch.Size([768]): True
model.encoder.rnn.bias_hh_l0_reverse, torch.Size([768]): True
model.decoder.attention.key_layer.weight, torch.Size([256, 512]): True
model.decoder.attention.query_layer.weight, torch.Size([256, 256]): True
model.decoder.attention.energy_layer.weight, torch.Size([1, 256]): True
model.decoder.rnn.weight_ih_l0, torch.Size([768, 1024]): True
model.decoder.rnn.weight_hh_l0, torch.Size([768, 256]): True
model.decoder.rnn.bias_ih_l0, torch.Size([768]): True
model.decoder.rnn.bias_hh_l0, torch.Size([768]): True
model.decoder.bridge.weight, torch.Size([256, 512]): True
model.decoder.bridge.bias, torch.Size([256]): True
model.decoder.pre_output_layer.weight, torch.Size([256, 1280]): True
model.src_embed.weight, torch.Size([39, 512]): True
model.trg_embed.weight, torch.Size([39, 512]): True
model.generator.proj.weight, torch.Size([39, 256]): True
vq_layer.embedding.weight, torch.Size([48, 512]): True
Epoch 0, ppl: 1.0172,  recon_loss: 20.9632, vq_loss: 0.6819, acc: 0.3785
val -- ppl: 1.0192,  recon_loss: 19.4898, vq_loss: 0.7568, acc: 0.4666 
update best loss
Epoch 1, ppl: 1.0136,  recon_loss: 16.3558, vq_loss: 0.7535, acc: 0.4969
val -- ppl: 1.0166,  recon_loss: 16.8645, vq_loss: 0.7488, acc: 0.5263 
update best loss
Epoch 2, ppl: 1.0121,  recon_loss: 14.5421, vq_loss: 0.7497, acc: 0.5471
val -- ppl: 1.0153,  recon_loss: 15.4643, vq_loss: 0.7525, acc: 0.5617 
update best loss
Epoch 3, ppl: 1.0111,  recon_loss: 13.2844, vq_loss: 0.7522, acc: 0.5845
val -- ppl: 1.0140,  recon_loss: 14.0315, vq_loss: 0.7509, acc: 0.5996 
update best loss
Epoch 4, ppl: 1.0103,  recon_loss: 12.2622, vq_loss: 0.7452, acc: 0.6163
val -- ppl: 1.0129,  recon_loss: 12.9831, vq_loss: 0.7412, acc: 0.6347 
update best loss
Epoch 5, ppl: 1.0096,  recon_loss: 11.4323, vq_loss: 0.7358, acc: 0.6418
val -- ppl: 1.0123,  recon_loss: 12.2843, vq_loss: 0.7336, acc: 0.6549 
update best loss
Epoch 6, ppl: 1.0089,  recon_loss: 10.4634, vq_loss: 0.7316, acc: 0.6709
val -- ppl: 1.0112,  recon_loss: 11.1303, vq_loss: 0.7326, acc: 0.6856 
update best loss
Epoch 7, ppl: 1.0082,  recon_loss: 9.6207, vq_loss: 0.7233, acc: 0.6968
val -- ppl: 1.0103,  recon_loss: 10.2146, vq_loss: 0.7200, acc: 0.7185 
update best loss
Epoch 8, ppl: 1.0075,  recon_loss: 8.7595, vq_loss: 0.7101, acc: 0.7244
val -- ppl: 1.0097,  recon_loss: 9.6219, vq_loss: 0.7069, acc: 0.7353 
update best loss
Epoch 9, ppl: 1.0067,  recon_loss: 7.7632, vq_loss: 0.6981, acc: 0.7571
val -- ppl: 1.0086,  recon_loss: 8.4431, vq_loss: 0.6993, acc: 0.7684 
update best loss
Epoch 10, ppl: 1.0062,  recon_loss: 7.1474, vq_loss: 0.6921, acc: 0.7746
val -- ppl: 1.0079,  recon_loss: 7.7394, vq_loss: 0.6936, acc: 0.7887 
update best loss
Epoch 11, ppl: 1.0058,  recon_loss: 6.5932, vq_loss: 0.6873, acc: 0.7920
val -- ppl: 1.0077,  recon_loss: 7.5171, vq_loss: 0.6856, acc: 0.7899 
update best loss
Epoch 12, ppl: 1.0054,  recon_loss: 6.1534, vq_loss: 0.6821, acc: 0.8072
val -- ppl: 1.0074,  recon_loss: 7.1444, vq_loss: 0.6838, acc: 0.8019 
update best loss
Epoch 13, ppl: 1.0053,  recon_loss: 5.9863, vq_loss: 0.6800, acc: 0.8114
val -- ppl: 1.0072,  recon_loss: 7.0054, vq_loss: 0.6845, acc: 0.8099 
update best loss
Epoch 14, ppl: 1.0048,  recon_loss: 5.3996, vq_loss: 0.6760, acc: 0.8295
val -- ppl: 1.0064,  recon_loss: 6.1752, vq_loss: 0.6787, acc: 0.8306 
update best loss
Epoch 15, ppl: 1.0045,  recon_loss: 5.0642, vq_loss: 0.6706, acc: 0.8398
val -- ppl: 1.0061,  recon_loss: 5.7659, vq_loss: 0.6733, acc: 0.8412 
update best loss
Epoch 16, ppl: 1.0043,  recon_loss: 4.7695, vq_loss: 0.6652, acc: 0.8493
val -- ppl: 1.0058,  recon_loss: 5.5027, vq_loss: 0.6704, acc: 0.8484 
update best loss
Epoch 17, ppl: 1.0040,  recon_loss: 4.3367, vq_loss: 0.6609, acc: 0.8628
val -- ppl: 1.0056,  recon_loss: 5.2770, vq_loss: 0.6667, acc: 0.8582 
update best loss
Epoch 18, ppl: 1.0037,  recon_loss: 4.0770, vq_loss: 0.6586, acc: 0.8706
val -- ppl: 1.0054,  recon_loss: 5.0971, vq_loss: 0.6655, acc: 0.8634 
update best loss
Epoch 19, ppl: 1.0036,  recon_loss: 3.9258, vq_loss: 0.6588, acc: 0.8762
val -- ppl: 1.0055,  recon_loss: 5.2239, vq_loss: 0.6681, acc: 0.8608 