
number of params: 12896256 
Namespace(batchsize=128, dec_dropout_in=0.5, dec_dropout_out=0.5, dec_nh=1024, device='cuda', enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=1024, epochs=10, fig_path='model/vae/results/training/582000_instances/10epochs.png', kl_anneal=True, kl_start=0.1, log_path='model/vae/results/training/582000_instances/10epochs.log', logger=<common.utils.Logger object at 0x7fa9703d8f50>, lr=0.001, maxtrnsize=582000, maxtstsize=10000, maxvalsize=10000, mname='vae', model=VAE(
  (encoder): VAE_Encoder(
    (embed): Embedding(33, 512)
    (lstm): LSTM(512, 1024, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=1024, out_features=64, bias=False)
  )
  (decoder): VAE_Decoder(
    (embed): Embedding(33, 512, padding_idx=0)
    (dropout_in): Dropout(p=0.5, inplace=False)
    (dropout_out): Dropout(p=0.5, inplace=False)
    (trans_linear): Linear(in_features=32, out_features=1024, bias=False)
    (lstm): LSTM(544, 1024, batch_first=True)
    (pred_linear): Linear(in_features=1024, out_features=33, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/vae/results/training/582000_instances/', ni=512, nz=32, opt='Adam', save_path='model/vae/results/training/582000_instances/10epochs.pt', seq_to_no_pad='surface', surface_vocab_file='model/vae/data/wordlist.tur.trn', task='vae', trndata='model/vae/data/wordlist.tur.trn', trnsize=582000, tstdata='model/vae/data/wordlist.tur.val', tstsize=582000, valdata='model/vae/data/wordlist.tur.val', valsize=923, warm_up=10)

encoder.embed.weight, torch.Size([33, 512]): True
encoder.lstm.weight_ih_l0, torch.Size([4096, 512]): True
encoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
encoder.lstm.bias_ih_l0, torch.Size([4096]): True
encoder.lstm.bias_hh_l0, torch.Size([4096]): True
encoder.linear.weight, torch.Size([64, 1024]): True
decoder.embed.weight, torch.Size([33, 512]): True
decoder.trans_linear.weight, torch.Size([1024, 32]): True
decoder.lstm.weight_ih_l0, torch.Size([4096, 544]): True
decoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
decoder.lstm.bias_ih_l0, torch.Size([4096]): True
decoder.lstm.bias_hh_l0, torch.Size([4096]): True
decoder.pred_linear.weight, torch.Size([33, 1024]): True
epoch: 0, kl_weight: 0.19, avg_loss: 21.0948, avg_recon_loss: 20.2760, avg_kl_loss: 0.8188, acc: 0.4292
val --- kl_weight: 0.19, avg_loss: 16.8868, avg_recon_loss: 14.8298, avg_kl_loss: 2.0570, acc: 0.6020
update best loss 

epoch: 1, kl_weight: 0.28, avg_loss: 15.6583, avg_recon_loss: 12.5376, avg_kl_loss: 3.1207, acc: 0.6540
val --- kl_weight: 0.28, avg_loss: 13.8068, avg_recon_loss: 9.4996, avg_kl_loss: 4.3072, acc: 0.7188
update best loss 

epoch: 2, kl_weight: 0.37, avg_loss: 14.5618, avg_recon_loss: 9.6499, avg_kl_loss: 4.9119, acc: 0.7273
val --- kl_weight: 0.37, avg_loss: 14.5324, avg_recon_loss: 9.0531, avg_kl_loss: 5.4793, acc: 0.7237

epoch: 3, kl_weight: 0.46, avg_loss: 14.7880, avg_recon_loss: 8.5994, avg_kl_loss: 6.1886, acc: 0.7536
val --- kl_weight: 0.46, avg_loss: 15.7109, avg_recon_loss: 9.2836, avg_kl_loss: 6.4273, acc: 0.7115

epoch: 4, kl_weight: 0.55, avg_loss: 15.5167, avg_recon_loss: 8.3788, avg_kl_loss: 7.1379, acc: 0.7591
val --- kl_weight: 0.55, avg_loss: 16.4048, avg_recon_loss: 9.0272, avg_kl_loss: 7.3776, acc: 0.7148

epoch: 5, kl_weight: 0.64, avg_loss: 16.3121, avg_recon_loss: 8.5626, avg_kl_loss: 7.7496, acc: 0.7536
val --- kl_weight: 0.64, avg_loss: 17.0948, avg_recon_loss: 9.1994, avg_kl_loss: 7.8955, acc: 0.7121

epoch: 6, kl_weight: 0.73, avg_loss: 17.1538, avg_recon_loss: 9.1234, avg_kl_loss: 8.0304, acc: 0.7371
val --- kl_weight: 0.73, avg_loss: 19.3228, avg_recon_loss: 11.5826, avg_kl_loss: 7.7402, acc: 0.6533

epoch: 7, kl_weight: 0.82, avg_loss: 17.9545, avg_recon_loss: 9.9363, avg_kl_loss: 8.0182, acc: 0.7135
val --- kl_weight: 0.82, avg_loss: 19.8652, avg_recon_loss: 12.0286, avg_kl_loss: 7.8366, acc: 0.6304

epoch: 8, kl_weight: 0.91, avg_loss: 18.6314, avg_recon_loss: 11.0971, avg_kl_loss: 7.5343, acc: 0.6794
val --- kl_weight: 0.91, avg_loss: 20.8160, avg_recon_loss: 13.7782, avg_kl_loss: 7.0377, acc: 0.5992

epoch: 9, kl_weight: 1.00, avg_loss: 19.1317, avg_recon_loss: 12.7445, avg_kl_loss: 6.3872, acc: 0.6311
val --- kl_weight: 1.00, avg_loss: 21.6568, avg_recon_loss: 16.2150, avg_kl_loss: 5.4418, acc: 0.5549
