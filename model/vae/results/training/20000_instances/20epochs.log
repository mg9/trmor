
number of params: 12904448 
Namespace(batchsize=128, dec_dropout_in=0.3, dec_dropout_out=0.5, dec_nh=1024, device='cuda', enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=1024, epochs=20, fig_path='model/vae/results/training/20000_instances/20epochs.png', kl_anneal=True, kl_start=0.1, log_path='model/vae/results/training/20000_instances/20epochs.log', logger=<common.utils.Logger object at 0x7f273cdc2e90>, lr=0.001, maxtrnsize=50000, maxtstsize=10000, maxvalsize=10000, mname='vae', model=VAE(
  (encoder): VAE_Encoder(
    (embed): Embedding(37, 512)
    (lstm): LSTM(512, 1024, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=1024, out_features=64, bias=False)
  )
  (decoder): VAE_Decoder(
    (embed): Embedding(37, 512, padding_idx=0)
    (dropout_in): Dropout(p=0.3, inplace=False)
    (dropout_out): Dropout(p=0.5, inplace=False)
    (trans_linear): Linear(in_features=32, out_features=1024, bias=False)
    (lstm): LSTM(544, 1024, batch_first=True)
    (pred_linear): Linear(in_features=1024, out_features=37, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/vae/results/training/20000_instances/', ni=512, nz=32, opt='Adam', save_path='model/vae/results/training/20000_instances/20epochs.pt', seq_to_no_pad='surface', surface_vocab_file='model/vae/data/filtered_wordlist_20k.tur', task='vae', trndata='model/vae/data/filtered_wordlist_20k.tur', trnsize=20000, tstdata='model/vae/data/wordlist.tur.val', tstsize=20000, valdata='model/vae/data/wordlist.tur.val', valsize=923, warm_up=30)

encoder.embed.weight, torch.Size([37, 512]): True
encoder.lstm.weight_ih_l0, torch.Size([4096, 512]): True
encoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
encoder.lstm.bias_ih_l0, torch.Size([4096]): True
encoder.lstm.bias_hh_l0, torch.Size([4096]): True
encoder.linear.weight, torch.Size([64, 1024]): True
decoder.embed.weight, torch.Size([37, 512]): True
decoder.trans_linear.weight, torch.Size([1024, 32]): True
decoder.lstm.weight_ih_l0, torch.Size([4096, 544]): True
decoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
decoder.lstm.bias_ih_l0, torch.Size([4096]): True
decoder.lstm.bias_hh_l0, torch.Size([4096]): True
decoder.pred_linear.weight, torch.Size([37, 1024]): True
epoch: 0, kl_weight: 0.13, avg_loss: 24.6363, avg_recon_loss: 24.6153, avg_kl_loss: 0.0210, acc: 0.2049
val --- kl_weight: 0.13, avg_loss: 29.9346, avg_recon_loss: 29.7023, avg_kl_loss: 0.2323, acc: 0.2699
update best loss 

epoch: 1, kl_weight: 0.16, avg_loss: 20.2048, avg_recon_loss: 20.0094, avg_kl_loss: 0.1955, acc: 0.3103
val --- kl_weight: 0.16, avg_loss: 28.6535, avg_recon_loss: 28.4559, avg_kl_loss: 0.1976, acc: 0.2826
update best loss 

epoch: 2, kl_weight: 0.19, avg_loss: 18.6454, avg_recon_loss: 18.3437, avg_kl_loss: 0.3017, acc: 0.3477
val --- kl_weight: 0.19, avg_loss: 25.9707, avg_recon_loss: 25.5575, avg_kl_loss: 0.4133, acc: 0.3376
update best loss 

epoch: 3, kl_weight: 0.22, avg_loss: 17.0057, avg_recon_loss: 16.6192, avg_kl_loss: 0.3865, acc: 0.3931
val --- kl_weight: 0.22, avg_loss: 25.5146, avg_recon_loss: 25.0359, avg_kl_loss: 0.4787, acc: 0.3385
update best loss 

epoch: 4, kl_weight: 0.25, avg_loss: 15.9174, avg_recon_loss: 15.4106, avg_kl_loss: 0.5068, acc: 0.4277
val --- kl_weight: 0.25, avg_loss: 24.2859, avg_recon_loss: 23.7285, avg_kl_loss: 0.5574, acc: 0.3848
update best loss 

epoch: 5, kl_weight: 0.28, avg_loss: 14.9969, avg_recon_loss: 14.4128, avg_kl_loss: 0.5841, acc: 0.4595
val --- kl_weight: 0.28, avg_loss: 24.5320, avg_recon_loss: 23.9363, avg_kl_loss: 0.5957, acc: 0.3813

epoch: 6, kl_weight: 0.31, avg_loss: 14.3939, avg_recon_loss: 13.7348, avg_kl_loss: 0.6591, acc: 0.4816
val --- kl_weight: 0.31, avg_loss: 23.7268, avg_recon_loss: 23.0294, avg_kl_loss: 0.6974, acc: 0.4033
update best loss 

epoch: 7, kl_weight: 0.34, avg_loss: 13.9606, avg_recon_loss: 13.2236, avg_kl_loss: 0.7370, acc: 0.4985
val --- kl_weight: 0.34, avg_loss: 22.6773, avg_recon_loss: 21.8356, avg_kl_loss: 0.8416, acc: 0.4040
update best loss 

epoch: 8, kl_weight: 0.37, avg_loss: 13.5600, avg_recon_loss: 12.7221, avg_kl_loss: 0.8379, acc: 0.5184
val --- kl_weight: 0.37, avg_loss: 24.0264, avg_recon_loss: 23.1014, avg_kl_loss: 0.9249, acc: 0.3991

epoch: 9, kl_weight: 0.40, avg_loss: 13.2141, avg_recon_loss: 12.2848, avg_kl_loss: 0.9293, acc: 0.5322
val --- kl_weight: 0.40, avg_loss: 24.0055, avg_recon_loss: 22.8594, avg_kl_loss: 1.1461, acc: 0.4041

epoch: 10, kl_weight: 0.43, avg_loss: 13.1449, avg_recon_loss: 12.1445, avg_kl_loss: 1.0004, acc: 0.5379
val --- kl_weight: 0.43, avg_loss: 23.5106, avg_recon_loss: 22.2621, avg_kl_loss: 1.2485, acc: 0.4182

epoch: 11, kl_weight: 0.46, avg_loss: 12.8230, avg_recon_loss: 11.6984, avg_kl_loss: 1.1246, acc: 0.5527
val --- kl_weight: 0.46, avg_loss: 25.1457, avg_recon_loss: 23.8065, avg_kl_loss: 1.3392, acc: 0.4017

epoch: 12, kl_weight: 0.49, avg_loss: 12.6803, avg_recon_loss: 11.4840, avg_kl_loss: 1.1963, acc: 0.5590
val --- kl_weight: 0.49, avg_loss: 23.5649, avg_recon_loss: 22.0821, avg_kl_loss: 1.4827, acc: 0.4127

epoch: 13, kl_weight: 0.52, avg_loss: 12.6100, avg_recon_loss: 11.3508, avg_kl_loss: 1.2592, acc: 0.5638
val --- kl_weight: 0.52, avg_loss: 23.1075, avg_recon_loss: 21.5345, avg_kl_loss: 1.5731, acc: 0.4301

epoch: 14, kl_weight: 0.55, avg_loss: 12.3994, avg_recon_loss: 11.0595, avg_kl_loss: 1.3399, acc: 0.5712
val --- kl_weight: 0.55, avg_loss: 23.6271, avg_recon_loss: 22.1205, avg_kl_loss: 1.5066, acc: 0.4399

epoch: 15, kl_weight: 0.58, avg_loss: 12.3042, avg_recon_loss: 10.8806, avg_kl_loss: 1.4236, acc: 0.5783
val --- kl_weight: 0.58, avg_loss: 23.5901, avg_recon_loss: 21.9041, avg_kl_loss: 1.6860, acc: 0.4222

epoch: 16, kl_weight: 0.61, avg_loss: 12.2571, avg_recon_loss: 10.7279, avg_kl_loss: 1.5292, acc: 0.5827
val --- kl_weight: 0.61, avg_loss: 24.0011, avg_recon_loss: 22.1931, avg_kl_loss: 1.8080, acc: 0.4213

epoch: 17, kl_weight: 0.64, avg_loss: 12.1661, avg_recon_loss: 10.5367, avg_kl_loss: 1.6294, acc: 0.5874
val --- kl_weight: 0.64, avg_loss: 25.7006, avg_recon_loss: 23.9310, avg_kl_loss: 1.7696, acc: 0.4125

epoch: 18, kl_weight: 0.67, avg_loss: 12.1391, avg_recon_loss: 10.4396, avg_kl_loss: 1.6995, acc: 0.5913
val --- kl_weight: 0.67, avg_loss: 26.1063, avg_recon_loss: 24.2195, avg_kl_loss: 1.8867, acc: 0.4215

epoch: 19, kl_weight: 0.70, avg_loss: 12.1297, avg_recon_loss: 10.3510, avg_kl_loss: 1.7788, acc: 0.5953
val --- kl_weight: 0.70, avg_loss: 25.8386, avg_recon_loss: 23.8712, avg_kl_loss: 1.9674, acc: 0.4129
