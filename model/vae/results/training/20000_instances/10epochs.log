
number of params: 12904448 
Namespace(batchsize=128, dec_dropout_in=0.5, dec_dropout_out=0.5, dec_nh=1024, device='cuda', enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=1024, epochs=10, fig_path='model/vae/results/training/20000_instances/10epochs.png', kl_anneal=True, kl_start=0.1, log_path='model/vae/results/training/20000_instances/10epochs.log', logger=<common.utils.Logger object at 0x7f9b9bdc2c10>, lr=0.001, maxtrnsize=50000, maxtstsize=10000, maxvalsize=10000, mname='vae', model=VAE(
  (encoder): VAE_Encoder(
    (embed): Embedding(37, 512)
    (lstm): LSTM(512, 1024, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=1024, out_features=64, bias=False)
  )
  (decoder): VAE_Decoder(
    (embed): Embedding(37, 512, padding_idx=0)
    (dropout_in): Dropout(p=0.5, inplace=False)
    (dropout_out): Dropout(p=0.5, inplace=False)
    (trans_linear): Linear(in_features=32, out_features=1024, bias=False)
    (lstm): LSTM(544, 1024, batch_first=True)
    (pred_linear): Linear(in_features=1024, out_features=37, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/vae/results/training/20000_instances/', ni=512, nz=32, opt='Adam', save_path='model/vae/results/training/20000_instances/10epochs.pt', seq_to_no_pad='surface', surface_vocab_file='model/vae/data/filtered_wordlist_20k.tur', task='vae', trndata='model/vae/data/filtered_wordlist_20k.tur', trnsize=20000, tstdata='model/vae/data/wordlist.tur.val', tstsize=20000, valdata='model/vae/data/wordlist.tur.val', valsize=923, warm_up=10)

encoder.embed.weight, torch.Size([37, 512]): True
encoder.lstm.weight_ih_l0, torch.Size([4096, 512]): True
encoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
encoder.lstm.bias_ih_l0, torch.Size([4096]): True
encoder.lstm.bias_hh_l0, torch.Size([4096]): True
encoder.linear.weight, torch.Size([64, 1024]): True
decoder.embed.weight, torch.Size([37, 512]): True
decoder.trans_linear.weight, torch.Size([1024, 32]): True
decoder.lstm.weight_ih_l0, torch.Size([4096, 544]): True
decoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
decoder.lstm.bias_ih_l0, torch.Size([4096]): True
decoder.lstm.bias_hh_l0, torch.Size([4096]): True
decoder.pred_linear.weight, torch.Size([37, 1024]): True
epoch: 0, kl_weight: 0.19, avg_loss: 24.8320, avg_recon_loss: 24.8191, avg_kl_loss: 0.0129, acc: 0.1955
val --- kl_weight: 0.19, avg_loss: 30.0477, avg_recon_loss: 29.9734, avg_kl_loss: 0.0744, acc: 0.2647
update best loss 

epoch: 1, kl_weight: 0.28, avg_loss: 20.4795, avg_recon_loss: 20.2659, avg_kl_loss: 0.2136, acc: 0.3046
val --- kl_weight: 0.28, avg_loss: 29.1389, avg_recon_loss: 28.8552, avg_kl_loss: 0.2837, acc: 0.2741
update best loss 

epoch: 2, kl_weight: 0.37, avg_loss: 19.1245, avg_recon_loss: 18.8478, avg_kl_loss: 0.2766, acc: 0.3348
val --- kl_weight: 0.37, avg_loss: 26.3659, avg_recon_loss: 26.0670, avg_kl_loss: 0.2988, acc: 0.3219
update best loss 

epoch: 3, kl_weight: 0.46, avg_loss: 17.6893, avg_recon_loss: 17.2638, avg_kl_loss: 0.4255, acc: 0.3744
val --- kl_weight: 0.46, avg_loss: 26.6380, avg_recon_loss: 26.0744, avg_kl_loss: 0.5636, acc: 0.2963

epoch: 4, kl_weight: 0.55, avg_loss: 16.6672, avg_recon_loss: 16.0684, avg_kl_loss: 0.5988, acc: 0.4047
val --- kl_weight: 0.55, avg_loss: 25.7951, avg_recon_loss: 25.0661, avg_kl_loss: 0.7290, acc: 0.3273
update best loss 

epoch: 5, kl_weight: 0.64, avg_loss: 15.9214, avg_recon_loss: 15.2327, avg_kl_loss: 0.6887, acc: 0.4315
val --- kl_weight: 0.64, avg_loss: 25.2083, avg_recon_loss: 24.5016, avg_kl_loss: 0.7067, acc: 0.3438
update best loss 

epoch: 6, kl_weight: 0.73, avg_loss: 15.3235, avg_recon_loss: 14.5344, avg_kl_loss: 0.7891, acc: 0.4528
val --- kl_weight: 0.73, avg_loss: 25.1310, avg_recon_loss: 24.3866, avg_kl_loss: 0.7444, acc: 0.3694
update best loss 

epoch: 7, kl_weight: 0.82, avg_loss: 14.9654, avg_recon_loss: 14.1267, avg_kl_loss: 0.8387, acc: 0.4670
val --- kl_weight: 0.82, avg_loss: 23.3365, avg_recon_loss: 22.5600, avg_kl_loss: 0.7765, acc: 0.3996
update best loss 

epoch: 8, kl_weight: 0.91, avg_loss: 14.6982, avg_recon_loss: 13.8373, avg_kl_loss: 0.8610, acc: 0.4780
val --- kl_weight: 0.91, avg_loss: 23.7332, avg_recon_loss: 23.1810, avg_kl_loss: 0.5522, acc: 0.3822

epoch: 9, kl_weight: 1.00, avg_loss: 14.3350, avg_recon_loss: 13.5606, avg_kl_loss: 0.7744, acc: 0.4877
val --- kl_weight: 1.00, avg_loss: 23.6493, avg_recon_loss: 23.1237, avg_kl_loss: 0.5256, acc: 0.3891
