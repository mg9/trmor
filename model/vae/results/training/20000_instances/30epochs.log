
number of params: 12904448 
Namespace(batchsize=128, dec_dropout_in=0.5, dec_dropout_out=0.5, dec_nh=1024, device='cuda', enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=1024, epochs=30, fig_path='model/vae/results/training/20000_instances/30epochs.png', kl_anneal=True, kl_start=0.1, log_path='model/vae/results/training/20000_instances/30epochs.log', logger=<common.utils.Logger object at 0x7f8d7509d2d0>, lr=0.001, maxtrnsize=50000, maxtstsize=10000, maxvalsize=10000, mname='vae', model=VAE(
  (encoder): VAE_Encoder(
    (embed): Embedding(37, 512)
    (lstm): LSTM(512, 1024, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=1024, out_features=64, bias=False)
  )
  (decoder): VAE_Decoder(
    (embed): Embedding(37, 512, padding_idx=0)
    (dropout_in): Dropout(p=0.5, inplace=False)
    (dropout_out): Dropout(p=0.5, inplace=False)
    (trans_linear): Linear(in_features=32, out_features=1024, bias=False)
    (lstm): LSTM(544, 1024, batch_first=True)
    (pred_linear): Linear(in_features=1024, out_features=37, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/vae/results/training/20000_instances/', ni=512, nz=32, opt='Adam', save_path='model/vae/results/training/20000_instances/30epochs.pt', seq_to_no_pad='surface', surface_vocab_file='model/vae/data/filtered_wordlist_20k.tur', task='vae', trndata='model/vae/data/filtered_wordlist_20k.tur', trnsize=20000, tstdata='model/vae/data/wordlist.tur.val', tstsize=20000, valdata='model/vae/data/wordlist.tur.val', valsize=923, warm_up=30)

encoder.embed.weight, torch.Size([37, 512]): True
encoder.lstm.weight_ih_l0, torch.Size([4096, 512]): True
encoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
encoder.lstm.bias_ih_l0, torch.Size([4096]): True
encoder.lstm.bias_hh_l0, torch.Size([4096]): True
encoder.linear.weight, torch.Size([64, 1024]): True
decoder.embed.weight, torch.Size([37, 512]): True
decoder.trans_linear.weight, torch.Size([1024, 32]): True
decoder.lstm.weight_ih_l0, torch.Size([4096, 544]): True
decoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
decoder.lstm.bias_ih_l0, torch.Size([4096]): True
decoder.lstm.bias_hh_l0, torch.Size([4096]): True
decoder.pred_linear.weight, torch.Size([37, 1024]): True
epoch: 0, kl_weight: 0.13, avg_loss: 24.4906, avg_recon_loss: 24.4753, avg_kl_loss: 0.0152, acc: 0.2053
val --- kl_weight: 0.13, avg_loss: 29.8888, avg_recon_loss: 29.8694, avg_kl_loss: 0.0194, acc: 0.2818
update best loss 

epoch: 1, kl_weight: 0.16, avg_loss: 20.3371, avg_recon_loss: 20.1804, avg_kl_loss: 0.1567, acc: 0.3072
val --- kl_weight: 0.16, avg_loss: 29.0352, avg_recon_loss: 28.8320, avg_kl_loss: 0.2032, acc: 0.2800
update best loss 

epoch: 2, kl_weight: 0.19, avg_loss: 18.7395, avg_recon_loss: 18.4485, avg_kl_loss: 0.2910, acc: 0.3461
val --- kl_weight: 0.19, avg_loss: 26.5863, avg_recon_loss: 26.1527, avg_kl_loss: 0.4336, acc: 0.3127
update best loss 

epoch: 3, kl_weight: 0.22, avg_loss: 17.1072, avg_recon_loss: 16.7059, avg_kl_loss: 0.4013, acc: 0.3880
val --- kl_weight: 0.22, avg_loss: 26.5309, avg_recon_loss: 26.0843, avg_kl_loss: 0.4466, acc: 0.3012
update best loss 

epoch: 4, kl_weight: 0.25, avg_loss: 16.1334, avg_recon_loss: 15.6263, avg_kl_loss: 0.5072, acc: 0.4175
val --- kl_weight: 0.25, avg_loss: 24.8321, avg_recon_loss: 24.3172, avg_kl_loss: 0.5150, acc: 0.3290
update best loss 

epoch: 5, kl_weight: 0.28, avg_loss: 15.2034, avg_recon_loss: 14.5966, avg_kl_loss: 0.6069, acc: 0.4491
val --- kl_weight: 0.28, avg_loss: 24.7172, avg_recon_loss: 24.0782, avg_kl_loss: 0.6390, acc: 0.3791
update best loss 

epoch: 6, kl_weight: 0.31, avg_loss: 14.6636, avg_recon_loss: 13.9803, avg_kl_loss: 0.6833, acc: 0.4705
val --- kl_weight: 0.31, avg_loss: 23.9019, avg_recon_loss: 23.1323, avg_kl_loss: 0.7696, acc: 0.3998
update best loss 

epoch: 7, kl_weight: 0.34, avg_loss: 14.1430, avg_recon_loss: 13.3547, avg_kl_loss: 0.7883, acc: 0.4915
val --- kl_weight: 0.34, avg_loss: 22.4426, avg_recon_loss: 21.3646, avg_kl_loss: 1.0780, acc: 0.4318
update best loss 

epoch: 8, kl_weight: 0.37, avg_loss: 13.7834, avg_recon_loss: 12.8623, avg_kl_loss: 0.9211, acc: 0.5115
val --- kl_weight: 0.37, avg_loss: 23.4311, avg_recon_loss: 22.3726, avg_kl_loss: 1.0585, acc: 0.4130

epoch: 9, kl_weight: 0.40, avg_loss: 13.4466, avg_recon_loss: 12.4302, avg_kl_loss: 1.0164, acc: 0.5261
val --- kl_weight: 0.40, avg_loss: 23.8424, avg_recon_loss: 22.6808, avg_kl_loss: 1.1616, acc: 0.4200

epoch: 10, kl_weight: 0.43, avg_loss: 13.2059, avg_recon_loss: 12.0945, avg_kl_loss: 1.1114, acc: 0.5367
val --- kl_weight: 0.43, avg_loss: 23.8120, avg_recon_loss: 22.5532, avg_kl_loss: 1.2588, acc: 0.3949

epoch: 11, kl_weight: 0.46, avg_loss: 13.0250, avg_recon_loss: 11.8409, avg_kl_loss: 1.1841, acc: 0.5452
val --- kl_weight: 0.46, avg_loss: 25.3662, avg_recon_loss: 24.0446, avg_kl_loss: 1.3216, acc: 0.3884

epoch: 12, kl_weight: 0.49, avg_loss: 12.8390, avg_recon_loss: 11.5417, avg_kl_loss: 1.2973, acc: 0.5539
val --- kl_weight: 0.49, avg_loss: 23.1022, avg_recon_loss: 21.7870, avg_kl_loss: 1.3152, acc: 0.4384

epoch: 13, kl_weight: 0.52, avg_loss: 12.5803, avg_recon_loss: 11.1566, avg_kl_loss: 1.4236, acc: 0.5678
val --- kl_weight: 0.52, avg_loss: 23.2879, avg_recon_loss: 21.8742, avg_kl_loss: 1.4137, acc: 0.4418

epoch: 14, kl_weight: 0.55, avg_loss: 12.4419, avg_recon_loss: 10.8524, avg_kl_loss: 1.5895, acc: 0.5789
val --- kl_weight: 0.55, avg_loss: 23.2032, avg_recon_loss: 21.5355, avg_kl_loss: 1.6677, acc: 0.4248

epoch: 15, kl_weight: 0.58, avg_loss: 12.3665, avg_recon_loss: 10.6581, avg_kl_loss: 1.7084, acc: 0.5843
val --- kl_weight: 0.58, avg_loss: 23.3843, avg_recon_loss: 21.7775, avg_kl_loss: 1.6068, acc: 0.4185

epoch: 16, kl_weight: 0.61, avg_loss: 12.3549, avg_recon_loss: 10.5708, avg_kl_loss: 1.7841, acc: 0.5885
val --- kl_weight: 0.61, avg_loss: 23.7806, avg_recon_loss: 22.0781, avg_kl_loss: 1.7025, acc: 0.4120

epoch: 17, kl_weight: 0.64, avg_loss: 12.2524, avg_recon_loss: 10.3687, avg_kl_loss: 1.8837, acc: 0.5945
val --- kl_weight: 0.64, avg_loss: 25.8459, avg_recon_loss: 24.2134, avg_kl_loss: 1.6325, acc: 0.3988

epoch: 18, kl_weight: 0.67, avg_loss: 12.1592, avg_recon_loss: 10.2211, avg_kl_loss: 1.9381, acc: 0.5989
val --- kl_weight: 0.67, avg_loss: 26.4085, avg_recon_loss: 24.5111, avg_kl_loss: 1.8975, acc: 0.4179

epoch: 19, kl_weight: 0.70, avg_loss: 12.1427, avg_recon_loss: 10.1019, avg_kl_loss: 2.0408, acc: 0.6015
val --- kl_weight: 0.70, avg_loss: 25.6738, avg_recon_loss: 23.7619, avg_kl_loss: 1.9119, acc: 0.4189

epoch: 20, kl_weight: 0.73, avg_loss: 12.1338, avg_recon_loss: 10.0360, avg_kl_loss: 2.0978, acc: 0.6033
val --- kl_weight: 0.73, avg_loss: 23.6953, avg_recon_loss: 21.6624, avg_kl_loss: 2.0330, acc: 0.4296

epoch: 21, kl_weight: 0.76, avg_loss: 12.1641, avg_recon_loss: 10.0272, avg_kl_loss: 2.1369, acc: 0.6030
val --- kl_weight: 0.76, avg_loss: 24.2602, avg_recon_loss: 22.2152, avg_kl_loss: 2.0450, acc: 0.4381

epoch: 22, kl_weight: 0.79, avg_loss: 12.1478, avg_recon_loss: 9.9506, avg_kl_loss: 2.1972, acc: 0.6058
val --- kl_weight: 0.79, avg_loss: 26.4306, avg_recon_loss: 24.4474, avg_kl_loss: 1.9832, acc: 0.4157

epoch: 23, kl_weight: 0.82, avg_loss: 12.1274, avg_recon_loss: 9.9268, avg_kl_loss: 2.2006, acc: 0.6059
val --- kl_weight: 0.82, avg_loss: 26.0690, avg_recon_loss: 24.2707, avg_kl_loss: 1.7983, acc: 0.4078

epoch: 24, kl_weight: 0.85, avg_loss: 12.1994, avg_recon_loss: 9.9823, avg_kl_loss: 2.2171, acc: 0.6046
val --- kl_weight: 0.85, avg_loss: 25.1968, avg_recon_loss: 23.1153, avg_kl_loss: 2.0814, acc: 0.4227

epoch: 25, kl_weight: 0.88, avg_loss: 12.2771, avg_recon_loss: 10.0086, avg_kl_loss: 2.2685, acc: 0.6066
val --- kl_weight: 0.88, avg_loss: 26.2420, avg_recon_loss: 24.2169, avg_kl_loss: 2.0251, acc: 0.4112

epoch: 26, kl_weight: 0.91, avg_loss: 12.2314, avg_recon_loss: 9.9695, avg_kl_loss: 2.2619, acc: 0.6057
val --- kl_weight: 0.91, avg_loss: 24.3087, avg_recon_loss: 22.3133, avg_kl_loss: 1.9954, acc: 0.4258

epoch: 27, kl_weight: 0.94, avg_loss: 12.2245, avg_recon_loss: 9.9577, avg_kl_loss: 2.2668, acc: 0.6074
val --- kl_weight: 0.94, avg_loss: 26.6801, avg_recon_loss: 24.7370, avg_kl_loss: 1.9430, acc: 0.4150

epoch: 28, kl_weight: 0.97, avg_loss: 12.2732, avg_recon_loss: 10.0429, avg_kl_loss: 2.2303, acc: 0.6026
val --- kl_weight: 0.97, avg_loss: 26.6635, avg_recon_loss: 24.7164, avg_kl_loss: 1.9471, acc: 0.3968

epoch: 29, kl_weight: 1.00, avg_loss: 12.2638, avg_recon_loss: 10.1000, avg_kl_loss: 2.1639, acc: 0.6014
val --- kl_weight: 1.00, avg_loss: 26.0148, avg_recon_loss: 24.2023, avg_kl_loss: 1.8126, acc: 0.4176
