
number of params: 12904448 
Namespace(batchsize=128, dec_dropout_in=0.5, dec_dropout_out=0.5, dec_nh=1024, device='cuda', enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=1024, epochs=10, fig_path='model/vae/results/training/50000_instances/10epochs.png', kl_anneal=True, kl_start=0.1, log_path='model/vae/results/training/50000_instances/10epochs.log', logger=<common.utils.Logger object at 0x7f4f7dc1c050>, lr=0.001, maxtrnsize=50000, maxtstsize=10000, maxvalsize=10000, mname='vae', model=VAE(
  (encoder): VAE_Encoder(
    (embed): Embedding(37, 512)
    (lstm): LSTM(512, 1024, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=1024, out_features=64, bias=False)
  )
  (decoder): VAE_Decoder(
    (embed): Embedding(37, 512, padding_idx=0)
    (dropout_in): Dropout(p=0.5, inplace=False)
    (dropout_out): Dropout(p=0.5, inplace=False)
    (trans_linear): Linear(in_features=32, out_features=1024, bias=False)
    (lstm): LSTM(544, 1024, batch_first=True)
    (pred_linear): Linear(in_features=1024, out_features=37, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/vae/results/training/50000_instances/', ni=512, nz=32, opt='Adam', save_path='model/vae/results/training/50000_instances/10epochs.pt', seq_to_no_pad='surface', surface_vocab_file='model/vae/data/filtered_wordlist2.tur', task='vae', trndata='model/vae/data/filtered_wordlist2.tur', trnsize=50000, tstdata='model/vae/data/wordlist.tur.val', tstsize=50000, valdata='model/vae/data/wordlist.tur.val', valsize=923, warm_up=10)

encoder.embed.weight, torch.Size([37, 512]): True
encoder.lstm.weight_ih_l0, torch.Size([4096, 512]): True
encoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
encoder.lstm.bias_ih_l0, torch.Size([4096]): True
encoder.lstm.bias_hh_l0, torch.Size([4096]): True
encoder.linear.weight, torch.Size([64, 1024]): True
decoder.embed.weight, torch.Size([37, 512]): True
decoder.trans_linear.weight, torch.Size([1024, 32]): True
decoder.lstm.weight_ih_l0, torch.Size([4096, 544]): True
decoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
decoder.lstm.bias_ih_l0, torch.Size([4096]): True
decoder.lstm.bias_hh_l0, torch.Size([4096]): True
decoder.pred_linear.weight, torch.Size([37, 1024]): True
epoch: 0, kl_weight: 0.19, avg_loss: 22.2136, avg_recon_loss: 21.9928, avg_kl_loss: 0.2208, acc: 0.2929
val --- kl_weight: 0.19, avg_loss: 26.5129, avg_recon_loss: 26.0112, avg_kl_loss: 0.5017, acc: 0.3061
update best loss 

epoch: 1, kl_weight: 0.28, avg_loss: 17.8111, avg_recon_loss: 17.2399, avg_kl_loss: 0.5711, acc: 0.4116
val --- kl_weight: 0.28, avg_loss: 23.8399, avg_recon_loss: 23.1140, avg_kl_loss: 0.7258, acc: 0.3639
update best loss 

epoch: 2, kl_weight: 0.37, avg_loss: 16.3123, avg_recon_loss: 15.4363, avg_kl_loss: 0.8760, acc: 0.4692
val --- kl_weight: 0.37, avg_loss: 22.8588, avg_recon_loss: 21.6116, avg_kl_loss: 1.2471, acc: 0.4296
update best loss 

epoch: 3, kl_weight: 0.46, avg_loss: 15.5673, avg_recon_loss: 14.4200, avg_kl_loss: 1.1474, acc: 0.5017
val --- kl_weight: 0.46, avg_loss: 21.5324, avg_recon_loss: 19.8784, avg_kl_loss: 1.6540, acc: 0.4673
update best loss 

epoch: 4, kl_weight: 0.55, avg_loss: 14.9673, avg_recon_loss: 13.4599, avg_kl_loss: 1.5074, acc: 0.5349
val --- kl_weight: 0.55, avg_loss: 21.1711, avg_recon_loss: 19.3070, avg_kl_loss: 1.8641, acc: 0.4871
update best loss 

epoch: 5, kl_weight: 0.64, avg_loss: 14.7939, avg_recon_loss: 13.0649, avg_kl_loss: 1.7291, acc: 0.5482
val --- kl_weight: 0.64, avg_loss: 20.6631, avg_recon_loss: 18.6034, avg_kl_loss: 2.0598, acc: 0.5038
update best loss 

epoch: 6, kl_weight: 0.73, avg_loss: 14.5908, avg_recon_loss: 12.6734, avg_kl_loss: 1.9174, acc: 0.5591
val --- kl_weight: 0.73, avg_loss: 21.0213, avg_recon_loss: 18.6489, avg_kl_loss: 2.3724, acc: 0.4982

epoch: 7, kl_weight: 0.82, avg_loss: 14.5968, avg_recon_loss: 12.5627, avg_kl_loss: 2.0341, acc: 0.5624
val --- kl_weight: 0.82, avg_loss: 22.2674, avg_recon_loss: 19.9432, avg_kl_loss: 2.3242, acc: 0.4617

epoch: 8, kl_weight: 0.91, avg_loss: 14.5410, avg_recon_loss: 12.5254, avg_kl_loss: 2.0156, acc: 0.5624
val --- kl_weight: 0.91, avg_loss: 20.5469, avg_recon_loss: 18.1010, avg_kl_loss: 2.4459, acc: 0.5042
update best loss 

epoch: 9, kl_weight: 1.00, avg_loss: 14.5632, avg_recon_loss: 12.5918, avg_kl_loss: 1.9713, acc: 0.5593
val --- kl_weight: 1.00, avg_loss: 21.5998, avg_recon_loss: 19.2743, avg_kl_loss: 2.3256, acc: 0.4911
