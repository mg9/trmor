
number of params: 12863488 
Namespace(batchsize=128, dec_dropout_in=0.5, dec_dropout_out=0.5, dec_nh=1024, device='cuda', enc_dropout_in=0.0, enc_dropout_out=0.0, enc_nh=1024, epochs=5, fig_path='model/ae/results/training/582000_instances/5epochs.png', log_path='model/ae/results/training/582000_instances/5epochs.log', logger=<common.utils.Logger object at 0x7f2e38fa5c90>, lr=0.001, maxtrnsize=582000, maxtstsize=10000, maxvalsize=10000, mname='ae', model=AE(
  (encoder): AE_Encoder(
    (embed): Embedding(33, 512)
    (lstm): LSTM(512, 1024, batch_first=True)
    (dropout_in): Dropout(p=0.0, inplace=False)
    (linear): Linear(in_features=1024, out_features=32, bias=False)
  )
  (decoder): AE_Decoder(
    (embed): Embedding(33, 512, padding_idx=0)
    (dropout_in): Dropout(p=0.5, inplace=False)
    (dropout_out): Dropout(p=0.5, inplace=False)
    (trans_linear): Linear(in_features=32, out_features=1024, bias=False)
    (lstm): LSTM(544, 1024, batch_first=True)
    (pred_linear): Linear(in_features=1024, out_features=33, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/ae/results/training/582000_instances/', ni=512, nz=32, opt='Adam', save_path='model/ae/results/training/582000_instances/5epochs.pt', seq_to_no_pad='surface', surface_vocab_file='model/ae/data/wordlist.tur.trn', task='ae', trndata='model/ae/data/wordlist.tur.trn', trnsize=582000, tstdata='model/ae/data/wordlist.tur.val', tstsize=582000, valdata='model/ae/data/wordlist.tur.val', valsize=923)

encoder.embed.weight, torch.Size([33, 512]): True
encoder.lstm.weight_ih_l0, torch.Size([4096, 512]): True
encoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
encoder.lstm.bias_ih_l0, torch.Size([4096]): True
encoder.lstm.bias_hh_l0, torch.Size([4096]): True
encoder.linear.weight, torch.Size([32, 1024]): True
decoder.embed.weight, torch.Size([33, 512]): True
decoder.trans_linear.weight, torch.Size([1024, 32]): True
decoder.lstm.weight_ih_l0, torch.Size([4096, 544]): True
decoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
decoder.lstm.bias_ih_l0, torch.Size([4096]): True
decoder.lstm.bias_hh_l0, torch.Size([4096]): True
decoder.pred_linear.weight, torch.Size([33, 1024]): True
epoch: 0 avg_loss: 1.6051, acc: 0.5166
val --- avg_loss: 1.0646, acc: 0.7135  
update best loss 

epoch: 1 avg_loss: 0.5462, acc: 0.8298
val --- avg_loss: 0.1728, acc: 0.9309  
update best loss 

epoch: 2 avg_loss: 0.1378, acc: 0.9539
val --- avg_loss: 0.0521, acc: 0.9815  
update best loss 

epoch: 3 avg_loss: 0.0743, acc: 0.9749
val --- avg_loss: 0.0457, acc: 0.9843  
update best loss 

epoch: 4 avg_loss: 0.0503, acc: 0.9833
val --- avg_loss: 0.0114, acc: 0.9955  
update best loss 
