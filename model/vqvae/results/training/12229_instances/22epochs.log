
number of params: 8460288 
Namespace(batchsize=128, beta=0, dec_dropout_in=0.2, dec_dropout_out=0.2, dec_nh=1024, device='cuda', embedding_dim=512, enc_dropout_in=0.2, enc_dropout_out=0.2, enc_nh=512, epochs=22, fig_path='model/vqvae/results/training/12229_instances/22epochs.png', incat=0, log_path='model/vqvae/results/training/12229_instances/22epochs.log', logger=<common.utils.Logger object at 0x7f2f4a8374d0>, lr=0.001, maxtrnsize=1000000, maxtstsize=10000, maxvalsize=10000, mname='vqvae', model=VQVAE_AE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(36, 256)
    (lstm): LSTM(256, 512, batch_first=True, bidirectional=True)
    (dropout_in): Dropout(p=0.2, inplace=False)
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(36, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.2, inplace=False)
    (dropout_out): Dropout(p=0.2, inplace=False)
    (lstm): LSTM(256, 1024, batch_first=True)
    (pred_linear): Linear(in_features=1024, out_features=36, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/vqvae/results/training/12229_instances/', ni=256, num_dicts=0, nz=512, opt='Adam', orddict_emb_num=0, outcat=0, rootdict_emb_dim=512, rootdict_emb_num=0, save_path='model/vqvae/results/training/12229_instances/22epochs.pt', seq_to_no_pad='surface', surface_vocab_file='data/sigmorphon2016/turkish-task3-train', task='vqvae', trndata='data/sigmorphon2016/turkish-task3-train', trnsize=12229, tstdata='data/sigmorphon2016/turkish-task3-dev', tstsize=12229, valdata='data/sigmorphon2016/turkish-task3-dev', valsize=1589)

encoder.embed.weight, torch.Size([36, 256]): True
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): True
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): True
encoder.lstm.bias_ih_l0, torch.Size([2048]): True
encoder.lstm.bias_hh_l0, torch.Size([2048]): True
encoder.lstm.weight_ih_l0_reverse, torch.Size([2048, 256]): True
encoder.lstm.weight_hh_l0_reverse, torch.Size([2048, 512]): True
encoder.lstm.bias_ih_l0_reverse, torch.Size([2048]): True
encoder.lstm.bias_hh_l0_reverse, torch.Size([2048]): True
decoder.embed.weight, torch.Size([36, 256]): True
decoder.lstm.weight_ih_l0, torch.Size([4096, 256]): True
decoder.lstm.weight_hh_l0, torch.Size([4096, 1024]): True
decoder.lstm.bias_ih_l0, torch.Size([4096]): True
decoder.lstm.bias_hh_l0, torch.Size([4096]): True
decoder.pred_linear.weight, torch.Size([36, 1024]): True
epoch: 0,  avg_loss: 34.4602, avg_recon_loss: 34.4602, avg_vq_loss: 0.0000, acc: 0.1673
val ---  avg_loss: 28.1416, avg_recon_loss: 28.1416, avg_vq_loss: 0.0000, acc: 0.2719
update best loss 

epoch: 1,  avg_loss: 25.8554, avg_recon_loss: 25.8554, avg_vq_loss: 0.0000, acc: 0.3321
val ---  avg_loss: 22.8148, avg_recon_loss: 22.8148, avg_vq_loss: 0.0000, acc: 0.4140
update best loss 

epoch: 2,  avg_loss: 21.6554, avg_recon_loss: 21.6554, avg_vq_loss: 0.0000, acc: 0.4347
val ---  avg_loss: 20.0928, avg_recon_loss: 20.0928, avg_vq_loss: 0.0000, acc: 0.4853
update best loss 

epoch: 3,  avg_loss: 18.7849, avg_recon_loss: 18.7849, avg_vq_loss: 0.0000, acc: 0.5089
val ---  avg_loss: 16.9768, avg_recon_loss: 16.9768, avg_vq_loss: 0.0000, acc: 0.5551
update best loss 

epoch: 4,  avg_loss: 15.2513, avg_recon_loss: 15.2513, avg_vq_loss: 0.0000, acc: 0.5956
val ---  avg_loss: 13.0224, avg_recon_loss: 13.0224, avg_vq_loss: 0.0000, acc: 0.6498
update best loss 

epoch: 5,  avg_loss: 11.9292, avg_recon_loss: 11.9292, avg_vq_loss: 0.0000, acc: 0.6752
val ---  avg_loss: 9.9760, avg_recon_loss: 9.9760, avg_vq_loss: 0.0000, acc: 0.7254
update best loss 

epoch: 6,  avg_loss: 8.3675, avg_recon_loss: 8.3675, avg_vq_loss: 0.0000, acc: 0.7675
val ---  avg_loss: 6.4076, avg_recon_loss: 6.4076, avg_vq_loss: 0.0000, acc: 0.8264
update best loss 

epoch: 7,  avg_loss: 5.7418, avg_recon_loss: 5.7418, avg_vq_loss: 0.0000, acc: 0.8403
val ---  avg_loss: 4.3032, avg_recon_loss: 4.3032, avg_vq_loss: 0.0000, acc: 0.8953
update best loss 

epoch: 8,  avg_loss: 3.5262, avg_recon_loss: 3.5262, avg_vq_loss: 0.0000, acc: 0.9096
val ---  avg_loss: 2.2175, avg_recon_loss: 2.2175, avg_vq_loss: 0.0000, acc: 0.9503
update best loss 

epoch: 9,  avg_loss: 1.6550, avg_recon_loss: 1.6550, avg_vq_loss: 0.0000, acc: 0.9645
val ---  avg_loss: 2.4914, avg_recon_loss: 2.4914, avg_vq_loss: 0.0000, acc: 0.9416

epoch: 10,  avg_loss: 1.5505, avg_recon_loss: 1.5505, avg_vq_loss: 0.0000, acc: 0.9652
val ---  avg_loss: 0.8518, avg_recon_loss: 0.8518, avg_vq_loss: 0.0000, acc: 0.9841
update best loss 

epoch: 11,  avg_loss: 0.8945, avg_recon_loss: 0.8945, avg_vq_loss: 0.0000, acc: 0.9826
val ---  avg_loss: 0.9156, avg_recon_loss: 0.9156, avg_vq_loss: 0.0000, acc: 0.9813

epoch: 12,  avg_loss: 0.5872, avg_recon_loss: 0.5872, avg_vq_loss: 0.0000, acc: 0.9899
val ---  avg_loss: 0.4308, avg_recon_loss: 0.4308, avg_vq_loss: 0.0000, acc: 0.9913
update best loss 

epoch: 13,  avg_loss: 0.2692, avg_recon_loss: 0.2692, avg_vq_loss: 0.0000, acc: 0.9964
val ---  avg_loss: 0.3009, avg_recon_loss: 0.3009, avg_vq_loss: 0.0000, acc: 0.9942
update best loss 

epoch: 14,  avg_loss: 0.2003, avg_recon_loss: 0.2003, avg_vq_loss: 0.0000, acc: 0.9975
val ---  avg_loss: 0.2772, avg_recon_loss: 0.2772, avg_vq_loss: 0.0000, acc: 0.9943
update best loss 

epoch: 15,  avg_loss: 0.1583, avg_recon_loss: 0.1583, avg_vq_loss: 0.0000, acc: 0.9980
val ---  avg_loss: 0.2497, avg_recon_loss: 0.2497, avg_vq_loss: 0.0000, acc: 0.9948
update best loss 

epoch: 16,  avg_loss: 0.1584, avg_recon_loss: 0.1584, avg_vq_loss: 0.0000, acc: 0.9977
val ---  avg_loss: 0.3575, avg_recon_loss: 0.3575, avg_vq_loss: 0.0000, acc: 0.9923

epoch: 17,  avg_loss: 0.1892, avg_recon_loss: 0.1892, avg_vq_loss: 0.0000, acc: 0.9971
val ---  avg_loss: 0.2222, avg_recon_loss: 0.2222, avg_vq_loss: 0.0000, acc: 0.9957
update best loss 

epoch: 18,  avg_loss: 0.1257, avg_recon_loss: 0.1257, avg_vq_loss: 0.0000, acc: 0.9984
val ---  avg_loss: 0.2075, avg_recon_loss: 0.2075, avg_vq_loss: 0.0000, acc: 0.9955
update best loss 

epoch: 19,  avg_loss: 0.0619, avg_recon_loss: 0.0619, avg_vq_loss: 0.0000, acc: 0.9996
val ---  avg_loss: 0.1539, avg_recon_loss: 0.1539, avg_vq_loss: 0.0000, acc: 0.9966
update best loss 

epoch: 20,  avg_loss: 0.1630, avg_recon_loss: 0.1630, avg_vq_loss: 0.0000, acc: 0.9969
val ---  avg_loss: 0.4192, avg_recon_loss: 0.4192, avg_vq_loss: 0.0000, acc: 0.9895

epoch: 21,  avg_loss: 0.1244, avg_recon_loss: 0.1244, avg_vq_loss: 0.0000, acc: 0.9982
val ---  avg_loss: 0.1942, avg_recon_loss: 0.1942, avg_vq_loss: 0.0000, acc: 0.9955
