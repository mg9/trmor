
number of params: 3190784 
Namespace(batchsize=128, beta=0, dec_dropout_in=0.2, dec_dropout_out=0.2, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.2, enc_dropout_out=0.2, enc_nh=512, epochs=20, fig_path='model/vqvae/results/training/28794_instances/20epochs.png', incat=0, log_path='model/vqvae/results/training/28794_instances/20epochs.log', logger=<common.utils.Logger object at 0x7f6b48ba1990>, lr=0.001, maxtrnsize=1000000, maxtstsize=10000, maxvalsize=10000, mname='vqvae', model=VQVAE_AE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(36, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.2, inplace=False)
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(36, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.2, inplace=False)
    (dropout_out): Dropout(p=0.2, inplace=False)
    (lstm): LSTM(256, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=36, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/vqvae/results/training/28794_instances/', ni=256, num_dicts=0, nz=512, opt='Adam', orddict_emb_num=0, outcat=0, rootdict_emb_dim=512, rootdict_emb_num=0, save_path='model/vqvae/results/training/28794_instances/20epochs.pt', seq_to_no_pad='surface', surface_vocab_file='data/sigmorphon2016/zhou_merged', task='vqvae', trndata='data/sigmorphon2016/zhou_merged', trnsize=28794, tstdata='data/sigmorphon2016/turkish-task3-dev', tstsize=28794, valdata='data/sigmorphon2016/turkish-task3-dev', valsize=1589)

encoder.embed.weight, torch.Size([36, 256]): True
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): True
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): True
encoder.lstm.bias_ih_l0, torch.Size([2048]): True
encoder.lstm.bias_hh_l0, torch.Size([2048]): True
decoder.embed.weight, torch.Size([36, 256]): True
decoder.lstm.weight_ih_l0, torch.Size([2048, 256]): True
decoder.lstm.weight_hh_l0, torch.Size([2048, 512]): True
decoder.lstm.bias_ih_l0, torch.Size([2048]): True
decoder.lstm.bias_hh_l0, torch.Size([2048]): True
decoder.pred_linear.weight, torch.Size([36, 512]): True
epoch: 0,  avg_loss: 29.3641, avg_recon_loss: 29.3641, avg_vq_loss: 0.0000, acc: 0.2839
val ---  avg_loss: 23.2929, avg_recon_loss: 23.2929, avg_vq_loss: 0.0000, acc: 0.3884
update best loss 

epoch: 1,  avg_loss: 21.6927, avg_recon_loss: 21.6927, avg_vq_loss: 0.0000, acc: 0.4335
val ---  avg_loss: 20.5973, avg_recon_loss: 20.5973, avg_vq_loss: 0.0000, acc: 0.4469
update best loss 

epoch: 2,  avg_loss: 19.2466, avg_recon_loss: 19.2466, avg_vq_loss: 0.0000, acc: 0.4870
val ---  avg_loss: 17.9127, avg_recon_loss: 17.9127, avg_vq_loss: 0.0000, acc: 0.5199
update best loss 

epoch: 3,  avg_loss: 17.4704, avg_recon_loss: 17.4704, avg_vq_loss: 0.0000, acc: 0.5304
val ---  avg_loss: 15.5078, avg_recon_loss: 15.5078, avg_vq_loss: 0.0000, acc: 0.5848
update best loss 

epoch: 4,  avg_loss: 15.0134, avg_recon_loss: 15.0134, avg_vq_loss: 0.0000, acc: 0.5993
val ---  avg_loss: 12.8409, avg_recon_loss: 12.8409, avg_vq_loss: 0.0000, acc: 0.6665
update best loss 

epoch: 5,  avg_loss: 12.5242, avg_recon_loss: 12.5242, avg_vq_loss: 0.0000, acc: 0.6683
val ---  avg_loss: 10.0540, avg_recon_loss: 10.0540, avg_vq_loss: 0.0000, acc: 0.7435
update best loss 

epoch: 6,  avg_loss: 9.5364, avg_recon_loss: 9.5364, avg_vq_loss: 0.0000, acc: 0.7513
val ---  avg_loss: 6.7121, avg_recon_loss: 6.7121, avg_vq_loss: 0.0000, acc: 0.8409
update best loss 

epoch: 7,  avg_loss: 6.2136, avg_recon_loss: 6.2136, avg_vq_loss: 0.0000, acc: 0.8424
val ---  avg_loss: 3.9373, avg_recon_loss: 3.9373, avg_vq_loss: 0.0000, acc: 0.9101
update best loss 

epoch: 8,  avg_loss: 3.5332, avg_recon_loss: 3.5332, avg_vq_loss: 0.0000, acc: 0.9151
val ---  avg_loss: 1.8626, avg_recon_loss: 1.8626, avg_vq_loss: 0.0000, acc: 0.9651
update best loss 

epoch: 9,  avg_loss: 2.0610, avg_recon_loss: 2.0610, avg_vq_loss: 0.0000, acc: 0.9538
val ---  avg_loss: 1.0649, avg_recon_loss: 1.0649, avg_vq_loss: 0.0000, acc: 0.9819
update best loss 

epoch: 10,  avg_loss: 1.6350, avg_recon_loss: 1.6350, avg_vq_loss: 0.0000, acc: 0.9644
val ---  avg_loss: 0.6855, avg_recon_loss: 0.6855, avg_vq_loss: 0.0000, acc: 0.9902
update best loss 

epoch: 11,  avg_loss: 0.8352, avg_recon_loss: 0.8352, avg_vq_loss: 0.0000, acc: 0.9841
val ---  avg_loss: 0.6880, avg_recon_loss: 0.6880, avg_vq_loss: 0.0000, acc: 0.9850

epoch: 12,  avg_loss: 0.5947, avg_recon_loss: 0.5947, avg_vq_loss: 0.0000, acc: 0.9888
val ---  avg_loss: 0.2289, avg_recon_loss: 0.2289, avg_vq_loss: 0.0000, acc: 0.9975
update best loss 

epoch: 13,  avg_loss: 0.4569, avg_recon_loss: 0.4569, avg_vq_loss: 0.0000, acc: 0.9915
val ---  avg_loss: 0.5214, avg_recon_loss: 0.5214, avg_vq_loss: 0.0000, acc: 0.9891

epoch: 14,  avg_loss: 0.4697, avg_recon_loss: 0.4697, avg_vq_loss: 0.0000, acc: 0.9910
val ---  avg_loss: 0.1231, avg_recon_loss: 0.1231, avg_vq_loss: 0.0000, acc: 0.9988
update best loss 

epoch: 15,  avg_loss: 0.2774, avg_recon_loss: 0.2774, avg_vq_loss: 0.0000, acc: 0.9954
val ---  avg_loss: 0.1428, avg_recon_loss: 0.1428, avg_vq_loss: 0.0000, acc: 0.9983

epoch: 16,  avg_loss: 0.4696, avg_recon_loss: 0.4696, avg_vq_loss: 0.0000, acc: 0.9902
val ---  avg_loss: 0.0763, avg_recon_loss: 0.0763, avg_vq_loss: 0.0000, acc: 0.9995
update best loss 

epoch: 17,  avg_loss: 0.3201, avg_recon_loss: 0.3201, avg_vq_loss: 0.0000, acc: 0.9936
val ---  avg_loss: 0.2121, avg_recon_loss: 0.2121, avg_vq_loss: 0.0000, acc: 0.9966

epoch: 18,  avg_loss: 0.1778, avg_recon_loss: 0.1778, avg_vq_loss: 0.0000, acc: 0.9973
val ---  avg_loss: 0.0761, avg_recon_loss: 0.0761, avg_vq_loss: 0.0000, acc: 0.9988
update best loss 

epoch: 19,  avg_loss: 0.1034, avg_recon_loss: 0.1034, avg_vq_loss: 0.0000, acc: 0.9986
val ---  avg_loss: 0.0274, avg_recon_loss: 0.0274, avg_vq_loss: 0.0000, acc: 0.9998
update best loss 
