
number of params: 3190784 
Namespace(batchsize=128, beta=0, dec_dropout_in=0.2, dec_dropout_out=0.2, dec_nh=512, device='cuda', embedding_dim=512, enc_dropout_in=0.2, enc_dropout_out=0.2, enc_nh=512, epochs=21, fig_path='model/vqvae/results/training/25031_instances/21epochs.png', incat=0, log_path='model/vqvae/results/training/25031_instances/21epochs.log', logger=<common.utils.Logger object at 0x7f0b17e5c710>, lr=0.001, maxtrnsize=1000000, maxtstsize=10000, maxvalsize=10000, mname='vqvae', model=VQVAE_AE(
  (encoder): VQVAE_Encoder(
    (embed): Embedding(36, 256)
    (lstm): LSTM(256, 512, batch_first=True)
    (dropout_in): Dropout(p=0.2, inplace=False)
  )
  (decoder): VQVAE_Decoder(
    (embed): Embedding(36, 256, padding_idx=0)
    (dropout_in): Dropout(p=0.2, inplace=False)
    (dropout_out): Dropout(p=0.2, inplace=False)
    (lstm): LSTM(256, 512, batch_first=True)
    (pred_linear): Linear(in_features=512, out_features=36, bias=False)
    (loss): CrossEntropyLoss()
  )
), modelname='model/vqvae/results/training/25031_instances/', ni=256, num_dicts=0, nz=512, opt='Adam', orddict_emb_num=0, outcat=0, rootdict_emb_dim=512, rootdict_emb_num=0, save_path='model/vqvae/results/training/25031_instances/21epochs.pt', seq_to_no_pad='surface', surface_vocab_file='data/sigmorphon2016/zhou_merged', task='vqvae', trndata='data/sigmorphon2016/zhou_merged', trnsize=25031, tstdata='data/sigmorphon2016/turkish-task3-dev', tstsize=25031, valdata='data/sigmorphon2016/turkish-task3-dev', valsize=1589)

encoder.embed.weight, torch.Size([36, 256]): True
encoder.lstm.weight_ih_l0, torch.Size([2048, 256]): True
encoder.lstm.weight_hh_l0, torch.Size([2048, 512]): True
encoder.lstm.bias_ih_l0, torch.Size([2048]): True
encoder.lstm.bias_hh_l0, torch.Size([2048]): True
decoder.embed.weight, torch.Size([36, 256]): True
decoder.lstm.weight_ih_l0, torch.Size([2048, 256]): True
decoder.lstm.weight_hh_l0, torch.Size([2048, 512]): True
decoder.lstm.bias_ih_l0, torch.Size([2048]): True
decoder.lstm.bias_hh_l0, torch.Size([2048]): True
decoder.pred_linear.weight, torch.Size([36, 512]): True
epoch: 0,  avg_loss: 31.6857, avg_recon_loss: 31.6857, avg_vq_loss: 0.0000, acc: 0.2222
val ---  avg_loss: 25.9187, avg_recon_loss: 25.9187, avg_vq_loss: 0.0000, acc: 0.3484
update best loss 

epoch: 1,  avg_loss: 23.0518, avg_recon_loss: 23.0518, avg_vq_loss: 0.0000, acc: 0.4091
val ---  avg_loss: 20.9101, avg_recon_loss: 20.9101, avg_vq_loss: 0.0000, acc: 0.4461
update best loss 

epoch: 2,  avg_loss: 20.2601, avg_recon_loss: 20.2601, avg_vq_loss: 0.0000, acc: 0.4628
val ---  avg_loss: 19.0779, avg_recon_loss: 19.0779, avg_vq_loss: 0.0000, acc: 0.4906
update best loss 

epoch: 3,  avg_loss: 18.0530, avg_recon_loss: 18.0530, avg_vq_loss: 0.0000, acc: 0.5155
val ---  avg_loss: 17.2826, avg_recon_loss: 17.2826, avg_vq_loss: 0.0000, acc: 0.5314
update best loss 

epoch: 4,  avg_loss: 16.1252, avg_recon_loss: 16.1252, avg_vq_loss: 0.0000, acc: 0.5706
val ---  avg_loss: 15.5352, avg_recon_loss: 15.5352, avg_vq_loss: 0.0000, acc: 0.5893
update best loss 

epoch: 5,  avg_loss: 14.0159, avg_recon_loss: 14.0159, avg_vq_loss: 0.0000, acc: 0.6363
val ---  avg_loss: 12.4031, avg_recon_loss: 12.4031, avg_vq_loss: 0.0000, acc: 0.6794
update best loss 

epoch: 6,  avg_loss: 11.0676, avg_recon_loss: 11.0676, avg_vq_loss: 0.0000, acc: 0.7162
val ---  avg_loss: 8.5310, avg_recon_loss: 8.5310, avg_vq_loss: 0.0000, acc: 0.7930
update best loss 

epoch: 7,  avg_loss: 7.1759, avg_recon_loss: 7.1759, avg_vq_loss: 0.0000, acc: 0.8217
val ---  avg_loss: 5.1048, avg_recon_loss: 5.1048, avg_vq_loss: 0.0000, acc: 0.8775
update best loss 

epoch: 8,  avg_loss: 4.0472, avg_recon_loss: 4.0472, avg_vq_loss: 0.0000, acc: 0.9036
val ---  avg_loss: 2.2115, avg_recon_loss: 2.2115, avg_vq_loss: 0.0000, acc: 0.9565
update best loss 

epoch: 9,  avg_loss: 2.0178, avg_recon_loss: 2.0178, avg_vq_loss: 0.0000, acc: 0.9564
val ---  avg_loss: 1.6966, avg_recon_loss: 1.6966, avg_vq_loss: 0.0000, acc: 0.9643
update best loss 

epoch: 10,  avg_loss: 1.5215, avg_recon_loss: 1.5215, avg_vq_loss: 0.0000, acc: 0.9670
val ---  avg_loss: 0.7018, avg_recon_loss: 0.7018, avg_vq_loss: 0.0000, acc: 0.9905
update best loss 

epoch: 11,  avg_loss: 0.7396, avg_recon_loss: 0.7396, avg_vq_loss: 0.0000, acc: 0.9868
val ---  avg_loss: 0.6839, avg_recon_loss: 0.6839, avg_vq_loss: 0.0000, acc: 0.9871
update best loss 

epoch: 12,  avg_loss: 0.6229, avg_recon_loss: 0.6229, avg_vq_loss: 0.0000, acc: 0.9884
val ---  avg_loss: 1.1688, avg_recon_loss: 1.1688, avg_vq_loss: 0.0000, acc: 0.9725

epoch: 13,  avg_loss: 0.7790, avg_recon_loss: 0.7790, avg_vq_loss: 0.0000, acc: 0.9837
val ---  avg_loss: 0.3313, avg_recon_loss: 0.3313, avg_vq_loss: 0.0000, acc: 0.9947
update best loss 

epoch: 14,  avg_loss: 0.3092, avg_recon_loss: 0.3092, avg_vq_loss: 0.0000, acc: 0.9953
val ---  avg_loss: 0.1636, avg_recon_loss: 0.1636, avg_vq_loss: 0.0000, acc: 0.9977
update best loss 

epoch: 15,  avg_loss: 0.2050, avg_recon_loss: 0.2050, avg_vq_loss: 0.0000, acc: 0.9971
val ---  avg_loss: 0.1825, avg_recon_loss: 0.1825, avg_vq_loss: 0.0000, acc: 0.9965

epoch: 16,  avg_loss: 0.2614, avg_recon_loss: 0.2614, avg_vq_loss: 0.0000, acc: 0.9956
val ---  avg_loss: 0.1208, avg_recon_loss: 0.1208, avg_vq_loss: 0.0000, acc: 0.9982
update best loss 

epoch: 17,  avg_loss: 0.1952, avg_recon_loss: 0.1952, avg_vq_loss: 0.0000, acc: 0.9966
val ---  avg_loss: 0.3673, avg_recon_loss: 0.3673, avg_vq_loss: 0.0000, acc: 0.9923

epoch: 18,  avg_loss: 0.1807, avg_recon_loss: 0.1807, avg_vq_loss: 0.0000, acc: 0.9973
val ---  avg_loss: 0.0735, avg_recon_loss: 0.0735, avg_vq_loss: 0.0000, acc: 0.9987
update best loss 

epoch: 19,  avg_loss: 0.1144, avg_recon_loss: 0.1144, avg_vq_loss: 0.0000, acc: 0.9984
val ---  avg_loss: 0.1029, avg_recon_loss: 0.1029, avg_vq_loss: 0.0000, acc: 0.9982

epoch: 20,  avg_loss: 0.1018, avg_recon_loss: 0.1018, avg_vq_loss: 0.0000, acc: 0.9986
val ---  avg_loss: 0.0695, avg_recon_loss: 0.0695, avg_vq_loss: 0.0000, acc: 0.9986
update best loss 
