
number of params: 6356480 
Namespace(batchsize=128, device='cuda', enc_dropout_in=0.2, enc_dropout_out=0.3, epochs=30, fig_path='model/charlm/results/training/617298_instances/30epochs.png', log_path='model/charlm/results/training/617298_instances/30epochs.log', logger=<common.utils.Logger object at 0x7fd05a83a550>, lr=0.001, maxtrnsize=700000, maxtstsize=10000, maxvalsize=10000, mname='charlm', model=CharLM(
  (embed): Embedding(37, 512, padding_idx=0)
  (lstm): LSTM(512, 1024, batch_first=True)
  (dropout_in): Dropout(p=0.2, inplace=False)
  (dropout_out): Dropout(p=0.3, inplace=False)
  (pred_linear): Linear(in_features=1024, out_features=37, bias=False)
  (loss): CrossEntropyLoss()
), modelname='model/charlm/results/training/617298_instances/', nh=1024, ni=512, opt='Adam', save_path='model/charlm/results/training/617298_instances/30epochs.pt', seq_to_no_pad='surface', surface_vocab_file='model/charlm/data/wordlist.tur', task='lm', trndata='model/charlm/data/wordlist.tur', trnsize=617298, tstdata='model/charlm/data/wordlist.tur.val', tstsize=617298, valdata='model/charlm/data/wordlist.tur.val', valsize=923)

embed.weight, torch.Size([37, 512]): True
lstm.weight_ih_l0, torch.Size([4096, 512]): True
lstm.weight_hh_l0, torch.Size([4096, 1024]): True
lstm.bias_ih_l0, torch.Size([4096]): True
lstm.bias_hh_l0, torch.Size([4096]): True
pred_linear.weight, torch.Size([37, 1024]): True
epoch: 0 avg_loss: 2.1751
val --- avg_loss: 2.1920 
update best loss 

epoch: 1 avg_loss: 1.9542
val --- avg_loss: 1.9696 
update best loss 

epoch: 2 avg_loss: 1.8664
val --- avg_loss: 1.8849 
update best loss 

epoch: 3 avg_loss: 1.8154
val --- avg_loss: 1.8149 
update best loss 

epoch: 4 avg_loss: 1.7818
val --- avg_loss: 1.8487 

epoch: 5 avg_loss: 1.7589
val --- avg_loss: 1.7961 
update best loss 

epoch: 6 avg_loss: 1.7401
val --- avg_loss: 1.7838 
update best loss 

epoch: 7 avg_loss: 1.7242
val --- avg_loss: 1.8124 

epoch: 8 avg_loss: 1.7121
val --- avg_loss: 1.8261 

epoch: 9 avg_loss: 1.7017
val --- avg_loss: 1.7779 
update best loss 

epoch: 10 avg_loss: 1.6936
val --- avg_loss: 1.7788 

epoch: 11 avg_loss: 1.6856
val --- avg_loss: 1.7864 

epoch: 12 avg_loss: 1.6797
val --- avg_loss: 1.8392 

epoch: 13 avg_loss: 1.6747
val --- avg_loss: 1.7904 

epoch: 14 avg_loss: 1.6722
val --- avg_loss: 1.7874 

epoch: 15 avg_loss: 1.6711
val --- avg_loss: 1.8214 

epoch: 16 avg_loss: 1.6774
val --- avg_loss: 1.8378 

epoch: 17 avg_loss: 1.6703
val --- avg_loss: 1.8373 

epoch: 18 avg_loss: 1.6728
val --- avg_loss: 1.7852 

epoch: 19 avg_loss: 1.6776
val --- avg_loss: 1.8228 

epoch: 20 avg_loss: 1.6749
val --- avg_loss: 1.7783 

epoch: 21 avg_loss: 1.6798
val --- avg_loss: 1.8122 

epoch: 22 avg_loss: 1.6710
val --- avg_loss: 1.7900 

epoch: 23 avg_loss: 1.6713
val --- avg_loss: 1.7835 

epoch: 24 avg_loss: 1.6958
val --- avg_loss: 1.8431 

epoch: 25 avg_loss: 1.7608
val --- avg_loss: 1.8840 

epoch: 26 avg_loss: 1.7703
val --- avg_loss: 1.8401 

epoch: 27 avg_loss: 1.7728
val --- avg_loss: 1.8780 

epoch: 28 avg_loss: 1.8970
val --- avg_loss: 1.9133 

epoch: 29 avg_loss: 1.8703
val --- avg_loss: 1.9703 
